{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HELP_PATH = '/Users/shankar/dev/code/ds/studies/data_science/dlcv'\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(IMG_HELP_PATH))\n",
    "from common.preprocessing import ImageToArrayPreprocessor, AspectAwarePreprocessor\n",
    "from common.datasets import SimpleDatasetLoader\n",
    "from common.nn.conv import FCHeadNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"../datasets/flowers17/images\"\n",
    "MODEL = \"flowers17.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the image generator for the data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=30, \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading Images\n"
     ]
    }
   ],
   "source": [
    "# Grab the list of images that we'll be describing, then extract the\n",
    "# class label names from the image paths\n",
    "print(\"[INFO] Loading Images\")\n",
    "imagePaths = list(paths.list_images(DATASET))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "classNames = [str(x) for x in np.unique(classNames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the image preprocessors\n",
    "aap = AspectAwarePreprocessor(224, 224)\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/1360\n",
      "[INFO] processed 1000/1360\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the disk then scale the raw pixel intensitites\n",
    "# to the range [0, 1]\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap, iap])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data into training and testing splits using 75% of \n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels from integers to vectors\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new head of the network, a set of FC layers followed\n",
    "# by a softmax classifier\n",
    "headModel = FCHeadNet.build(baseModel, len(classNames), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the head FC model on top of the base model -- this will become\n",
    "# the actual model we will train\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all layers in the base model and freeze them so they will\n",
    "# not be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling Model\n"
     ]
    }
   ],
   "source": [
    "# Compile our model (this needs to be done after our setting our layers\n",
    "# to being non-trainable)\n",
    "print(\"[INFO] Compiling Model\")\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head\n",
      "Epoch 1/25\n",
      "31/31 [==============================] - 523s 17s/step - loss: 6.5616 - acc: 0.1900 - val_loss: 1.7633 - val_acc: 0.4000\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 521s 17s/step - loss: 2.3265 - acc: 0.3236 - val_loss: 1.6202 - val_acc: 0.4765\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 540s 17s/step - loss: 1.8373 - acc: 0.4284 - val_loss: 1.2419 - val_acc: 0.6029\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 528s 17s/step - loss: 1.6089 - acc: 0.5108 - val_loss: 0.8957 - val_acc: 0.7471\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 867s 28s/step - loss: 1.4074 - acc: 0.5478 - val_loss: 0.7453 - val_acc: 0.7971\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 508s 16s/step - loss: 1.3552 - acc: 0.5818 - val_loss: 0.7732 - val_acc: 0.7618\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 600s 19s/step - loss: 1.2068 - acc: 0.6087 - val_loss: 0.8156 - val_acc: 0.7353\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 518s 17s/step - loss: 1.1883 - acc: 0.6351 - val_loss: 0.6097 - val_acc: 0.8088\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 514s 17s/step - loss: 1.0287 - acc: 0.6633 - val_loss: 0.5761 - val_acc: 0.8147\n",
      "Epoch 10/25\n",
      "31/31 [==============================] - 1154s 37s/step - loss: 0.9612 - acc: 0.6885 - val_loss: 0.5449 - val_acc: 0.8294\n",
      "Epoch 11/25\n",
      "31/31 [==============================] - 530s 17s/step - loss: 0.9516 - acc: 0.6921 - val_loss: 0.5328 - val_acc: 0.8382\n",
      "Epoch 12/25\n",
      "31/31 [==============================] - 721s 23s/step - loss: 0.9084 - acc: 0.7035 - val_loss: 0.4772 - val_acc: 0.8500\n",
      "Epoch 13/25\n",
      "31/31 [==============================] - 540s 17s/step - loss: 0.7620 - acc: 0.7507 - val_loss: 0.4845 - val_acc: 0.8353\n",
      "Epoch 14/25\n",
      "31/31 [==============================] - 520s 17s/step - loss: 0.8040 - acc: 0.7578 - val_loss: 0.5311 - val_acc: 0.8294\n",
      "Epoch 15/25\n",
      "31/31 [==============================] - 535s 17s/step - loss: 0.7738 - acc: 0.7517 - val_loss: 0.4436 - val_acc: 0.8735\n",
      "Epoch 16/25\n",
      "31/31 [==============================] - 520s 17s/step - loss: 0.7626 - acc: 0.7480 - val_loss: 0.5775 - val_acc: 0.8265\n",
      "Epoch 17/25\n",
      "31/31 [==============================] - 515s 17s/step - loss: 0.7173 - acc: 0.7743 - val_loss: 0.4250 - val_acc: 0.8735\n",
      "Epoch 18/25\n",
      "31/31 [==============================] - 2138s 69s/step - loss: 0.7194 - acc: 0.7532 - val_loss: 0.3785 - val_acc: 0.8706\n",
      "Epoch 19/25\n",
      "31/31 [==============================] - 523s 17s/step - loss: 0.6403 - acc: 0.7821 - val_loss: 0.3374 - val_acc: 0.9000\n",
      "Epoch 20/25\n",
      "31/31 [==============================] - 531s 17s/step - loss: 0.6665 - acc: 0.7974 - val_loss: 0.5043 - val_acc: 0.8588\n",
      "Epoch 21/25\n",
      "31/31 [==============================] - 1456s 47s/step - loss: 0.5955 - acc: 0.8050 - val_loss: 0.5465 - val_acc: 0.8353\n",
      "Epoch 22/25\n",
      "31/31 [==============================] - 621s 20s/step - loss: 0.6016 - acc: 0.7912 - val_loss: 0.4453 - val_acc: 0.8647\n",
      "Epoch 23/25\n",
      "31/31 [==============================] - 671s 22s/step - loss: 0.6241 - acc: 0.7926 - val_loss: 0.4593 - val_acc: 0.8706\n",
      "Epoch 24/25\n",
      "31/31 [==============================] - 722s 23s/step - loss: 0.5804 - acc: 0.8115 - val_loss: 0.4716 - val_acc: 0.8765\n",
      "Epoch 25/25\n",
      "31/31 [==============================] - 685s 22s/step - loss: 0.5535 - acc: 0.8211 - val_loss: 0.5034 - val_acc: 0.8735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2562fe48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the head of the network for a few epochs (all other layers)\n",
    "# are frozen) -- this will allow the new FC layers to start to become\n",
    "# initialized with actual \"learned\" values versus pure random\n",
    "print(\"[INFO] training head\")\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32), validation_data=(testX, testY),\n",
    "    epochs=25, steps_per_epoch=len(trainX)//32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating after initialization...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   bluebell       0.88      0.94      0.91        16\n",
      "  buttercup       1.00      1.00      1.00        15\n",
      "  coltsfoot       0.94      0.80      0.86        20\n",
      "    cowslip       0.61      0.94      0.74        18\n",
      "     crocus       0.88      0.70      0.78        20\n",
      "   daffodil       0.81      0.91      0.86        23\n",
      "      daisy       1.00      0.95      0.97        19\n",
      "  dandelion       1.00      0.78      0.88        18\n",
      " fritillary       0.94      0.89      0.92        19\n",
      "       iris       0.95      1.00      0.98        21\n",
      " lilyvalley       1.00      0.70      0.82        20\n",
      "      pansy       0.90      0.96      0.93        27\n",
      "   snowdrop       0.94      0.68      0.79        22\n",
      "  sunflower       1.00      1.00      1.00        23\n",
      "  tigerlily       0.88      0.94      0.91        16\n",
      "      tulip       0.55      0.85      0.67        20\n",
      " windflower       1.00      0.83      0.90        23\n",
      "\n",
      "avg / total       0.90      0.87      0.88       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network after initialization \n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), \n",
    "    target_names=classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Serializing Model\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "print(\"[INFO] Serializing Model\")\n",
    "model.save(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
