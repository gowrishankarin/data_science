{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HELP_PATH = '/Users/shankar/dev/code/ds/studies/data_science/dlcv'\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(IMG_HELP_PATH))\n",
    "from common.preprocessing import ImageToArrayPreprocessor, AspectAwarePreprocessor\n",
    "from common.datasets import SimpleDatasetLoader\n",
    "from common.nn.conv import FCHeadNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"../datasets/flowers17/images\"\n",
    "MODEL = \"flowers17.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the image generator for the data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=30, \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading Images\n"
     ]
    }
   ],
   "source": [
    "# Grab the list of images that we'll be describing, then extract the\n",
    "# class label names from the image paths\n",
    "print(\"[INFO] Loading Images\")\n",
    "imagePaths = list(paths.list_images(DATASET))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "classNames = [str(x) for x in np.unique(classNames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the image preprocessors\n",
    "aap = AspectAwarePreprocessor(224, 224)\n",
    "iap = ImageToArrayPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 500/1360\n",
      "[INFO] processed 1000/1360\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from the disk then scale the raw pixel intensitites\n",
    "# to the range [0, 1]\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap, iap])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data into training and testing splits using 75% of \n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels from integers to vectors\n",
    "trainY = LabelBinarizer().fit_transform(trainY)\n",
    "testY = LabelBinarizer().fit_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 network, ensuring the head FC layer sets are left off\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new head of the network, a set of FC layers followed\n",
    "# by a softmax classifier\n",
    "headModel = FCHeadNet.build(baseModel, len(classNames), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the head FC model on top of the base model -- this will become\n",
    "# the actual model we will train\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all layers in the base model and freeze them so they will\n",
    "# not be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling Model\n"
     ]
    }
   ],
   "source": [
    "# Compile our model (this needs to be done after our setting our layers\n",
    "# to being non-trainable)\n",
    "print(\"[INFO] Compiling Model\")\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head\n",
      "Epoch 1/25\n",
      "31/31 [==============================] - 523s 17s/step - loss: 6.5616 - acc: 0.1900 - val_loss: 1.7633 - val_acc: 0.4000\n",
      "Epoch 2/25\n",
      "31/31 [==============================] - 521s 17s/step - loss: 2.3265 - acc: 0.3236 - val_loss: 1.6202 - val_acc: 0.4765\n",
      "Epoch 3/25\n",
      "31/31 [==============================] - 540s 17s/step - loss: 1.8373 - acc: 0.4284 - val_loss: 1.2419 - val_acc: 0.6029\n",
      "Epoch 4/25\n",
      "31/31 [==============================] - 528s 17s/step - loss: 1.6089 - acc: 0.5108 - val_loss: 0.8957 - val_acc: 0.7471\n",
      "Epoch 5/25\n",
      "31/31 [==============================] - 867s 28s/step - loss: 1.4074 - acc: 0.5478 - val_loss: 0.7453 - val_acc: 0.7971\n",
      "Epoch 6/25\n",
      "31/31 [==============================] - 508s 16s/step - loss: 1.3552 - acc: 0.5818 - val_loss: 0.7732 - val_acc: 0.7618\n",
      "Epoch 7/25\n",
      "31/31 [==============================] - 600s 19s/step - loss: 1.2068 - acc: 0.6087 - val_loss: 0.8156 - val_acc: 0.7353\n",
      "Epoch 8/25\n",
      "31/31 [==============================] - 518s 17s/step - loss: 1.1883 - acc: 0.6351 - val_loss: 0.6097 - val_acc: 0.8088\n",
      "Epoch 9/25\n",
      "31/31 [==============================] - 514s 17s/step - loss: 1.0287 - acc: 0.6633 - val_loss: 0.5761 - val_acc: 0.8147\n",
      "Epoch 10/25\n",
      "26/31 [========================>.....] - ETA: 3:03 - loss: 0.9454 - acc: 0.6968"
     ]
    }
   ],
   "source": [
    "# Train the head of the network for a few epochs (all other layers)\n",
    "# are frozen) -- this will allow the new FC layers to start to become\n",
    "# initialized with actual \"learned\" values versus pure random\n",
    "print(\"[INFO] training head\")\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=32), validation_data=(testX, testY),\n",
    "    epochs=25, steps_per_epoch=len(trainX)//32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the network after initialization \n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), \n",
    "    target_names=classNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "print(\"[INFO] Serializing Model\")\n",
    "model.save(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
