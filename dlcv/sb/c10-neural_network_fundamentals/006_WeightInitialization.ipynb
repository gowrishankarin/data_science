{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Initialization\n",
    "Zeros, Ones and a Defaut Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeros\n",
    "C =0.3423\n",
    "\n",
    "W1 = np.zeros((64, 32))\n",
    "W2 = np.ones((64, 32))\n",
    "W3 = np.ones((64, 32)) * C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform and Normal Distributions\n",
    "**Uniform Distribution**\n",
    "A uniform distribution draws a random value from the range(lower and upper), where every value inside this range has equal probability of being drawn.\n",
    "\n",
    "**Norman Distribution**\n",
    "A normal distribution where we define the probability density for the Gaussian distribution as \n",
    "\\begin{align}\n",
    "p(x) &= \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}}} {e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}}\n",
    "\\end{align}\n",
    "Where $\\mu$ is mean and $\\sigma$ is standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform\n",
    "W2 = np.random.uniform(low=-0.06, high=-.06, size=(64, 32))\n",
    "\n",
    "# Normal\n",
    "W2 = np.random.normal(0.0, 0.05, size=(64, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeCun Uniform and Normal\n",
    "Otherwise efficient backprop, derived from work of LeCun et al\n",
    "\n",
    "$F_{in}$ - fan in, number of inputs to the layer\n",
    "\n",
    "$F_{out}$ - fan out, number of outputs from the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_in = 64\n",
    "F_out = 32\n",
    "limit = np.sqrt(3/float(F_in))\n",
    "\n",
    "# Uniform\n",
    "W1 = np.random.uniform(low = -limit, high = limit, size=(F_in, F_out))\n",
    "\n",
    "# Normal\n",
    "W = np.random.normal(0.0, limit, size=(F_in, F_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glorot/Xavier Uniform and Normal\n",
    "Reference Paper: Understanding the difficulty of training deep feedforward neural networks\n",
    "\n",
    "For normal distribution, limit value is constructed by averaging $F_{in}$ and $F_{out}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_in = 64\n",
    "F_out = 32\n",
    "limit = np.sqrt(6/float(F_in + F_out))\n",
    "\n",
    "# Uniform\n",
    "W1 = np.random.uniform(low = -limit, high = limit, size=(F_in, F_out))\n",
    "\n",
    "# Normal\n",
    "limit = np.sqrt(2/float(F_in + F_out))\n",
    "W = np.random.normal(0.0, limit, size=(F_in, F_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## He et al./Kaiming/MSRA Uniform and Normal Distribution\n",
    "Reference Paper: Deliving Deep into Rectifiers: Surpassing Human Level Performance on ImageNet Classification\n",
    "\n",
    "This is used while training deeper networks using ReLU or PReLU\n",
    "\n",
    "limit = $\\sqrt{\\frac{6}{F_{in}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_in = 64\n",
    "F_out = 32\n",
    "limit = np.sqrt(6 / float(F_in))\n",
    "W = np.random.uniform(low=-limit, high=limit, size=(F_in, F_out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
