{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dlcv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True)\n",
    "\n",
    "def trend(time, slope=0):\n",
    "    return slope * time\n",
    "\n",
    "def seasonal_pattern(season_time):\n",
    "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
    "    return np.where(season_time < 0.1,\n",
    "                    np.cos(season_time * 7 * np.pi),\n",
    "                    1 / np.exp(5 * season_time))\n",
    "\n",
    "def seasonality(time, period, amplitude=1, phase=0):\n",
    "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
    "    season_time = ((time + phase) % period) / period\n",
    "    return amplitude * seasonal_pattern(season_time)\n",
    "\n",
    "def noise(time, noise_level=1, seed=None):\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    return rnd.randn(len(time)) * noise_level\n",
    "\n",
    "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
    "baseline = 10\n",
    "series = trend(time, 0.1)  \n",
    "baseline = 10\n",
    "amplitude = 40\n",
    "slope = 0.05\n",
    "noise_level = 5\n",
    "\n",
    "# Create the series\n",
    "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
    "# Update with noise\n",
    "series += noise(time, noise_level, seed=42)\n",
    "\n",
    "split_time = 1000\n",
    "time_train = time[:split_time]\n",
    "x_train = series[:split_time]\n",
    "time_valid = time[split_time:]\n",
    "x_valid = series[split_time:]\n",
    "\n",
    "window_size = 30\n",
    "batch_size = 32\n",
    "shuffle_buffer_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, shuffle_buffer, batch_size=32):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = windowed_dataset(series, window_size, shuffle_buffer_size, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=5, strides=1, padding=\"causal\", activation=\"relu\", input_shape=[None, 1]),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
    "])\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=['mae'])\n",
    "history = model.fit(train_set, epochs=100, verbose=0, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-07, 0.0001, 0, 20]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183a0c2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = 1e-8 * (10**(np.arange(100) / 20))\n",
    "plt.semilogx(lrs, history.history[\"loss\"])\n",
    "plt.axis([1e-7, 1e-4, 0, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=['mae'])\n",
    "history = model.fit(train_set, verbose=0, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecaster(_model):\n",
    "    forecast = []\n",
    "\n",
    "    for time in range(len(series) - window_size):\n",
    "        forecast.append(_model.predict(series[time:time + window_size][np.newaxis]))\n",
    "    \n",
    "    forecast = forecast[split_time - window_size:]\n",
    "    results = np.array(forecast)[:, 0, 0]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_input to have 3 dimensions, but got array with shape (1, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-308dbf4bfd04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-80464d2453ce>\u001b[0m in \u001b[0;36mforecaster\u001b[0;34m(_model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mforecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dlcv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dlcv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dlcv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dlcv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dlcv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/dlcv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv1d_input to have 3 dimensions, but got array with shape (1, 30)"
     ]
    }
   ],
   "source": [
    "results = forecaster(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_series(time_valid, x_valid)\n",
    "plot_series(time_valid, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mae = history.history['mae']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, mae, 'r')\n",
    "plt.plot(epochs, loss, 'b')\n",
    "plt.title('MAE and Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(\"MAE\", \"Loss\")\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_zoom = epochs[200:]\n",
    "mae_zoom = mae[200:]\n",
    "loss_zoom = loss[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_zoom, mae_zoom, 'r')\n",
    "plt.plot(epochs_zoom, loss_zoom, 'b')\n",
    "plt.title('MAE and Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend([\"MAE\", \"Loss\"])\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
