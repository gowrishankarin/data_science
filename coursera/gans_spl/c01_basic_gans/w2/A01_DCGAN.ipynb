{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional GAN\n",
    "### Goal\n",
    "Implement a Deep Convolutional GAN (DCGAN), a very successful and influential GAN model developed in 2015.\n",
    "\n",
    "*Note: [here](https://arxiv.org/pdf/1511.06434v1.pdf) is the paper if you are interested! It might look dense now, but soon you'll be able to understand many parts of it :)*\n",
    "\n",
    "### Learning Objectives\n",
    "1.   Get hands-on experience making a widely used GAN: Deep Convolutional GAN (DCGAN).\n",
    "2.   Train a powerful generative model.\n",
    "\n",
    "\n",
    "![Generator architecture](images/dcgan-gen.png)\n",
    "\n",
    "Figure: Architectural drawing of a generator from DCGAN from [Radford et al (2016)](https://arxiv.org/pdf/1511.06434v1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features of DCGAN\n",
    "- Use convolutions without pooling layers\n",
    "- Use batchnorm in both the generator and the discriminator\n",
    "- Don't use fully connected hidden layers\n",
    "- Use ReLU actiation in the generator for all layers except for the output, which uses `Tanh` activation\n",
    "- Use LeakyReLU activation in the discriminator for all layers except for the ouput, which does not use an activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "        \n",
    "    def make_gen_block(\n",
    "        self, input_channels, output_channels, \n",
    "        kernel_size=3, stride=2, final_layer=False\n",
    "    ):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                input_channels,\n",
    "                output_channels,\n",
    "                kernel_size=(kernel_size, kernel_size),\n",
    "                stride=stride\n",
    "            ),\n",
    "            nn.BatchNorm2d(output_channels), nn.ReLU() if not final_layer else nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def unsqueeze_noise(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the genertator: Given a noise tensor\n",
    "        returns a copy of that noise with width and height = 1 and channels = z_dim\n",
    "        \n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)\n",
    "    \n",
    "    \n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dim (n_samples, z_dim)\n",
    "    creates a tensor of theat shape filled with random numbers form the normal distribution\n",
    "    '''\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test your make_gen_block() function\n",
    "'''\n",
    "gen = Generator()\n",
    "num_test = 100\n",
    "\n",
    "# Test the hidden block\n",
    "test_hidden_noise = get_noise(num_test, gen.z_dim)\n",
    "test_hidden_block = gen.make_gen_block(10, 20, kernel_size=4, stride=1)\n",
    "print(test_hidden_block)\n",
    "test_uns_noise = gen.unsqueeze_noise(test_hidden_noise)\n",
    "hidden_output = test_hidden_block(test_uns_noise)\n",
    "\n",
    "# Check that it works with other strides\n",
    "test_hidden_block_stride = gen.make_gen_block(20, 20, kernel_size=4, stride=2)\n",
    "\n",
    "test_final_noise = get_noise(num_test, gen.z_dim) * 20\n",
    "test_final_block = gen.make_gen_block(10, 20, final_layer=True)\n",
    "print(test_final_block)\n",
    "test_final_uns_noise = gen.unsqueeze_noise(test_final_noise)\n",
    "final_output = test_final_block(test_final_uns_noise)\n",
    "\n",
    "# Test the whole thing:\n",
    "test_gen_noise = get_noise(num_test, gen.z_dim)\n",
    "test_uns_gen_noise = gen.unsqueeze_noise(test_gen_noise)\n",
    "gen_output = gen(test_uns_gen_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TESTS\n",
    "assert tuple(hidden_output.shape) == (num_test, 20, 4, 4)\n",
    "assert hidden_output.max() > 1\n",
    "assert hidden_output.min() == 0\n",
    "assert hidden_output.std() > 0.2\n",
    "assert hidden_output.std() < 1\n",
    "assert hidden_output.std() > 0.5\n",
    "\n",
    "assert tuple(test_hidden_block_stride(hidden_output).shape) == (num_test, 20, 10, 10)\n",
    "\n",
    "assert final_output.max().item() >= 0.98\n",
    "assert final_output.min().item() <= -0.98\n",
    "\n",
    "assert tuple(gen_output.shape) == (num_test, 1, 28, 28)\n",
    "assert gen_output.std() > 0.5\n",
    "assert gen_output.std() < 0.8\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.min().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_chan=1, hidden_dim=16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n",
    "        )\n",
    "        \n",
    "    def make_disc_block(\n",
    "        self, input_channels, output_channels,\n",
    "        kernel_size=4, stride=2, final_layer=False\n",
    "    ):\n",
    "        \n",
    "        if not final_layer: \n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    input_channels,\n",
    "                    output_channels,\n",
    "                    kernel_size=(kernel_size, kernel_size),\n",
    "                    stride=stride\n",
    "                ),\n",
    "                nn.BatchNorm2d(output_channels), nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    input_channels,\n",
    "                    output_channels,\n",
    "                    kernel_size=(kernel_size, kernel_size),\n",
    "                    stride=stride\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test your make_disc_block() function\n",
    "'''\n",
    "num_test = 100\n",
    "\n",
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "test_images = gen(get_noise(num_test, gen.z_dim))\n",
    "\n",
    "# Test the hidden block\n",
    "test_hidden_block = disc.make_disc_block(1, 5, kernel_size=6, stride=3)\n",
    "hidden_output = test_hidden_block(test_images)\n",
    "\n",
    "# Test the final block\n",
    "test_final_block = disc.make_disc_block(1, 10, kernel_size=2, stride=5, final_layer=True)\n",
    "final_output = test_final_block(test_images)\n",
    "\n",
    "# Test the whole thing:\n",
    "disc_output = disc(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tuple(hidden_output.shape) == (num_test, 5, 8, 8)\n",
    "# Because of the LeakyReLU slope\n",
    "assert -hidden_output.min() / hidden_output.max() > 0.15\n",
    "assert -hidden_output.min() / hidden_output.max() < 0.25\n",
    "assert hidden_output.std() > 0.5\n",
    "assert hidden_output.std() < 1\n",
    "\n",
    "# Test the final block\n",
    "\n",
    "assert tuple(final_output.shape) == (num_test, 10, 6, 6)\n",
    "assert final_output.max() > 1.0\n",
    "assert final_output.min() < -1.0\n",
    "assert final_output.std() > 0.3\n",
    "assert final_output.std() < 0.6\n",
    "\n",
    "# Test the whole thing:\n",
    "\n",
    "assert tuple(disc_output.shape) == (num_test, 1)\n",
    "assert disc_output.std() > 0.25\n",
    "assert disc_output.std() < 0.5\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "\n",
    "# These parameters control the optimizer's momentum, which you can read more about here:\n",
    "# https://distill.pub/2017/momentum/ but you don’t need to worry about it for this course!\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "device = 'cpu'\n",
    "\n",
    "# Transform the image values to be between -1 and 1 \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "disc = Discriminator().to(device)\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\n",
    "\n",
    "# Initialize the weights to normal distribution\n",
    "# with mean 0 and standard deviation 0.02\n",
    "\n",
    "def weights_init(m):\n",
    "    if(isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d)):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if(isinstance(m, nn.BatchNorm2d)):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "test_generator = True\n",
    "gen_loss = False\n",
    "error = False\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Dataloader returns the batches\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        \n",
    "        ## Update Discriminator\n",
    "        disc_opt.zero_grad()\n",
    "        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake = gen(fake_noise)\n",
    "        disc_fake_pred = disc(fake.detach())\n",
    "        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
    "        disc_real_pred = disc(real)\n",
    "        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
    "        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n",
    "        \n",
    "        # Keep track of the average discriminator loss\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "        # Update gradients\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        # Update optimizer\n",
    "        disc_opt.step()\n",
    "        \n",
    "        ## Update Generator\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        disc_fake_pred = disc(fake_2)\n",
    "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        \n",
    "        # Kepp track of the average generator loss\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "        \n",
    "        ## Visualization code ##\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
