{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein GAN - WGAN\n",
    "- Build Wasserstein GAN with Gradient Penalty: WGAN - GP\n",
    "- It solves othe stability issues with the GANs\n",
    "- The special kind of loss function W-loss and Gradient Penalties prevent mode collapse\n",
    "\n",
    "*Fun Fact: Wasserstein is named after a mathematician at Penn State, Leonid Vaseršteĭn. You'll see it abbreviated to W (e.g. WGAN, W-loss, W-distance).*\n",
    "\n",
    "## Generator and Critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0) # Set for testing purposes, please do not change!\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grad_hook():\n",
    "    '''\n",
    "    Function to keep track of gradients for visalization purposes,\n",
    "    which fills the grads list when using model.apply\n",
    "    '''\n",
    "    grads = []\n",
    "    def grad_hook(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            grads.append(m.weight.grad)\n",
    "        return grds, grad_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "        \n",
    "    def make_gen_block(\n",
    "        self, input_channels, output_channels, \n",
    "        kernel_size=3, stride=2, final_layer=False\n",
    "    ):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                input_channels,\n",
    "                output_channels,\n",
    "                kernel_size=(kernel_size, kernel_size),\n",
    "                stride=stride\n",
    "            ),\n",
    "            nn.BatchNorm2d(output_channels), nn.ReLU() if not final_layer else nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def unsqueeze_noise(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the genertator: Given a noise tensor\n",
    "        returns a copy of that noise with width and height = 1 and channels = z_dim\n",
    "        \n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)\n",
    "    \n",
    "    \n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dim (n_samples, z_dim)\n",
    "    creates a tensor of theat shape filled with random numbers form the normal distribution\n",
    "    '''\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, im_chan=1, hidden_dim=16):\n",
    "        super(Critic, self).__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            self.make_critic_block(im_chan, hidden_dim),\n",
    "            self.make_critic_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_critic_block(hidden_dim * 2, 1, final_layer=True),\n",
    "        )\n",
    "        \n",
    "    def make_critic_block(\n",
    "        self, input_channels, output_channels,\n",
    "        kernel_size=4, stride=2, final_layer=False\n",
    "    ):\n",
    "        \n",
    "        if not final_layer: \n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    input_channels,\n",
    "                    output_channels,\n",
    "                    kernel_size=(kernel_size, kernel_size),\n",
    "                    stride=stride\n",
    "                ),\n",
    "                nn.BatchNorm2d(output_channels), nn.LeakyReLU(0.2)\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    input_channels,\n",
    "                    output_channels,\n",
    "                    kernel_size=(kernel_size, kernel_size),\n",
    "                    stride=stride\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def forward(self, image):\n",
    "        critic_pred = self.critic(image)\n",
    "        return critic_pred.view(len(critic_pred), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Initializations\n",
    "Start by setting the parameters:\n",
    "  *   n_epochs: the number of times you iterate through the entire dataset when training\n",
    "  *   z_dim: the dimension of the noise vector\n",
    "  *   display_step: how often to display/visualize the images\n",
    "  *   batch_size: the number of images per forward/backward pass\n",
    "  *   lr: the learning rate\n",
    "  *   beta_1, beta_2: the momentum terms\n",
    "  *   c_lambda: weight of the gradient penalty\n",
    "  *   crit_repeats: number of times to update the critic per generator update - there are more details about this in the *Putting It All Together* section\n",
    "  *   device: the device type\n",
    "\n",
    "You will also load and transform the MNIST dataset to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "z_dim = 64\n",
    "display_step = 50\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "c_lambda = 10\n",
    "crit_repeats = 5\n",
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
    "crit = Critic().to(device)\n",
    "crit_opt = torch.optim.Adam(critic.parameters(), lr=lr)\n",
    "\n",
    "# Initialize the weights to normal distribution\n",
    "# with mean 0 and standard deviation 0.02\n",
    "\n",
    "def weights_init(m):\n",
    "    if(isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d)):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if(isinstance(m, nn.BatchNorm2d)):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "gen = gen.apply(weights_init)\n",
    "crit = crit.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Penalty\n",
    "Calculating GP in 2 steps.  \n",
    " * Compute the gradient wrt the images\n",
    " * Compute the GP given the gradient\n",
    " \n",
    "a. The gradient is created by first creating a mixed image  \n",
    "b. This is done by weighing the fake and real image using epsilon and then adding together  \n",
    "c. Once the interermediate image is available, critic's output of the images is obtained.  \n",
    "d. Compute the gradient of the critic score's on the mixed images(output) wrt the pixels of the mixed images  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(crit, real, fake, epsilon):\n",
    "    # Mix the images together\n",
    "    mixed_images = real * epsilon + fake * (1 - epsilon)\n",
    "    \n",
    "    # Calculate the critic's scores on the mixed images\n",
    "    mixed_scores = crit(mixed_images)\n",
    "    \n",
    "    # Take the gradient of the scores wrt the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=mixed_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_gradient(image_shape):\n",
    "    real = torch.randn(*image_shape, device=device) + 1\n",
    "    fake = torch.randn(*image_shape, device=device) + 1\n",
    "    epsilon_shape = [1 for _ in image_shape]\n",
    "    epsilon_shape[0] = image_shape[0]\n",
    "    epsilon = torch.randn(epsilon_shape, device=device).requires_grad_()\n",
    "    gradient = get_gradient(crit, real, fake, epsilon)\n",
    "    assert tuple(gradient.shape) == image_shape\n",
    "    assert gradient.max() > 0\n",
    "    assert gradient.min() < 0\n",
    "    return gradient\n",
    "\n",
    "gradient = test_get_gradient((256, 1, 28, 28))\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Penalty**.  \n",
    "- Calculate the magnitude of each image's gradient\n",
    "- The magnitude of a gradient is also called the norm\n",
    "- Calculate the penalty by squaring the distance between each magnitude and the ideal norm of 1 and taking the mean of all the squared distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    # Flatten the gradients so that each row captures one image\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "    # Calculate the magnitude of every row\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    # Penalize the mean squared distance of the gradient norms from 1\n",
    "    penalty = ((1 - gradient_norm).mean())**2\n",
    "    \n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gradient_penalty(image_shape):\n",
    "    bad_gradient = torch.zeros(*image_shape)\n",
    "    bad_gradient_penalty = gradient_penalty(bad_gradient)\n",
    "    assert torch.isclose(bad_gradient_penalty, torch.tensor(1.0))\n",
    "    \n",
    "    image_size = torch.prod(torch.Tensor(image_shape[1:]))\n",
    "    good_gradient = torch.ones(*image_shape) / torch.sqrt(image_size)\n",
    "    good_gradient_penalty = gradient_penalty(good_gradient)\n",
    "    assert torch.isclose(good_gradient_penalty, torch.tensor(0.))\n",
    "    \n",
    "    random_gradient = test_get_gradient(image_shape)\n",
    "    random_gradient_penalty = gradient_penalty(random_gradient)\n",
    "    \n",
    "    assert torch.abs(random_gradient_penalty - 1) < 0.1\n",
    "    \n",
    "test_gradient_penalty((256, 1, 28, 29))\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses\n",
    "- Calculate the loss for the generator and critic\n",
    "- For generator, the loss is calculated by maximizing the critic's prediction on the generator's fake image\n",
    "- The argument has the score for all fake images in the batch, but you will use the mean of the them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(crit_fake_pred):\n",
    "    gen_loss = -crit_fake_pred.mean()\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isclose(\n",
    "    get_gen_loss(torch.tensor(1.0)), torch.tensor(-1.0)\n",
    ")\n",
    "\n",
    "assert torch.isclose(\n",
    "    get_gen_loss(torch.rand(10000)), torch.tensor(-0.5), 0.05\n",
    ")\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crit_loss(crit_fake_pred, crit_real_pred, gp, c_lambda):\n",
    "    crit_loss = gp * c_lambda + (-crit_real_pred + crit_fake_pred).mean()\n",
    "    return crit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isclose(\n",
    "    get_crit_loss(torch.tensor(1.), torch.tensor(2.), torch.tensor(3.), 0.1),\n",
    "    torch.tensor(-0.7)\n",
    ")\n",
    "assert torch.isclose(\n",
    "    get_crit_loss(torch.tensor(20.), torch.tensor(-20.), torch.tensor(2.), 10),\n",
    "    torch.tensor(60.)\n",
    ")\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cur_step = 0\n",
    "generator_losses = []\n",
    "critic_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "        \n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(crit_repeats):\n",
    "            crit_opt.zero_grad()\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            crit_fake_pred = crit(fake.detach())\n",
    "            crit_real_pred = crit(real)\n",
    "            \n",
    "            epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "            gradient = get_gradient(crit, real, fake.detach(), epsilon)\n",
    "            gp = gradient_penalty(gradient)\n",
    "            crit_loss = get_crit_loss(crit_fake_pred, crit_real_pred, gp, c_lambda)\n",
    "            \n",
    "            # Keep track of the average critic loss in this batch\n",
    "            mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "            \n",
    "            # Update Grdients\n",
    "            crit_loss.backward(retain_graph=True)\n",
    "            \n",
    "            # Update Optimizer\n",
    "            crit_opt.step()\n",
    "        critic_losses += [mean_iteration_critic_loss]\n",
    "        \n",
    "        ## Update Generator\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        crit_fake_pred = crit(fake_2)\n",
    "        \n",
    "        gen_loss = get_gen_loss(crit_fake_pred)\n",
    "        gen_loss.backward()\n",
    "        \n",
    "        gen_opt.step()\n",
    "        \n",
    "        generator_losses += [gen_loss.item()]\n",
    "        \n",
    "        ### Visualization code ###\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "            crit_mean = sum(critic_losses[-display_step:]) / display_step\n",
    "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
    "            show_tensor_images(fake)\n",
    "            show_tensor_images(real)\n",
    "            step_bins = 20\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Critic Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
