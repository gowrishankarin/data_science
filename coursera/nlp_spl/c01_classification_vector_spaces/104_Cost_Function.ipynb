{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost(Loss) Function for Binary Classification Explained\n",
    "\n",
    "The key challenge in any machine learning problem is to minimize the difference between the actual from the predicted entity.\n",
    "ie What is the probablity of rain tomorrow(predicted) and whether it rained(actual).\n",
    "\n",
    "- How one can represent this emprically?\n",
    "- Let us y_actual is the actual event\n",
    "- Let y_predicted is the predicted event\n",
    "- **y_actual** is unknown and **y_predicted** is a function of various events and attributes.\n",
    "- Further, let us simplify **y_actual** and **y_predicted** to **y** and **ùë¶^** respectively for rich representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplifying the Loss Function\n",
    "- Loss functions indicates how much the predicted probability is deviated from the actual event.\n",
    "- Let us remember, sum of all probabilities is 1\n",
    "- Let us say, it rained then y(y_actual) is 1\n",
    "- Based on various events and attributes, ùë¶^(y_predicted) is calculated as 0.78\n",
    "- Then the loss or error is y - ùë¶^, which is 0.22\n",
    "\n",
    "**The Goal**  \n",
    "The goal of any machine learning problem is to minimize the erro to achieve maximum accuracy or predictability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function for a Logistic Regression Problem\n",
    "- Logistic Regression is nothing but a classification problem, for example whether it rained or not?\n",
    "- The loss function used for Logistic Regression is Log Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function for a single training example is\n",
    "$$ Loss = -1 \\times \\left( y\\log (\\hat{y}) + (1-y)\\log (1-\\hat{y}) \\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us form matrix to understand the significance of this equation, there are 4 scenarios\n",
    "- When the model predicts close to 1(ùë¶^) and the actual is 1(y), ie Model predicted 0.999 for rain and it rained\n",
    "- When the model predicts close to 0(ùë¶^) and the actual is 0(y), ie Model predicted 0.001 for rain and it rained\n",
    "- When the model predicts close to 1(ùë¶^) and the actual is 0(y), ie Model predicted 0.999 for rain and it did not rain\n",
    "- When the model predicts close to 0(ùë¶^) and the actual is 1(y), ie Model predicted 0.001 for rain and it did not rain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|$y_{i}$   \t|$\\hat{y_{i}}$   \t|   \t|Loss   \t|   \t|\n",
    "|:-:\t|:-:\t|:-:\t|:-:\t|:-:\t|\n",
    "|1   \t|0.999   \t|   \t|0.001   \t|   \t|\n",
    "|0   \t|0.001   \t|   \t|0.001   \t|   \t|\n",
    "|0   \t|0.999   \t|   \t|6.90   \t|   \t|\n",
    "|1   \t|0.001   \t|   \t|6.90   \t|   \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above matrix shows the Log Loss function has the ability to penalize by maximizing the error when the predictions are wrong. Similarly, reduce the error when the predictions are right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the Cost Function for more Observations\n",
    "Let us say, our rain prediction algorithms are for more than 1 one day or a series of days. Then the equation evolves as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss for 3 days can be written as follows\n",
    "\n",
    "$$ Loss_{day_1} = -1 \\times \\left( y_{day_1}\\log (\\hat{y_{day_1}}) + (1-y_{day_1})\\log (1-\\hat{y_{day_1}}) \\right)$$\n",
    "$$ Loss_{day_2} = -1 \\times \\left( y_{day_2}\\log (\\hat{y_{day_2}}) + (1-y_{day_2})\\log (1-\\hat{y_{day_2}}) \\right)$$\n",
    "$$ Loss_{day_3} = -1 \\times \\left( y_{day_3}\\log (\\hat{y_{day_3}}) + (1-y_{day_3})\\log (1-\\hat{y_{day_3}}) \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then the net loss is the average of 3 days loss, ie\n",
    "$$ Net Loss = \\frac{1} 3 \\times (Loss_{day_1} + Loss_{day_2} + Loss_{day_3})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider,\n",
    "- $n$ is the number of days for which the rain prediction is made\n",
    "- $y_{i}$ is the actual event happened for the ith day\n",
    "- $\\hat{y_{i}}$ is the predicted probability of the event for the ith day\n",
    "\n",
    "then the equation transforms as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Net Loss = -\\frac{1}{n} \\sum_{i=1}^n y^{(i)}\\log (\\hat{y_{i}}) + (1-y^{(i)})\\log (1-\\hat{y_{i}}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
