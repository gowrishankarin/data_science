{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Language Model\n",
    "- Calculate n-gram probability by counting frequencies of n-grams and n-gram prefixes in the training dataset\n",
    "- Store n-gram frequencies in a dictionary\n",
    "- Build count matrix that keeps counts of (n-1)-gram prefix followed by all possible last words in the vocabulary\n",
    "- Check retrieve and update counts of n-grams in the word count dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_counts = {\n",
    "    ('i', 'am', 'happy'): 2,\n",
    "    ('am', 'happy', 'because'): 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of n-gram ('i', 'am', 'happy'): 2\n"
     ]
    }
   ],
   "source": [
    "# Get count for an n-gram tuple\n",
    "print(f\"count of n-gram {('i', 'am', 'happy')}: {n_gram_counts[('i', 'am', 'happy')]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of n-gram ('i', 'am', 'happy'): 2\n",
      "n-gram ('i', 'am', 'learning') missing\n",
      "n-gram ('i', 'am', 'learning') found\n"
     ]
    }
   ],
   "source": [
    "# get count for an n-gram tuple\n",
    "print(f\"count of n-gram {('i', 'am', 'happy')}: {n_gram_counts[('i', 'am', 'happy')]}\")\n",
    "\n",
    "# check if n-gram is present in the dictionary\n",
    "if ('i', 'am', 'learning') in n_gram_counts:\n",
    "    print(f\"n-gram {('i', 'am', 'learning')} found\")\n",
    "else:\n",
    "    print(f\"n-gram {('i', 'am', 'learning')} missing\")\n",
    "\n",
    "# update the count in the word count dictionary\n",
    "n_gram_counts[('i', 'am', 'learning')] = 1\n",
    "if ('i', 'am', 'learning') in n_gram_counts:\n",
    "    print(f\"n-gram {('i', 'am', 'learning')} found\")\n",
    "else:\n",
    "    print(f\"n-gram {('i', 'am', 'learning')} missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', 'am', 'happy', 'because')\n"
     ]
    }
   ],
   "source": [
    "# concatenate tuple for prefix and tuple with the last word to create the n_gram\n",
    "prefix = ('i', 'am', 'happy')\n",
    "word = 'because'\n",
    "\n",
    "# note here the syntax for creating a tuple for a single word\n",
    "n_gram = prefix + (word,)\n",
    "print(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_n_gram(tokenized_sentence, n):\n",
    "    \n",
    "    # Note that the last position of i is 3rd to the end\n",
    "    n_grams = [tuple(tokenized_sentence[i:i+n]) for i in range(len(tokenized_sentence) - (n-1))]\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = ['i', 'am', 'happy', 'because', 'i', 'am', 'learning', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_pass_trigram_count_matrix(corpus):\n",
    "    # \n",
    "    two_grams = sentence_to_n_gram(tokenized_sentence, 2)\n",
    "    three_grams = sentence_to_n_gram(tokenized_sentence, 3)\n",
    "    \n",
    "    bigrams = list(set(two_grams))\n",
    "    next_words = tokenized_sentence[2:]\n",
    "\n",
    "    next_word_list = {a_word: [] for a_word in next_words}\n",
    "    for a_word in next_words:\n",
    "        for a_bi_gram in bigrams:\n",
    "            if(a_bi_gram + (a_word,) in three_grams):\n",
    "                next_word_list[a_word].append(1)\n",
    "            else:\n",
    "                next_word_list[a_word].append(0)\n",
    "     \n",
    "    df = pd.DataFrame(next_word_list)\n",
    "    df[\"bigrams\"] = bigrams\n",
    "    df = df.set_index(\"bigrams\")\n",
    "    \n",
    "    return bigrams, list(set(corpus)), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams, vocab, count_matrix = single_pass_trigram_count_matrix(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('happy', 'because'),\n",
       " ('am', 'learning'),\n",
       " ('i', 'am'),\n",
       " ('because', 'i'),\n",
       " ('learning', '.'),\n",
       " ('am', 'happy')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy', 'i', 'learning', 'am', 'because', '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>happy</th>\n",
       "      <th>because</th>\n",
       "      <th>i</th>\n",
       "      <th>am</th>\n",
       "      <th>learning</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigrams</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(happy, because)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(am, learning)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(i, am)</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(because, i)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(learning, .)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(am, happy)</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  happy  because  i  am  learning  .\n",
       "bigrams                                             \n",
       "(happy, because)      0        0  1   0         0  0\n",
       "(am, learning)        0        0  0   0         0  1\n",
       "(i, am)               1        0  0   0         1  0\n",
       "(because, i)          0        0  0   1         0  0\n",
       "(learning, .)         0        0  0   0         0  0\n",
       "(am, happy)           0        1  0   0         0  0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  happy  because    i   am  learning    .\n",
      "bigrams                                                  \n",
      "(happy, because)    0.0      0.0  1.0  0.0       0.0  0.0\n",
      "(am, learning)      0.0      0.0  0.0  0.0       0.0  1.0\n",
      "(i, am)             0.5      0.0  0.0  0.0       0.5  0.0\n",
      "(because, i)        0.0      0.0  0.0  1.0       0.0  0.0\n",
      "(learning, .)       NaN      NaN  NaN  NaN       NaN  NaN\n",
      "(am, happy)         0.0      1.0  0.0  0.0       0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "row_sums = count_matrix.sum(axis=1)\n",
    "prob_matrix = count_matrix.div(row_sums, axis=0)\n",
    "\n",
    "print(prob_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram: ('i', 'am')\n",
      "word: happy\n",
      "trigram_probability: 0.5\n"
     ]
    }
   ],
   "source": [
    "# find the probability of a trigram in the probability matrix\n",
    "trigram = ('i', 'am', 'happy')\n",
    "\n",
    "# find the prefix bigram \n",
    "bigram = trigram[:-1]\n",
    "print(f'bigram: {bigram}')\n",
    "\n",
    "# find the last word of the trigram\n",
    "word = trigram[-1]\n",
    "print(f'word: {word}')\n",
    "\n",
    "# we are using the pandas dataframes here, column with vocabulary word comes first, row with the prefix bigram second\n",
    "trigram_probability = prob_matrix[word][bigram]\n",
    "print(f'trigram_probability: {trigram_probability}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in vocabulary starting with prefix: ha\n",
      "\n",
      "happy\n",
      "have\n"
     ]
    }
   ],
   "source": [
    "# lists all words in vocabulary starting with a given prefix\n",
    "vocabulary = ['i', 'am', 'happy', 'because', 'learning', '.', 'have', 'you', 'seen','it', '?']\n",
    "starts_with = 'ha'\n",
    "\n",
    "print(f'words in vocabulary starting with prefix: {starts_with}\\n')\n",
    "for word in vocabulary:\n",
    "    if word.startswith(starts_with):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model Evaluation\n",
    "**Train/Validation/Test Splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_validation_test_split(data, train_percent, validation_percent):\n",
    "    random.seed(87)\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    train_size = int(len(data) * train_percent / 100)\n",
    "    train_data = data[0:train_size]\n",
    "    \n",
    "    validation_size = int(len(data) * validation_percent / 100)\n",
    "    validation_data = data[train_size:train_size + validation_size]\n",
    "    \n",
    "    test_data = data[train_size + validation_size:]\n",
    "    \n",
    "    return train_data, validation_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 80/10/10:\n",
      " train data:[28, 76, 5, 0, 62, 29, 54, 95, 88, 58, 4, 22, 92, 14, 50, 77, 47, 33, 75, 68, 56, 74, 43, 80, 83, 84, 73, 93, 66, 87, 9, 91, 64, 79, 20, 51, 17, 27, 12, 31, 67, 81, 7, 34, 45, 72, 38, 30, 16, 60, 40, 86, 48, 21, 70, 59, 6, 19, 2, 99, 37, 36, 52, 61, 97, 44, 26, 57, 89, 55, 53, 85, 3, 39, 10, 71, 23, 32, 25, 8]\n",
      " validation data:[78, 65, 63, 11, 49, 98, 1, 46, 15, 41]\n",
      " test data:[90, 96, 82, 42, 35, 13, 69, 24, 94, 18]\n",
      "\n",
      "split 98/1/1:\n",
      " train data:[66, 23, 29, 28, 52, 87, 70, 13, 15, 2, 62, 43, 82, 50, 40, 32, 30, 79, 71, 89, 6, 10, 34, 78, 11, 49, 39, 42, 26, 46, 58, 96, 97, 8, 56, 86, 33, 93, 92, 91, 57, 65, 95, 20, 72, 3, 12, 9, 47, 37, 67, 1, 16, 74, 53, 99, 54, 68, 5, 18, 27, 17, 48, 36, 24, 45, 73, 19, 41, 59, 21, 98, 0, 31, 4, 85, 80, 64, 84, 88, 25, 44, 61, 22, 60, 94, 76, 38, 77, 81, 90, 69, 63, 7, 51, 14, 55, 83]\n",
      " validation data:[35]\n",
      " test data:[75]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [x for x in range (0, 100)]\n",
    "train_data, validation_data, test_data = train_validation_test_split(data, 80, 10)\n",
    "print(\"split 80/10/10:\\n\",f\"train data:{train_data}\\n\", f\"validation data:{validation_data}\\n\", \n",
    "      f\"test data:{test_data}\\n\")\n",
    "\n",
    "train_data, validation_data, test_data = train_validation_test_split(data, 98, 1)\n",
    "print(\"split 98/1/1:\\n\",f\"train data:{train_data}\\n\", f\"validation data:{validation_data}\\n\", \n",
    "      f\"test data:{test_data}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity\n",
    "\n",
    "$$\n",
    "PP\\left(W\\right) = \\sqrt[m] {\\prod^m_{i=1} \\frac{1}{P\\left(w_i|w_{i-1}\\right)}}\n",
    "$$\n",
    "Remember from calculus\n",
    "$$\n",
    "\\sqrt[m]\\frac{1}{x} = x^{-\\frac{1}{M}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316.22776601683796\n"
     ]
    }
   ],
   "source": [
    "p = 10 ** (-250)\n",
    "M = 100\n",
    "perplexity = p** (-1 / M)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
