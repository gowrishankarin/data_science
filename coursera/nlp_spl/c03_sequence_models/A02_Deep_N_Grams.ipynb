{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep N-Grams\n",
    "- How to convert a line to text into a tensor\n",
    "- Create an iterator to feed data to the model\n",
    "- Define a GRU model using `trax`\n",
    "- Train the model using `trax`\n",
    "- Compute the accuracy of your model using perplexity\n",
    "- Predict using your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "- Predict the next set of characters using previous characters\n",
    "- Convert a line of text into a tensor\n",
    "- Create a generator to feed data into the model\n",
    "- Train a neural network in order to predict the new set of characters of defined length\n",
    "- Use embeddings for each character and feed them as inputs to your model\n",
    "    - Many natural language tasks rely on using embeddings for predictions\n",
    "- Your model will convert each character to its embedding, \n",
    "    - run the embeddings through a GRU and \n",
    "        - run it through a linear layer to predict the next set of characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further...  \n",
    "- Get the embeddings\n",
    "- Stack the embeddings on top of each other\n",
    "- Run them through two layers with a relu activation in the middle\n",
    "- Compute the softmax\n",
    "\n",
    "To predict the next character...   \n",
    "- Use the softmax output and identify the word with the highest probability\n",
    "- The word with the highest probability is the prediction for the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shankar/dev/tools/anaconda3/envs/trax/lib/python3.8/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import trax\n",
    "import trax.fastmath.numpy as np\n",
    "import pickle\n",
    "import numpy\n",
    "import random as rnd\n",
    "from trax import fastmath\n",
    "from trax import layers as tl\n",
    "\n",
    "# Set random seed\n",
    "trax.supervised.trainer_lib.init_random_number_generators(32)\n",
    "rnd.seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = 'data/'\n",
    "lines = []\n",
    "for filename in os.listdir(dirname):\n",
    "    with open(os.path.join(dirname, filename)) as files:\n",
    "        for line in files:\n",
    "            pure_line = line.strip()\n",
    "            if(pure_line):\n",
    "                lines.append(pure_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 125097\n",
      "Sample line at position 0 THE MERRY WIVES OF WINDSOR\n",
      "Sample line at position 999 you.\n"
     ]
    }
   ],
   "source": [
    "n_lines = len(lines)\n",
    "print(f\"Number of lines: {n_lines}\")\n",
    "print(f\"Sample line at position 0 {lines[0]}\")\n",
    "print(f\"Sample line at position 999 {lines[999]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 125097\n",
      "Sample line at position 0 the merry wives of windsor\n",
      "Sample line at position 999 you.\n"
     ]
    }
   ],
   "source": [
    "# go through each line\n",
    "for i, line in enumerate(lines):\n",
    "    # convert to all lowercase\n",
    "    lines[i] = line.lower()\n",
    "\n",
    "print(f\"Number of lines: {n_lines}\")\n",
    "print(f\"Sample line at position 0 {lines[0]}\")\n",
    "print(f\"Sample line at position 999 {lines[999]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines for training: 124097\n",
      "Number of lines for validation: 1000\n"
     ]
    }
   ],
   "source": [
    "# Create a holdout validation set\n",
    "eval_lines = lines[-1000:]\n",
    "lines = lines[:-1000]\n",
    "\n",
    "print(f'Number of lines for training: {len(lines)}')\n",
    "print(f'Number of lines for validation: {len(eval_lines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord('a'): 97\n",
      "ord('b'): 98\n",
      "ord('c'): 99\n",
      "ord(' '): 32\n",
      "ord('x'): 120\n",
      "ord('y'): 121\n",
      "ord('z'): 122\n",
      "ord('1'): 49\n",
      "ord('2'): 50\n",
      "ord('3'): 51\n"
     ]
    }
   ],
   "source": [
    "# View the unique unicode integer associated with each character\n",
    "print(f\"ord('a'): {ord('a')}\")\n",
    "print(f\"ord('b'): {ord('b')}\")\n",
    "print(f\"ord('c'): {ord('c')}\")\n",
    "print(f\"ord(' '): {ord(' ')}\")\n",
    "print(f\"ord('x'): {ord('x')}\")\n",
    "print(f\"ord('y'): {ord('y')}\")\n",
    "print(f\"ord('z'): {ord('z')}\")\n",
    "print(f\"ord('1'): {ord('1')}\")\n",
    "print(f\"ord('2'): {ord('2')}\")\n",
    "print(f\"ord('3'): {ord('3')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function ord in module builtins:\n",
      "\n",
      "ord(c, /)\n",
      "    Return the Unicode code point for a one-character string.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a function to transform a single line to its unicode string array\n",
    "- The output string array is the tensor\n",
    "- Special characters are used to represent the end of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_tensor(line, EOS_int=1):\n",
    "    tensor = []\n",
    "    for c in line:\n",
    "        c_int = ord(c)\n",
    "        tensor.append(c_int)\n",
    "    tensor.append(EOS_int)\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97, 98, 99, 32, 120, 121, 122, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_to_tensor('abc xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Generator\n",
    "- Build a batch generator that takes in a text and returns a batch of text lines\n",
    "- The generator converts the text lines into numpy array of integers padded by zeros\n",
    "- Padding ensures all arrays have the same length\n",
    "- Length of the array is equal to the length of the longest sentence\n",
    "- Using `next` operator, the sentence arrays can be iterated\n",
    "- Generator returns a bactch with 3 parts tuple: (inputs, targets, mask)\n",
    "- The inputs and targets are identifcal\n",
    "- The second column will be used to evaluate your predictions\n",
    "- Mask is 1 for non-padding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, max_length, data_lines, lines_to_tensor=line_to_tensor, shuffle=True):\n",
    "    \n",
    "    # Initialize the index that points to the current position in the lines index array\n",
    "    index = 0\n",
    "    \n",
    "    # Initialize the list that will contain the current batch\n",
    "    cur_batch = []\n",
    "    \n",
    "    # Count the number of lines in data_lines\n",
    "    num_lines = len(data_lines)\n",
    "    \n",
    "    # Create an array with the indexes of data_lines that can be shuffled\n",
    "    lines_index = [*range(num_lines)]\n",
    "    \n",
    "    # Shuffle line indexes of if shuffle is set to True\n",
    "    if(shuffle):\n",
    "        rnd.shuffle(lines_index)\n",
    "        \n",
    "    while(True):\n",
    "        # if the index isgrater or equal that to the number of lines in data_lines\n",
    "        if(index >= len(data_lines)):\n",
    "            index = 0\n",
    "            if(shuffle):\n",
    "                rnd.shuffle(lines_index)\n",
    "        \n",
    "        # Get a line at the `lines_index[index]` position in data_lines\n",
    "        line = data_lines[lines_index[index]]\n",
    "        \n",
    "        # If the length of the line is less than max_length\n",
    "        if(len(line) < max_length):\n",
    "            cur_batch.append(line)\n",
    "            \n",
    "        index += 1\n",
    "        \n",
    "        if(len(cur_batch) == batch_size):\n",
    "            batch = []\n",
    "            mask = []\n",
    "            \n",
    "            # Go thru each line in curr_batch\n",
    "            for li in cur_batch:\n",
    "                tensor = line_to_tensor(li)\n",
    "                \n",
    "                # Create a list of zeros to represent the padding\n",
    "                # so that the tensor plus padding will have length `max_length`\n",
    "                pad = [0] * (max_length - len(tensor))\n",
    "                \n",
    "                # Combine the tensor plus pad\n",
    "                tensor_pad = tensor + pad\n",
    "                batch.append(tensor_pad)\n",
    "                \n",
    "                example_mask = [1 if a_num != 0 else 0 for a_num in tensor_pad]\n",
    "                mask.append(example_mask)\n",
    "                \n",
    "            # Convert the batch (data type list) to a trax's numpy array\n",
    "            batch_np_arr = np.array(batch)\n",
    "            mask_np_arr = np.array(mask)\n",
    "            \n",
    "            yield batch_np_arr, batch_np_arr, mask_np_arr\n",
    "            \n",
    "            cur_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
       "              [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32),\n",
       " DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
       "              [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32),\n",
       " DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out your data generator\n",
    "tmp_lines = ['12345678901', #length 11\n",
    "             '123456789', # length 9\n",
    "             '234567890', # length 9\n",
    "             '345678901'] # length 9\n",
    "\n",
    "# Get a batch size of 2, max length 10\n",
    "tmp_data_gen = data_generator(batch_size=2, \n",
    "                              max_length=10, \n",
    "                              data_lines=tmp_lines,\n",
    "                              shuffle=False)\n",
    "\n",
    "# get one batch\n",
    "tmp_batch = next(tmp_data_gen)\n",
    "\n",
    "# view the batch\n",
    "tmp_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeating Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "infinite_data_generator = itertools.cycle(\n",
    "    data_generator(batch_size=2, max_length=10, data_lines=tmp_lines)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)), (DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)), (DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [51, 52, 53, 54, 55, 56, 57, 48, 49,  1]], dtype=int32), DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [51, 52, 53, 54, 55, 56, 57, 48, 49,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)), (DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)), (DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49,  1],\n",
      "             [51, 52, 53, 54, 55, 56, 57, 48, 49,  1]], dtype=int32), DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49,  1],\n",
      "             [51, 52, 53, 54, 55, 56, 57, 48, 49,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)), (DeviceArray([[50, 51, 52, 53, 54, 55, 56, 57, 48,  1],\n",
      "             [49, 50, 51, 52, 53, 54, 55, 56, 57,  1]], dtype=int32), DeviceArray([[50, 51, 52, 53, 54, 55, 56, 57, 48,  1],\n",
      "             [49, 50, 51, 52, 53, 54, 55, 56, 57,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)), (DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)), (DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49,  1],\n",
      "             [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)), (DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [51, 52, 53, 54, 55, 56, 57, 48, 49,  1]], dtype=int32), DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
      "             [51, 52, 53, 54, 55, 56, 57, 48, 49,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)), (DeviceArray([[50, 51, 52, 53, 54, 55, 56, 57, 48,  1],\n",
      "             [51, 52, 53, 54, 55, 56, 57, 48, 49,  1]], dtype=int32), DeviceArray([[50, 51, 52, 53, 54, 55, 56, 57, 48,  1],\n",
      "             [51, 52, 53, 54, 55, 56, 57, 48, 49,  1]], dtype=int32), DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32))]\n"
     ]
    }
   ],
   "source": [
    "ten_lines = [next(infinite_data_generator) for _ in range(10)]\n",
    "print(ten_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the GRU Model\n",
    "- Initialize the model with input and output tensors\n",
    "- GRULM, Using Trax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRULM(vocab_size=256, d_model=512, n_layers=2, mode='train'):\n",
    "    model = tl.Serial(\n",
    "        tl.ShiftRight(n_shifts=1, mode=mode),\n",
    "        tl.Embedding(vocab_size, d_model),\n",
    "        [tl.GRU(n_units=d_model) for i in range(n_layers)],\n",
    "        tl.Dense(vocab_size),\n",
    "        tl.LogSoftmax()\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  ShiftRight(1)\n",
      "  Embedding_256_512\n",
      "  GRU_512\n",
      "  GRU_512\n",
      "  Dense_256\n",
      "  LogSoftmax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# testing your model\n",
    "model = GRULM()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_used_lines(lines, max_length):\n",
    "    n_lines = 0\n",
    "    for l in lines:\n",
    "        if(len(l) <= max_length):\n",
    "            n_lines += 1\n",
    "    return n_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used lines from the dataset: 25934\n",
      "Batch size (a power of 2): 32\n",
      "Number of steps to cover one epoch: 810\n"
     ]
    }
   ],
   "source": [
    "num_used_lines = n_used_lines(lines, 32)\n",
    "print('Number of used lines from the dataset:', num_used_lines)\n",
    "print('Batch size (a power of 2):', int(batch_size))\n",
    "steps_per_epoch = int(num_used_lines/batch_size)\n",
    "print('Number of steps to cover one epoch:', steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "def train_model(\n",
    "    model, data_generator, batch_size=32, max_length=64,\n",
    "    lines=lines, eval_lines=eval_lines, n_steps=1, output_dir='model/'\n",
    "):\n",
    "    bare_train_generator = data_generator(\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length,\n",
    "        data_lines=lines,\n",
    "        shuffle=False\n",
    "    )\n",
    "    infinite_train_generator = itertools.cycle(\n",
    "        data_generator(\n",
    "            batch_size=batch_size,\n",
    "            max_length=max_length,\n",
    "            data_lines=lines,\n",
    "            shuffle=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    bare_eval_generator = data_generator(\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length,\n",
    "        data_lines=eval_lines,\n",
    "        shuffle=False\n",
    "    )\n",
    "    infinite_eval_generator = itertools.cycle(\n",
    "        data_generator(\n",
    "            batch_size=batch_size,\n",
    "            max_length=max_length,\n",
    "            data_lines=eval_lines,\n",
    "            shuffle=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    train_task = training.TrainTask(\n",
    "        labeled_data=infinite_train_generator,\n",
    "        loss_layer=tl.CrossEntropyLoss(),\n",
    "        optimizer= trax.optimizers.Adam(0.0005)\n",
    "    )\n",
    "    eval_task = training.EvalTask(\n",
    "        labeled_data=infinite_eval_generator,\n",
    "        metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
    "        n_eval_batches=3\n",
    "    )\n",
    "    training_loop = training.Loop(\n",
    "        model,\n",
    "        train_task,\n",
    "        eval_task=eval_task,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    training_loop.run(n_steps=n_steps)\n",
    "    \n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      1: train CrossEntropyLoss |  5.54323053\n",
      "Step      1: eval  CrossEntropyLoss |  5.48575592\n",
      "Step      1: eval          Accuracy |  0.16526215\n"
     ]
    }
   ],
   "source": [
    "training_loop = train_model(GRULM(), data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(preds, target):\n",
    "    total_log_ppx = np.sum(preds * tl.one_hot(target, preds.shape[-1]), axis=-1)\n",
    "    non_pad = 1.0 - np.equal(target, 0)\n",
    "    ppx = non_pad * total_log_ppx\n",
    "    \n",
    "    log_ppx = np.sum(ppx) / np.sum(non_pad)\n",
    "    \n",
    "    return -log_ppx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Language with our Model\n",
    "$$ f(z) = {1\\over{\\beta}}e^{(-z+e^{(-z)})} $$\n",
    "\n",
    "where: $$ z = {(x - \\mu)\\over{\\beta}}$$\n",
    "\n",
    "The maximum value, which is what we choose as the prediction in the last step of a Recursive Neural Network `RNN` we are using for text generation, in a sample of a random variable following an exponential distribution approaches the Gumbel distribution when the sample increases asymptotically. For that reason, the Gumbel distribution is used to sample from a categorical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "LayerError",
     "evalue": "Exception passing through layer Serial (in pure_fn):\n  layer created in file [...]/<ipython-input-32-fdc509f12b4f>, line 2\n  layer input shapes: ShapeDtype{shape:(1, 32), dtype:int32}\n\n  File [...]/trax/layers/combinators.py, line 88, in forward\n    outputs, s = layer.pure_fn(inputs, w, s, rng, use_cache=True)\n\nLayerError: Exception passing through layer Embedding_256_512 (in pure_fn):\n  layer created in file [...]/<ipython-input-32-fdc509f12b4f>, line 4\n  layer input shapes: ShapeDtype{shape:(1, 32), dtype:int32}\n\n  File [...]/trax/layers/core.py, line 150, in forward\n    return jnp.take(self.weights, x, axis=0)\n\n  File [...]/jax/numpy/lax_numpy.py, line 3422, in take\n    return lax.gather(a, indices[..., None], dimension_numbers=dnums,\n\n  File [...]/jax/lax/lax.py, line 807, in gather\n    return gather_p.bind(\n\n  File [...]/site-packages/jax/core.py, line 276, in bind\n    return self.impl(*args, **kwargs)\n\n  File [...]/jax/interpreters/xla.py, line 224, in apply_primitive\n    compiled_fun = xla_primitive_callable(prim, *unsafe_map(arg_spec, args), **params)\n\n  File [...]/jax/interpreters/xla.py, line 257, in xla_primitive_callable\n    built_c = primitive_computation(prim, AxisEnv(nreps, (), (), None), backend,\n\n  File [...]/jax/interpreters/xla.py, line 316, in primitive_computation\n    raise RuntimeError(msg) from e\n\nRuntimeError: Invalid argument: Slice size at index 0 in gather op is out of range, must be within [0, 1), got 1.: \nThis is a bug in JAX's shape-checking rules; please report it!\n\nhttps://github.com/google/jax/issues\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLayerError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6f9f9afc30e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-6f9f9afc30e6>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(num_chars, prefix)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcur_inp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_inp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add batch dim.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgumbel_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/envs/trax/lib/python3.8/site-packages/trax/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, weights, state, rng)\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m  \u001b[0;31m# Needed if the model wasn't fully initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpure_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/tools/anaconda3/envs/trax/lib/python3.8/site-packages/trax/layers/base.py\u001b[0m in \u001b[0;36mpure_fn\u001b[0;34m(self, x, weights, state, rng, use_cache)\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0;31m# Skipping 3 lines as it's always the uninteresting internal call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_short_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m       raise LayerError(name, 'pure_fn',\n\u001b[0m\u001b[1;32m    450\u001b[0m                        self._caller, signature(x), trace) from None\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLayerError\u001b[0m: Exception passing through layer Serial (in pure_fn):\n  layer created in file [...]/<ipython-input-32-fdc509f12b4f>, line 2\n  layer input shapes: ShapeDtype{shape:(1, 32), dtype:int32}\n\n  File [...]/trax/layers/combinators.py, line 88, in forward\n    outputs, s = layer.pure_fn(inputs, w, s, rng, use_cache=True)\n\nLayerError: Exception passing through layer Embedding_256_512 (in pure_fn):\n  layer created in file [...]/<ipython-input-32-fdc509f12b4f>, line 4\n  layer input shapes: ShapeDtype{shape:(1, 32), dtype:int32}\n\n  File [...]/trax/layers/core.py, line 150, in forward\n    return jnp.take(self.weights, x, axis=0)\n\n  File [...]/jax/numpy/lax_numpy.py, line 3422, in take\n    return lax.gather(a, indices[..., None], dimension_numbers=dnums,\n\n  File [...]/jax/lax/lax.py, line 807, in gather\n    return gather_p.bind(\n\n  File [...]/site-packages/jax/core.py, line 276, in bind\n    return self.impl(*args, **kwargs)\n\n  File [...]/jax/interpreters/xla.py, line 224, in apply_primitive\n    compiled_fun = xla_primitive_callable(prim, *unsafe_map(arg_spec, args), **params)\n\n  File [...]/jax/interpreters/xla.py, line 257, in xla_primitive_callable\n    built_c = primitive_computation(prim, AxisEnv(nreps, (), (), None), backend,\n\n  File [...]/jax/interpreters/xla.py, line 316, in primitive_computation\n    raise RuntimeError(msg) from e\n\nRuntimeError: Invalid argument: Slice size at index 0 in gather op is out of range, must be within [0, 1), got 1.: \nThis is a bug in JAX's shape-checking rules; please report it!\n\nhttps://github.com/google/jax/issues\n\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to generate some news sentence\n",
    "def gumbel_sample(log_probs, temperature=1.0):\n",
    "    \"\"\"Gumbel sampling from a categorical distribution.\"\"\"\n",
    "    u = numpy.random.uniform(low=1e-6, high=1.0 - 1e-6, size=log_probs.shape)\n",
    "    g = -np.log(-np.log(u))\n",
    "    return np.argmax(log_probs + g * temperature, axis=-1)\n",
    "\n",
    "def predict(num_chars, prefix):\n",
    "    inp = [ord(c) for c in prefix]\n",
    "    result = [c for c in prefix]\n",
    "    max_len = len(prefix) + num_chars\n",
    "    for _ in range(num_chars):\n",
    "        cur_inp = np.array(inp + [0] * (max_len - len(inp)))\n",
    "        outp = model(cur_inp[None, :])  # Add batch dim.\n",
    "        next_char = gumbel_sample(outp[0, len(inp)])\n",
    "        inp += [int(next_char)]\n",
    "       \n",
    "        if inp[-1] == 1:\n",
    "            break  # EOS\n",
    "        result.append(chr(int(next_char)))\n",
    "    \n",
    "    return \"\".join(result)\n",
    "\n",
    "print(predict(32, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
