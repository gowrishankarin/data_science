{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shankar/dev/tools/anaconda3/envs/trax/lib/python3.8/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import trax\n",
    "from trax import layers as tl\n",
    "import trax.fastmath.numpy as np\n",
    "import numpy\n",
    "\n",
    "# Setting random seeds\n",
    "trax.supervised.trainer_lib.init_random_number_generators(10)\n",
    "numpy.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Normalization\n",
    "- Define an L2 normalization to a tensor\n",
    "- To build custom loss function, it is expected that the tensors received are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x): \n",
    "    return x / np.sqrt(np.sum(x * x, axis=-1, keepdims=True))\n",
    "#   return x / np.linalg.norm(x, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import handcalcs.render\n",
    "from math import sqrt\n",
    "x =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e31cead23c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\[\n",
       "\\begin{aligned}\n",
       "L_{2} &= \\frac{ x }{ \\sqrt{ \\left( \\operatorname{sum} \\left( x ^ 2 \\right) \\right) } } = \\frac{ 10 }{ \\sqrt{ \\left( \\operatorname{sum} \\left( 10 ^ 2 \\right) \\right) } } &= 1.0\n",
       "\\end{aligned}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%render\n",
    "L_2 = x / (sqrt(sum(x ^ 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor is of type: <class 'numpy.ndarray'>\n",
      "\n",
      "And looks like this:\n",
      "\n",
      " [[0.77132064 0.02075195 0.63364823 0.74880388 0.49850701]\n",
      " [0.22479665 0.19806286 0.76053071 0.16911084 0.08833981]]\n"
     ]
    }
   ],
   "source": [
    "tensor = numpy.random.random((2, 5))\n",
    "print(f'The tensor is of type: {type(tensor)}\\n\\nAnd looks like this:\\n\\n {tensor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized tensor is of type: <class 'jax.interpreters.xla.DeviceArray'>\n",
      "\n",
      "And looks like this:\n",
      "\n",
      " [[0.57393795 0.01544148 0.4714962  0.55718327 0.37093794]\n",
      " [0.26781026 0.23596111 0.9060541  0.20146926 0.10524315]]\n"
     ]
    }
   ],
   "source": [
    "norm_tensor = normalize(tensor)\n",
    "print(f'The normalized tensor is of type: {type(norm_tensor)}\\n\\nAnd looks like this:\\n\\n {norm_tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese Model\n",
    "- An LSTM model using `Serial` combinator layer\n",
    "- A `Parallel` combinator to create the Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "model_dimension = 128\n",
    "\n",
    "LSTM = tl.Serial(\n",
    "    tl.Embedding(vocab_size=vocab_size, d_feature=model_dimension),\n",
    "    tl.LSTM(model_dimension),\n",
    "    tl.Mean(axis=1),\n",
    "    tl.Fn('Normalize', lambda x: normalize(x))\n",
    ")\n",
    "\n",
    "# Use the Parallel combinator to create a Siamese model\n",
    "Siamese = tl.Parallel(LSTM, LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese Model: \n",
      "\n",
      "Total Layers: 2\n",
      "\n",
      "============\n",
      "Parallel.sublayers_0: Serial[\n",
      "  Embedding_500_128\n",
      "  LSTM_128\n",
      "  Mean\n",
      "  Normalize\n",
      "]\n",
      "\n",
      "============\n",
      "Parallel.sublayers_1: Serial[\n",
      "  Embedding_500_128\n",
      "  LSTM_128\n",
      "  Mean\n",
      "  Normalize\n",
      "]\n",
      "\n",
      "Detail of LSTM models: \n",
      "\n",
      "Total Layers: 4\n",
      "\n",
      "============\n",
      "Serial.sublayers_0: Embedding_500_128\n",
      "\n",
      "============\n",
      "Serial.sublayers_1: LSTM_128\n",
      "\n",
      "============\n",
      "Serial.sublayers_2: Mean\n",
      "\n",
      "============\n",
      "Serial.sublayers_3: Normalize\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_layers(model, layer_prefix):\n",
    "    print(f'Total Layers: {len(model.sublayers)}\\n')\n",
    "    for i in range(len(model.sublayers)):\n",
    "        print(\"============\")\n",
    "        print(f'{layer_prefix}_{i}: {model.sublayers[i]}\\n')\n",
    "        \n",
    "print('Siamese Model: \\n')\n",
    "show_layers(Siamese, 'Parallel.sublayers')\n",
    "\n",
    "print('Detail of LSTM models: \\n')\n",
    "show_layers(LSTM, 'Serial.sublayers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
