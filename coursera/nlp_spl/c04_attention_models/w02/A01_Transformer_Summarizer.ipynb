{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T07:52:41.727669Z",
     "iopub.status.busy": "2020-10-11T07:52:41.727416Z",
     "iopub.status.idle": "2020-10-11T07:52:41.733467Z",
     "shell.execute_reply": "2020-10-11T07:52:41.732336Z",
     "shell.execute_reply.started": "2020-10-11T07:52:41.727638Z"
    }
   },
   "source": [
    "# Transformer Summarizer\n",
    "\n",
    "- Explore summarization using the transformer model\n",
    "- Implement transformer decoder from scratch\n",
    "![alt_text](images/transformerNews.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [Introduction](#0)\n",
    "- [Part 1: Importing the dataset](#1)\n",
    "    - [1.1 Encode & Decode helper functions](#1.1)\n",
    "    - [1.2 Defining parameters](#1.2)\n",
    "    - [1.3 Exploring the data](#1.3)\n",
    "- [Part 2: Summarization with transformer](#2)\n",
    "    - [2.1 Dot product attention](#2.1)\n",
    "        - [Exercise 01](#ex01)\n",
    "    - [2.2 Causal Attention](#2.2)\n",
    "        - [Exercise 02](#ex02)\n",
    "    - [2.3 Transformer decoder block](#2.3)\n",
    "        - [Exercise 03](#ex03)\n",
    "    - [2.4 Transformer Language model](#2.4)\n",
    "        - [Exercise 04](#ex04)\n",
    "- [Part 3: Training](#3)\n",
    "    - [3.1 Training the model](#3.1)\n",
    "        - [Exercise 05](#ex05)\n",
    "- [Part 4: Evaluation](#4)\n",
    "    - [4.1 Loading in a trained model](#4.1)\n",
    "- [Part 5: Testing with your own input](#5) \n",
    "    - [Exercise 6](#ex06)\n",
    "    - [5.1 Greedy decoding](#5.1)\n",
    "        - [Exercise 07](#ex07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T07:56:25.332767Z",
     "iopub.status.busy": "2020-10-11T07:56:25.332522Z",
     "iopub.status.idle": "2020-10-11T07:56:25.338949Z",
     "shell.execute_reply": "2020-10-11T07:56:25.337762Z",
     "shell.execute_reply.started": "2020-10-11T07:56:25.332742Z"
    }
   },
   "source": [
    "<a name='0'></a>\n",
    "### Introduction\n",
    "- Summarization is an important task in NLP and could be useful for a consumer enterprise\n",
    "- Bots can be used to scrape articles, summarize them and then you can use sentiment analysis to identify the sentiment about certain stock\n",
    "- Summarize long emails or articles \n",
    "\n",
    "1. Use built in functions to preprocess data\n",
    "2. Implement DotProductAttention\n",
    "3. Implement Causal Attention\n",
    "4. Understand how attention works\n",
    "5. Build the transformer model\n",
    "6. Evaluate the model\n",
    "7. Summarize the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T07:58:28.332096Z",
     "iopub.status.busy": "2020-10-11T07:58:28.331842Z",
     "iopub.status.idle": "2020-10-11T07:58:28.336888Z",
     "shell.execute_reply": "2020-10-11T07:58:28.336043Z",
     "shell.execute_reply.started": "2020-10-11T07:58:28.332069Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.fastmath import numpy as jnp\n",
    "\n",
    "# To print the entire np array\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T14:22:11.448537Z",
     "iopub.status.busy": "2020-10-11T14:22:11.448305Z",
     "iopub.status.idle": "2020-10-11T14:22:11.452015Z",
     "shell.execute_reply": "2020-10-11T14:22:11.451199Z",
     "shell.execute_reply.started": "2020-10-11T14:22:11.448513Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "VOCAB_DIR = os.path.join(DATA_DIR, 'vocab_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T07:58:51.907247Z",
     "iopub.status.busy": "2020-10-11T07:58:51.906951Z",
     "iopub.status.idle": "2020-10-11T08:09:33.263121Z",
     "shell.execute_reply": "2020-10-11T08:09:33.262226Z",
     "shell.execute_reply.started": "2020-10-11T07:58:51.907218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset cnn_dailymail/plain_text/3.0.0 (download: 558.32 MiB, generated: 1.27 GiB, total: 1.82 GiB) to data/cnn_dailymail/plain_text/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea53f7eb8904088a040665d37aea428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf6af4f1e394f4faf569b0b6262cfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84cdcd9cb7d40fd8b7a0307fc14de9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to data/cnn_dailymail/plain_text/3.0.0.incompleteE8RCQQ/cnn_dailymail-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdebec32f82d4f57bf689b21d21abf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=287113.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to data/cnn_dailymail/plain_text/3.0.0.incompleteE8RCQQ/cnn_dailymail-validation.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6fc375ee5a4107b69e01df9b563e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13368.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to data/cnn_dailymail/plain_text/3.0.0.incompleteE8RCQQ/cnn_dailymail-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972adaf6574c4a55ac2a0ff168fcaa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11490.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cnn_dailymail downloaded and prepared to data/cnn_dailymail/plain_text/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Importing CNN/DailyMail articles dataset\n",
    "train_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
    "                                 data_dir=DATA_DIR,\n",
    "                                 keys=('article', 'highlights'),\n",
    "                                 train=True)\n",
    "\n",
    "# This should be much faster as the data is downloaded already.\n",
    "eval_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
    "                                data_dir='data/',\n",
    "                                keys=('article', 'highlights'),\n",
    "                                train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "## 1.1 Tokenize & Detokenize helper functions\n",
    "\n",
    "Just like in the previous assignment, the cell above loads in the encoder for you. Given any data set, you have to be able to map words to their indices, and indices to their words. The inputs and outputs to your [Trax](https://github.com/google/trax) models are usually tensors of numbers where each number corresponds to a word. If you were to process your data manually, you would have to make use of the following: \n",
    "\n",
    "- <span style='color:blue'> word2Ind: </span> a dictionary mapping the word to its index.\n",
    "- <span style='color:blue'> ind2Word:</span> a dictionary mapping the index to its word.\n",
    "- <span style='color:blue'> word2Count:</span> a dictionary mapping the word to the number of times it appears. \n",
    "- <span style='color:blue'> num_words:</span> total number of words that have appeared. \n",
    "\n",
    "Since you have already implemented these in previous assignments of the specialization, we will provide you with helper functions that will do this for you. Run the cell below to get the following functions:\n",
    "\n",
    "- <span style='color:blue'> tokenize: </span> converts a text sentence to its corresponding token list (i.e. list of indices). Also converts words to subwords.\n",
    "- <span style='color:blue'> detokenize: </span> converts a token list to its corresponding sentence (i.e. string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T14:27:40.859033Z",
     "iopub.status.busy": "2020-10-11T14:27:40.858796Z",
     "iopub.status.idle": "2020-10-11T14:27:40.864562Z",
     "shell.execute_reply": "2020-10-11T14:27:40.863755Z",
     "shell.execute_reply.started": "2020-10-11T14:27:40.859007Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(input_str, EOS=1):\n",
    "    \"\"\"Input str to features dict, ready for inference\"\"\"\n",
    "  \n",
    "    # Use the trax.data.tokenize method. It takes streams and returns streams,\n",
    "    # we get around it by making a 1-element stream with `iter`.\n",
    "    inputs =  next(trax.data.tokenize(\n",
    "        iter([input_str]),\n",
    "        vocab_dir=VOCAB_DIR,\n",
    "        vocab_file='summarize32k.subword.subwords'\n",
    "    ))\n",
    "    \n",
    "    # Mark the end of the sentence with EOS\n",
    "    return list(inputs) + [EOS]\n",
    "\n",
    "def detokenize(integers):\n",
    "    \"\"\"List of ints to str\"\"\"\n",
    "  \n",
    "    s = trax.data.detokenize(\n",
    "        integers,\n",
    "        vocab_dir=VOCAB_DIR,\n",
    "        vocab_file='summarize32k.subword.subwords'\n",
    "    )\n",
    "    \n",
    "    return wrapper.fill(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T08:11:15.764524Z",
     "iopub.status.busy": "2020-10-11T08:11:15.764286Z",
     "iopub.status.idle": "2020-10-11T08:11:15.769108Z",
     "shell.execute_reply": "2020-10-11T08:11:15.768046Z",
     "shell.execute_reply.started": "2020-10-11T08:11:15.764499Z"
    }
   },
   "source": [
    "<a name='1.2'></a>\n",
    "## 1.2 Preprocessing for Language Models: Concatenate It!\n",
    "**Transformer Decoder** Language model to solve an input-output problem\n",
    "- Language models predict the next word, they have no notion of input\n",
    "- Concatenate inputs with targets putting a separator in between\n",
    "- Create a mask - [0, 1] 0s at inputs and 1s at targets, so that the model is not penalized for mis-predicting the article and only focus on summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T14:27:41.983343Z",
     "iopub.status.busy": "2020-10-11T14:27:41.983111Z",
     "iopub.status.idle": "2020-10-11T14:27:42.177195Z",
     "shell.execute_reply": "2020-10-11T14:27:42.176494Z",
     "shell.execute_reply.started": "2020-10-11T14:27:41.983322Z"
    }
   },
   "outputs": [],
   "source": [
    "SEP = 0 # Padding or separator token\n",
    "EOS = 1 # End of sentence token\n",
    "\n",
    "# Concatenate ttokenized inputs and targets sing 0 as separator\n",
    "def preprocess(stream):\n",
    "    for (article, summary) in stream:\n",
    "        joint = np.array(list(article) + [EOS, SEP] + list(summary) + [EOS])\n",
    "        mask = [0] * (len(list(article)) + 2) + [1]* (len(list(summary)) + 1) # Accounting for EOS and SEP\n",
    "        yield joint, joint, np.array(mask)\n",
    "        \n",
    "# You can combine a few data preprocessing steps into a pipeline like this\n",
    "input_pipeline = trax.data.Serial(\n",
    "    # Tokenizes\n",
    "    trax.data.Tokenize(vocab_dir=VOCAB_DIR, vocab_file='summarize32k.subword.subwords'),\n",
    "    # Uses function defined above\n",
    "    preprocess,\n",
    "    # Filters out examples longer than 2048\n",
    "    trax.data.FilterByLength(2048)\n",
    ")\n",
    "\n",
    "# Apply preprocessing to data streams\n",
    "train_stream = input_pipeline(train_stream_fn())\n",
    "eval_stream = input_pipeline(eval_stream_fn())\n",
    "\n",
    "train_input, train_target, train_mask = next(train_stream)\n",
    "\n",
    "assert sum((train_input - train_target)**2) == 0 # They are the same in Language Model (LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T14:27:42.708353Z",
     "iopub.status.busy": "2020-10-11T14:27:42.708120Z",
     "iopub.status.idle": "2020-10-11T14:27:42.714052Z",
     "shell.execute_reply": "2020-10-11T14:27:42.713274Z",
     "shell.execute_reply.started": "2020-10-11T14:27:42.708327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example mask:\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# prints mask, 0s on article, 1s on summary\n",
    "print(f'Single example mask:\\n\\n {train_mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T14:27:44.532002Z",
     "iopub.status.busy": "2020-10-11T14:27:44.531768Z",
     "iopub.status.idle": "2020-10-11T14:27:44.673289Z",
     "shell.execute_reply": "2020-10-11T14:27:44.672714Z",
     "shell.execute_reply.started": "2020-10-11T14:27:44.531976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example:\n",
      "\n",
      " By . Emily Allen . Last updated at 6:33 PM on 7th September 2011 .\n",
      "Anthony Lloyd, 17, was found by police with his pockets 'bulging' with\n",
      "stolen cigarettes and jewellery . A teenage looter who took part in\n",
      "the Manchester riots lied in court about being an Olympic hopeful in a\n",
      "bid to avoid jail. Anthony Lloyd, 17, who was caught with pockets\n",
      "bulging with jewellery and cigarettes during the riots in Manchester\n",
      "on August 9, was jailed for eight months yesterday. But now he could\n",
      "now be hauled back into the dock after falsely claiming he was a\n",
      "member of the British judo team in a desperate plea for leniency. A\n",
      "letter was even presented to the judge at Manchester Magistrates Court\n",
      "backing up the claim. Lloyd had managed to convince his unwitting\n",
      "legal team he was a promising judo star. His defence lawyer Estelle\n",
      "Parkhouse told the court: 'A custodial sentence would impair his\n",
      "prospects with the squad and being part of the Olympics.' But it has\n",
      "been discovered Lloyd has never performed for Great Britain at any\n",
      "level. Bosses at the British Judo Association said that while he is a\n",
      "member of a local club he is 'a million miles away' from being\n",
      "anywhere near the national squad. A spokesman said: 'Mr Lloyd has\n",
      "never represented us at any level and it's wrong for anyone to\n",
      "describe him as an Olympic hopeful. 'He represents a club but has\n",
      "never been in any GB trials or anywhere near any of our squads.' It is\n",
      "understood the case could now be re-opened if the court feels it has\n",
      "been misled.  Lloyd may now face further charges of perjury should\n",
      "judges decide to bring him back into the dock. Loyd was sentenced to\n",
      "eight months' detention and training for each count, to serve\n",
      "concurrently at Manchester Youth Court . He could also be hauled\n",
      "before Crown Court if the offence is considered serious enough. Lloyd,\n",
      "of Audenshaw, was stopped by police at 9.30pm at the height of the\n",
      "rioting in Manchester. Officers found him carrying £66 worth of\n",
      "cigarettes stolen from a looted newsagents and a collection of costume\n",
      "jewellery which he said he had picked up off the floor. During the\n",
      "case Lloyd's lawyer Estelle Parkhouse said Lloyd was part of the\n",
      "British Judo team . and was returning from training that Tuesday night\n",
      "when he heard about . the disorder and ventured into the city centre.\n",
      "She said he took jewellery that he had seen on the street and knew it\n",
      "had been stolen. She said it was his intention to give it to his\n",
      "girlfriend. Lloyd's parents and brother were in court to hear District\n",
      "Judge Jonathan Taaffe describe the case as 'most tragic'. The judge\n",
      "said he accepted Lloyd had led a 'blameless existence' and had 'an\n",
      "excellent future and was a talented sportsman'. But after reading\n",
      "glowing references the judge told him: 'It is my duty to impose a\n",
      "custodial sentence in this matter. 'The public have to be aware that\n",
      "people who choose to become involved in large scale public disorder,\n",
      "rioting and looting, will be severely punished. 'On this night the\n",
      "centre of Manchester and Salford resembled a battlefield and the\n",
      "public throughout the country were shocked and sickened by what they\n",
      "saw.' Lloyd, who burst into tears as the sentence was read out, said\n",
      "he had been stupid and had gone into the city out of curiosity. After\n",
      "the hearing Ms Parkhouse issued a statement on his behalf, saying: 'I\n",
      "am sincerely remorseful for my actions and would do anything to give\n",
      "back to the community what I have taken from them.' It is understood\n",
      "attempts to check the bogus claim were made by the defence team. But\n",
      "they were unable to contact the GB team as they were in action abroad.\n",
      "Lloyd's social worker father declined to comment.<EOS><pad>BritishJudo\n",
      "Association admit he was a member of a local club but 'a million\n",
      "miles' from the national squad .<EOS>\n"
     ]
    }
   ],
   "source": [
    "# prints: [Example][<EOS>][<pad>][Example Summary][<EOS>]\n",
    "print(f'Single example:\\n\\n {detokenize(train_input)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.3'></a>\n",
    "\n",
    "## 1.3 Batching with bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T15:33:39.371179Z",
     "iopub.status.busy": "2020-10-11T15:33:39.370938Z",
     "iopub.status.idle": "2020-10-11T15:33:39.375794Z",
     "shell.execute_reply": "2020-10-11T15:33:39.375027Z",
     "shell.execute_reply.started": "2020-10-11T15:33:39.371150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bucketing to crete batched generators\n",
    "\n",
    "# Buckets are defined in terms of boundaries and batch sizes\n",
    "# Batch_sizes[i] determines the batch size for items with length < boundaries[i]\n",
    "# So below, we'll take a batch of 16 sentences of length < 128, 8 of length < 256\n",
    "# 4 of length < 512 and so on\n",
    "\n",
    "boundaries = [128, 256, 512, 1024]\n",
    "batch_sizes = [16, 8, 4, 2, 1]\n",
    "\n",
    "# Create the streams\n",
    "train_batch_stream = trax.data.BucketByLength(\n",
    "    boundaries,\n",
    "    batch_sizes\n",
    ")(train_stream)\n",
    "\n",
    "eval_batch_stream = trax.data.BucketByLength(\n",
    "    boundaries,\n",
    "    batch_sizes\n",
    ")(eval_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T15:34:49.092100Z",
     "iopub.status.busy": "2020-10-11T15:34:49.091853Z",
     "iopub.status.idle": "2020-10-11T15:34:49.102126Z",
     "shell.execute_reply": "2020-10-11T15:34:49.101336Z",
     "shell.execute_reply.started": "2020-10-11T15:34:49.092075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1076)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every execution will result in generation of a different article\n",
    "# Try running this cell multiple times to see how the length of the examples affects the batch size\n",
    "input_batch, _, mask_batch = next(train_batch_stream)\n",
    "\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T15:34:59.884151Z",
     "iopub.status.busy": "2020-10-11T15:34:59.883911Z",
     "iopub.status.idle": "2020-10-11T15:34:59.890252Z",
     "shell.execute_reply": "2020-10-11T15:34:59.889454Z",
     "shell.execute_reply.started": "2020-10-11T15:34:59.884127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  567   379  4773 13859 23839    58   186 13550   574 23839    58   379\n",
      "  7226  5182  3047  6611   136  4601     3  2937   180  1731 16958     4\n",
      "     2   406   754   429 11969 28081   379  9720 22449  3590  4601     3\n",
      "  2937   180  1731 16958     4     2   406   754   429   379 16226   958\n",
      "    11  5496  6758  9945  3403   417   229  2554    28   177  6369   809\n",
      "   213  3843   819  3324 16864  2173   132 13597     2  4084     2  1019\n",
      "  9022 11195    16   213  1293   261  2474   636 12461   379     9  9733\n",
      "  8409  1779  2935   186  1526    64   213  1293   261  2474   636 12461\n",
      "    70  1779    23    46   132 11235  1019    44    74    28  2593    70\n",
      "    23  5159    28 17383   320   250    15 21048   921 16564   333     3\n",
      "  5496  6758  9945  3403   417     2  1210     2    23    46 17694   254\n",
      "    15  4161   132  3126   132  1110    70    72    91   102    22  1343\n",
      "   635   101   186  5973    32    88   226   469   102 19387 25679   113\n",
      " 19181  1551 10017   213   438 10725     3  1191   213   493   253  2860\n",
      "     2   213  1210     6   104     6   292 25431     4   404    23   379\n",
      "    46   132 21048   921 16564   333   132    28   112     6  1967     6\n",
      "   691     6   253     6  1967  1280   809   213   379  1080  3843   819\n",
      "  3324 16864  2173   132  4084     2   249   412   117   213 16316 20251\n",
      " 18679   527   213  5829   283  2002  9945  3403   417   465   285  1786\n",
      "   227   379  2570   192   936  5892     2    22  1199   132 21048   921\n",
      "  8619   166    22   229    28   379  8409    70  1480    22  2065   229\n",
      "    28  9406   527    15   509   428   544     3    34   379    28  1541\n",
      "   320   213  2173     7     5 10335   279  1898   691   213  1562  1845\n",
      "  1585     2  9945  3403   417   465  3611    13   379  2418   163  3865\n",
      "   250   320   130 21048   921 16564   333   186  2005   320  1151   132\n",
      "    28   379  1676   132   163   552  2173  1076  4872 18312  1435  1325\n",
      "   872   379    31  1231  1019    92   256    74   373   926    28   194\n",
      " 10220    13    18    46   132 21048   921 16564   333   132   213   184\n",
      "    10    59     3   254   754   118 14400   391  1110     2  1248    92\n",
      "   250   132  5382   159    13   501  2005    19   320  1151   132  3696\n",
      "  4231 13282   181   379  6098 10915     5  7511   995   872   130  1280\n",
      "  2002     9  1585  1402   285  9945  3403   417  1202     7    26   188\n",
      "   172   213  2173     7     5 14939     2  1779  6166    15 15017   123\n",
      "    28   325 15572   111    72  4653  5799     3     9    86    54  4889\n",
      "  5151   210   213  1278   527    15  1829   229 10209    28   157  1779\n",
      "    23  1343   469   192 13166 24536    17     3    34   596     2  9945\n",
      "  3403   417     7     5  7047  9552 11208   157   127    15  6480  1118\n",
      "    64   527 21048   921   166    22  1353   117 21051    20 12259   391\n",
      "   186  2663   285  1786   213   261  2474   636  1287     2   213  1190\n",
      " 12461   379   527    28 19909 12903     2    28  3953   320  3977  6596\n",
      "   240   915   672   186    54 14577    70  9945  3403   417   229   117\n",
      "    92  1174    28  3188  2002 18837  6385    11  1191   213   493   253\n",
      "  2860     2  9945  3403 16599     4    23    46   132 21048   921 16564\n",
      "   333   132    28   112     6  1967     6   691     6   253     6  1967\n",
      "  1280   809   213  1080  3843   819  3324 16864  2173   132  4084     2\n",
      "  1480   229   249   412   117   213 16316 20251 18679   527   213  5829\n",
      "   283    80 22479   657    11    56   229   213  4665   285  1353 17782\n",
      "   132   213 16843   527   213   261  2474   636   691   213  8833  7086\n",
      "  9945  3403   417 19387 12912    21   379  6869 18535  8011   153    11\n",
      "  9945  3403   417    40  9931   213  7086 14131    62  8002   213    36\n",
      "  6657    71   213    54   186  1215   148 26846  9350   246 11969     7\n",
      "    13   362   103     7     5   141  5692 21809  3898 11208   157   127\n",
      "   872   924   809   213    55  1782  1135   527   213 17362    22  1669\n",
      "  1435   673  1955   181   132 10835  2002  9945  3403   417  1353 11529\n",
      "   320   177   132  2173   379   102    22  1353  9733   132   213   261\n",
      "  2474   636  1287     2   412   110   412    28  3953   320  7086   225\n",
      "   199   379 15237   212    95   213 12251   644     3   348    15   944\n",
      " 12623 10181   113     2  9945  3403   417  8470 21460 17655  3611  3175\n",
      "     2    13   410    28  8409   186   410  4225   527   103  2002   405\n",
      " 11496   229 16931    21 26203   151 13194     2   213  8108   527   213\n",
      "   493   253 11970 19599  1397   285  4099   213   261  2474   636 20754\n",
      "   186   346  1297    53    88   226   101  1955     3  4021  4234    21\n",
      "    11  1356    74    32    88   226   101    25  5973   132   213   261\n",
      "  2474   636  1287   379 16226   958    11  5496  6758  9945  3403   417\n",
      "  2442 11302    21   285    22  1353    28  8409   809    15 12623 10181\n",
      "   113   132   944     3  1333    22   465    22     7     5 21051    20\n",
      "   379    69 13483   320   213  1975   644   213   736   527   213   379\n",
      " 12461   186  1353  3361    72    91   272   132  3126     2  4872    22\n",
      "  1353   379  1411    95   320   213 13151     3    69   169  1056   132\n",
      "    28   112     6  1967   691   253     6  1967  1280  1248    28   379\n",
      "  1309     2    28  1282     2    28 14129     2    28 19079     4   186\n",
      "    28 19379     2 11208   157   127     3  1191   379  1058     2    22\n",
      "    23    46 13463   320   707  3541  1589  9567   379  1019  4752  1779\n",
      "  1435  2162   320  1151    28  4118  3188   320   213   379   296     3\n",
      "     9  5873  2481  9945  3403   417  1838   379 20814   113  1248    54\n",
      "  4752   186    86  1350   134   320  1179  1248    15   379  7199     2\n",
      " 11208   157   127     3   174   161  5855     2  9945  3403   417   229\n",
      "  5131 14959    21   186  2025   320  9615   123   379  6841  3252  2930\n",
      "     3     9  2173   229    43   278   320 18464 17445     4  9671   379\n",
      "  3751  7858  3039  3955     2  5639   324 12461   588     6 23374 16096\n",
      "     4  8609  8079 14400   117 16066   562 17445     4    80 17353  4035\n",
      "  4844   173 21719 13590  6200  9411   308   186   117 26783 17445     4\n",
      "    80  1308   379 20742     3 16787     4    11  2713  1501   213  4165\n",
      " 17988 10017   213   438 10725   527   213   261  2474   636     2   102\n",
      "   213 12461  2104     1     0  5496  6758  9945  3403   417  1353   213\n",
      "  9022  1246   527   213  8409  1287   285  1343   635   101   186  5973\n",
      "    32    88   226   469 16346 27439  6774  1628    69    23    46   475\n",
      "   132 21048   921 16564   333   809   213  1080  5270 16864  2173   254\n",
      "   213   493   253  2860 16346 27439  6774  1628   405  7199   465    22\n",
      "     7     5    92  1174    28  3188  2104     1]\n"
     ]
    }
   ],
   "source": [
    "# print corresponding integer values\n",
    "print(input_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T15:40:56.445229Z",
     "iopub.status.busy": "2020-10-11T15:40:56.444985Z",
     "iopub.status.idle": "2020-10-11T15:40:56.585149Z",
     "shell.execute_reply": "2020-10-11T15:40:56.584421Z",
     "shell.execute_reply.started": "2020-10-11T15:40:56.445195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "\n",
      " By . Daily Mail Reporter and Associated Press Reporter . PUBLISHED: .\n",
      "09:41 EST, 18 February 2013 . | . UPDATED: . 09:41 EST, 18 February\n",
      "2013 . Terrorist: Ramzi Yousef is serving a life sentence at the ADX\n",
      "supermax prison in Florence, Colorado, for masterminding the 1993\n",
      "World Trade Center bombing . The convicted terrorist who planned and\n",
      "carried out the 1993 World Trade Center bombing - who has been in\n",
      "isolation for more than a decade - has filed a lawsuit to end his\n",
      "solitary confinement. Ramzi Yousef, 45, has been imprisoned since his\n",
      "capture in Pakistan in 1995 - two years after he killed six people and\n",
      "injured 1,000 others after detonating explosives beneath the North\n",
      "Tower. Since the September 11 attacks, the 45-year-old Pakistani\n",
      "national has . been in solitary confinement in a 7-foot-by-11-foot\n",
      "cell at the . federal ADX supermax prison in Colorado, known as 'the\n",
      "Alcatraz of the Rockies.' Yousef says that despite good . behavior\n",
      "while behind bars, he remains in solitary solely because he is a .\n",
      "terrorist - which he claims is a violation of his due process rights.\n",
      "In . a letter to the prison's warden obtained by the Los Angeles\n",
      "Times, Yousef says: 'I . request an immediate end to my solitary\n",
      "confinement and ask to be in a . unit in an open prison environment\n",
      "where inmates are allowed outside . their cells for no less than 14\n",
      "hours a day.' 'I have been in solitary confinement in the U.S. since\n",
      "February 8, . 1995, with no end in sight... I further ask not to be in\n",
      "handcuffs or . leg irons when moved outside my cell.' The Times\n",
      "reports that Yousef doesn't even see the prison's guards, who push his\n",
      "meals through a small slot between two steel doors. The only other\n",
      "inmate within the sound of his voice is reportedly a man who has\n",
      "killed others while incarcerated. In August, Yousef's attorney Bernard\n",
      "Kleinman said his client wanted out of solitary because he was\n",
      "'lonely' - and claimed that despite the World Trade Center attack, the\n",
      "1994 bombing . of a Philippine jet, a plot to kill Pope John Paul II\n",
      "and other plots - Yousef is 'no longer a threat.' Isolation: Since the\n",
      "September 11 attacks, Yousefl has been in solitary confinement in a\n",
      "7-foot-by-11-foot cell at the federal ADX supermax prison in Colorado,\n",
      "which is known as 'the Alcatraz of the Rockies' Damage: This is the\n",
      "hole that was blown in the basement of the World Trade Center by the\n",
      "truck bomb Yousef detonated . Catastrophic: Yousef had hoped the bomb\n",
      "blast would collapse the one tower into the other and bring both\n",
      "crumbling down . 'I think it's just plain unfair,' Kleinman said\n",
      "outside court at the time. 'Most of the terrorists he knew are either\n",
      "dead or in jail.' Yousef was sentenced to life in prison . after he\n",
      "was convicted in the World Trade Center attack, as well as a plot to\n",
      "bomb 12 American . airliners over the Far East. At his 1998\n",
      "sentencing, Yousef defiantly proclaimed: 'Yes, I am a terrorist and am\n",
      "proud of it.' His uncle is Khalid Sheikh Mohammed, the architect of\n",
      "the September 11 terror atrocities that destroyed the World Trade\n",
      "Center towers and left nearly 3,000 people dead. Wounded: More than\n",
      "1,000 people were injured in the World Trade Center attack .\n",
      "Terrorist: Ramzi Yousef bragged that he was a terrorist at his\n",
      "sentencing in 1998. Now he says he's lonely . He fled to the Middle\n",
      "East the night of the . bombing and was captured two years later in\n",
      "Pakistan, where he was . turned over to the FBI. He now lives in a\n",
      "7-foot by 11-foot cell with a . radio, a television, a desk, a toilet\n",
      "and a shower, Kleinman said. Since . 1997, he has been subjected to\n",
      "special administrative measures reserved . for prisoners who are\n",
      "believed to be a continuing threat to the . country. The restrictions\n",
      "prevent Yousef from . communicating with other prisoners and only\n",
      "allow him to meet with his . lawyer, Kleinman said. For those visits,\n",
      "Yousef is shackled and forced to communicate through . Plexiglass. The\n",
      "prison is also home to Unabomber Ted . Kaczynski, Oklahoma City\n",
      "bombing co-conspirator Terry Nicholas, . 'underwear bomber' Umar\n",
      "Farouk Abdulmutallab and 'shoe bomber' Richard . Reid. Investigation:\n",
      "Police search the parking garage beneath the North Tower of the World\n",
      "Trade Center, after the bombing .<EOS><pad>RamziYousef was the\n",
      "mastermind of the terrorist attack that killed six people and injured\n",
      "1,000 others . He has been held in solitary confinement at the federal\n",
      "Supermax prison since the September 11 attacks . His lawyer says he's\n",
      "no longer a threat .<EOS>\n"
     ]
    }
   ],
   "source": [
    "# print the article and its summary\n",
    "print('Article:\\n\\n', detokenize(input_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T15:52:27.029686Z",
     "iopub.status.busy": "2020-10-11T15:52:27.029448Z",
     "iopub.status.idle": "2020-10-11T15:52:27.035893Z",
     "shell.execute_reply": "2020-10-11T15:52:27.034128Z",
     "shell.execute_reply.started": "2020-10-11T15:52:27.029660Z"
    }
   },
   "source": [
    "<a name='2'></a>\n",
    "# Part 2: Summarization with transformer\n",
    "![alt_text](images/transformer_decoder_zoomin.png)\n",
    "\n",
    "<a name='2.1'></a>\n",
    "## 2.1 Dot product attention \n",
    "\n",
    "Now you will implement dot product attention which takes in a query, key, value, and a mask. It returns the output.   \n",
    "![alt_text](images/dotproduct.png)\n",
    "\n",
    "Here are some helper functions that will help you create tensors and display useful information:\n",
    "   - `create_tensor`  creates a `jax numpy array` from a list of lists.\n",
    "   - `display_tensor` prints out the shape and the actual tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T15:57:41.044752Z",
     "iopub.status.busy": "2020-10-11T15:57:41.044501Z",
     "iopub.status.idle": "2020-10-11T15:57:41.049074Z",
     "shell.execute_reply": "2020-10-11T15:57:41.048190Z",
     "shell.execute_reply.started": "2020-10-11T15:57:41.044731Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_tensor(t):\n",
    "    \"\"\"\n",
    "    Create tensor from list of lists\n",
    "    \"\"\"\n",
    "    return jnp.array(t)\n",
    "\n",
    "def display_tensor(t, name):\n",
    "    \"\"\"Display shape and tensor\"\"\"\n",
    "    print(f'{name} shape: {t.shape}\\n')\n",
    "    print(f'{t}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for attention is this one:\n",
    "\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
    "$$\n",
    "\n",
    "$d_{k}$ stands for the dimension of queries and keys.\n",
    "\n",
    "The `query`, `key`, `value` and `mask` vectors are provided for this example.\n",
    "\n",
    "Notice that the masking is done using very negative values that will yield a similar effect to using $-\\infty $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T15:59:59.380839Z",
     "iopub.status.busy": "2020-10-11T15:59:59.380573Z",
     "iopub.status.idle": "2020-10-11T15:59:59.418202Z",
     "shell.execute_reply": "2020-10-11T15:59:59.417125Z",
     "shell.execute_reply.started": "2020-10-11T15:59:59.380809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: (2, 3)\n",
      "\n",
      "[[1 0 0]\n",
      " [0 1 0]]\n",
      "\n",
      "key shape: (2, 3)\n",
      "\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "value shape: (2, 3)\n",
      "\n",
      "[[0 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "mask shape: (2, 2)\n",
      "\n",
      "[[ 0.e+00  0.e+00]\n",
      " [-1.e+09  0.e+00]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shankar/dev/tools/anaconda3/envs/trax/lib/python3.8/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
    "display_tensor(q, 'query')\n",
    "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
    "display_tensor(k, 'key')\n",
    "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
    "display_tensor(v, 'value')\n",
    "m = create_tensor([[0, 0], [-1e9, 0]])\n",
    "display_tensor(m, 'mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T16:00:49.262275Z",
     "iopub.status.busy": "2020-10-11T16:00:49.262032Z",
     "iopub.status.idle": "2020-10-11T16:00:49.328603Z",
     "shell.execute_reply": "2020-10-11T16:00:49.327777Z",
     "shell.execute_reply.started": "2020-10-11T16:00:49.262248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query dot key shape: (2, 2)\n",
      "\n",
      "[[0.57735026 2.309401  ]\n",
      " [1.1547005  2.8867514 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_dot_k = q @ k.T / jnp.sqrt(3)\n",
    "display_tensor(q_dot_k, 'query dot key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T16:01:06.180521Z",
     "iopub.status.busy": "2020-10-11T16:01:06.180315Z",
     "iopub.status.idle": "2020-10-11T16:01:06.192861Z",
     "shell.execute_reply": "2020-10-11T16:01:06.192055Z",
     "shell.execute_reply.started": "2020-10-11T16:01:06.180500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked query dot key shape: (2, 2)\n",
      "\n",
      "[[ 5.7735026e-01  2.3094010e+00]\n",
      " [-1.0000000e+09  2.8867514e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "masked = q_dot_k + m\n",
    "display_tensor(masked, 'masked query dot key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T16:01:51.486829Z",
     "iopub.status.busy": "2020-10-11T16:01:51.486595Z",
     "iopub.status.idle": "2020-10-11T16:01:51.530944Z",
     "shell.execute_reply": "2020-10-11T16:01:51.530217Z",
     "shell.execute_reply.started": "2020-10-11T16:01:51.486804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked query dot key dot value shape: (2, 3)\n",
      "\n",
      "[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n",
      " [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(masked @ v, 'masked query dot key dot value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to use the previous dummy tensors to test some of the graded functions, a batch dimension should be added to them so they mimic the shape of real-life examples. \n",
    "- The mask is also replaced by a version of it that resembles the one that is used by trax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T16:04:39.806896Z",
     "iopub.status.busy": "2020-10-11T16:04:39.806641Z",
     "iopub.status.idle": "2020-10-11T16:04:39.820346Z",
     "shell.execute_reply": "2020-10-11T16:04:39.819507Z",
     "shell.execute_reply.started": "2020-10-11T16:04:39.806870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_with_batch = q[None, :]\n",
    "display_tensor(q_with_batch, 'query with batch dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-11T16:05:06.481317Z",
     "iopub.status.busy": "2020-10-11T16:05:06.480913Z",
     "iopub.status.idle": "2020-10-11T16:05:06.489709Z",
     "shell.execute_reply": "2020-10-11T16:05:06.488870Z",
     "shell.execute_reply.started": "2020-10-11T16:05:06.481271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]]\n",
      "\n",
      "value with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[0 1 0]\n",
      "  [1 0 1]]]\n",
      "\n",
      "boolean mask shape: (2, 2)\n",
      "\n",
      "[[ True  True]\n",
      " [False  True]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_with_batch = k[None,:]\n",
    "display_tensor(k_with_batch, 'key with batch dim')\n",
    "v_with_batch = v[None,:]\n",
    "display_tensor(v_with_batch, 'value with batch dim')\n",
    "m_bool = create_tensor([[True, True], [False, True]])\n",
    "display_tensor(m_bool, 'boolean mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
