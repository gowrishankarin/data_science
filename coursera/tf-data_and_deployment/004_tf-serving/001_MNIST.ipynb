{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) =  mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_images.shape: (60000, 28, 28, 1), of float64\n",
      "test_images.shape: (10000, 28, 28, 1), of float64\n"
     ]
    }
   ],
   "source": [
    "print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
    "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEKCAYAAADUyyOuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQzElEQVR4nO3dfaxUdX7H8fdHd11ZxIpyUYpG3BWjdtOi3iU17hrtik/VwG58ooawkSyr1ax2TZXSpj4kG6mtGrNtbHHRlVVhpa4RoxWJWUtN68YrRcGaKhJkQYSLbsXHVfDbP+bgjteZcy9zzsyZy+/zSiYzc37n4ZuBzz1nzu+c+SkiMLM9315VF2BmneGwmyXCYTdLhMNulgiH3SwRDrtZIhz2EkmKITzWV10ngKR5knaUtK43JP2kjHVl63tG0uMlrGeMpG3Z5/6NMmobzr5QdQF7mBMHvH8IeB64vm7abztWjd0CfFx1Ed3CYS9RRDxT/17Sb4FtA6c3I+lLEeE/BiWQ9CfAd4AfAvMrLqcr+DC+IpIWS1or6eTssPUD4EZJ+2aHnXMGzH90Nv2iAdNPk/SUpHezx6OSjimpxrMlPZ4dpr8nabWkH0hq+P9G0p9LWifpQ0nPSvpmg3naVm/dNr4E/DNwI/DrMtc9nDns1RoD/AxYCJwF/OvuLCzpO8AyYBvwZ8AMoAdYIWlcCfV9BXgc+C5wLnAfMA/42wbzngFcBlyb1QKwTNIRZdSb/cEZ6vf4vwE+Am4b4vxJ8GF8tX4PuDAilu2aIGnfoSyY7V1vB5ZFxHl10/8dWAdcCcxpsviQRMQ/1q1XwApgJLVQXz9g9h7g6xHxRjb/L4HXgLnA90qodwewc7Cas6OEvwSmRMSOWtkGDnvV3q8P+m76A+BQ4FpJ9f+O24FngZOLFifpUOAGYArw+8DedW0HRMT/1c2+YlfQASLiN5KW8buTloXqjYhDh1CvgH8BFkfEfww2f2p8GF+tNwafpamx2fN91M441z9OAw4qUlgWyEezdd0AnAJ8Hfj7bJaBRyBbGqxmCzC+E/VmZgDHAT+SdICkA6gdiQDsJ2n/ErYxbHnPXq1G9xd/TO1wdZ8B0weG4c3s+Wpqh9cDfVisNI4B/hA4PyI+PZcg6fwm8x/cZNqm7HW76wU4FtgPeLlB279R++NzSAnbGZYc9i4TETslbQK+NqDpTwe8Xw28DhwTEbe2oZQvZ8+f9lNnZ7mnN5n/m5IOqfvOPpraSbufd6heqHWxDTyJNxn4O+AHwHNt2u6w4LB3p8XADyVdC/QBpwKf2aNmfxSuAJZI+jLwILW95yHAScDL9SfYmpCk8xpM30jtYqDXgZvrutqupnaWu5FtwHJJN1I7Mvkrav+/flRGvZI2As9HxMA/ep+KiHXUTvbVL7fr68Z/R8R/Nls2BQ57d7oBGAX8BbU97CPUur+erp8pIh6SdCq1M94LgBHAZuC/gHuHsJ29gCUNpj8YEedJmgr8mNr37Dep7TnfBP6pwTLLgJXAzdRO5q0GzoiI9SXV+wXqThDa7pN/lsosDT4bb5YIh90sEQ67WSIcdrNEdPRs/JgxY2LChAmd3KRZUtavX8+2bdsa3hBQKOySzqR2c8PewE8iYl7e/BMmTKCvr6/IJs0sR29vb9O2lg/jJe1Nrb/1LGqXKU6XdGyr6zOz9irynX0ysDYi1kXER9Su+ppaTllmVrYiYR/PZ38FZCO/u8PpU5JmS+qT1Nff319gc2ZWRJGwNzoJ8LnL8SJifkT0RkRvT09Pgc2ZWRFFwr4ROKzu/aHUbpwwsy5UJOzPAhMlHSFpH+AiYGk5ZZlZ2Vruest+3+sKanc77Q3cFREvllaZmZWqUD97RDwGPFZSLWbWRr5c1iwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyWi0JDNktYD7wA7gR0R0VtGUWZWvkJhz5waEdtKWI+ZtZEP480SUTTsATwh6TlJsxvNIGm2pD5Jff39/QU3Z2atKhr2kyLieOAs4HJJJw+cISLmR0RvRPT29PQU3JyZtapQ2CPi9ex5K/AQMLmMosysfC2HXdJISaN2vQZOB9aUVZiZlavI2fiDgYck7VrP/RHxeClV7WFuuumm3Pa5c+fmtk+fPj23/f7779/tmrrBE088kdt+xhln5Lafc845ue2PPPLIbte0J2s57BGxDvijEmsxszZy15tZIhx2s0Q47GaJcNjNEuGwmyWijBthbBDvv/9+oeVHjRpVUiXdZe3atYWWH6zrbuXKlU3bjj/++ELbHo68ZzdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuF+9g5YsmRJoeUnTZpUUiXd5dVXXy20/IgRI3Lb99TrE1rlPbtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgj3s5dg+/btue0ffPBBofUP55F08q4xuPfeewute9y4cbntEydOLLT+PY337GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZItzPXoI1a/KHpd+wYUOh9R911FGFlm+nDz/8MLf9zjvvbNq2devWQtved999Cy2fmkH37JLukrRV0pq6aQdKWi7plex5dHvLNLOihnIY/1PgzAHT5gBPRsRE4MnsvZl1sUHDHhErgLcGTJ4K3JO9vgeYVnJdZlayVk/QHRwRmwGy57HNZpQ0W1KfpL7+/v4WN2dmRbX9bHxEzI+I3ojoHc43dJgNd62GfYukcQDZc7HTqmbWdq2GfSkwM3s9E3i4nHLMrF0G7WeXtAg4BRgjaSNwHTAPeEDSLGADcH47i0xdN9+Xfc011+S2L1++vG3bvvDCC9u27j3RoGGPiOlNmr5Vci1m1ka+XNYsEQ67WSIcdrNEOOxmiXDYzRLhW1xLUPQnkbvZDTfckNt+xx13tG3bBxxwQG77JZdc0rZt74m8ZzdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuF+9hLs3Lmz6hJaNtg1AvPmzctt37FjR5nlfMaJJ56Y2z52bNNfQ7MGvGc3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhfvYSTJo0Kbd9//33z23fvn17bvtrr72W23700Uc3bdu0aVPuspdeemlu+2BDMrfThAkTKtv2nsh7drNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEe5nL8Fll12W2/7MM8/kti9cuDC3/brrrsttnzJlStO2q666KnfZ9957L7e9nfbaK39fM23atA5VkoZB9+yS7pK0VdKaumnXS9okaVX2OLu9ZZpZUUM5jP8pcGaD6bdFxKTs8Vi5ZZlZ2QYNe0SsAN7qQC1m1kZFTtBdIemF7DB/dLOZJM2W1Cepr7+/v8DmzKyIVsN+B/BVYBKwGbil2YwRMT8ieiOit6enp8XNmVlRLYU9IrZExM6I+AS4E5hcbllmVraWwi5pXN3bbwNrms1rZt1h0H52SYuAU4AxkjYC1wGnSJoEBLAe+H4baxz2ZsyYkdv+9ttv57YvWbIkt/2BBx7Y7Zp2GTFiRG771KlTc9sXL17c8rZPOOGE3PbTTz+95XXb5w0a9oiY3mDygjbUYmZt5MtlzRLhsJslwmE3S4TDbpYIh90sEb7FtQNOO+20Qu0LFuR3fixdurRp2+GHH5677JVXXpnb/uijj+a2F+l6mzzZ12J1kvfsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1ki3M8+DMyaNatQexF3331329Y9enTTXzOzNvCe3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhPvZLde5556b275q1arc9iOPPLJp25w5c1qqyVrjPbtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNuloihDNl8GLAQOAT4BJgfEbdLOhD4OTCB2rDNF0TEb9pXqlVhzZo1hZbPGxJ65MiRhdZtu2coe/YdwNURcQzwx8Dlko4F5gBPRsRE4MnsvZl1qUHDHhGbI2Jl9vod4CVgPDAVuCeb7R5gWruKNLPidus7u6QJwHHAr4CDI2Iz1P4gAGPLLs7MyjPksEvaD3gQuCoitu/GcrMl9Unq6+/vb6VGMyvBkMIu6YvUgn5fRPwim7xF0risfRywtdGyETE/Inojorenp6eMms2sBYOGXZKABcBLEXFrXdNSYGb2eibwcPnlmVlZhnKL60nADGC1pF33M84F5gEPSJoFbADOb0+JVqWDDjqo0PIXXHBBSZVYUYOGPSKeBtSk+VvllmNm7eIr6MwS4bCbJcJhN0uEw26WCIfdLBEOu1ki/FPSlmvDhg2Fls+7xdU6y3t2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwR7me3XFu3NvwBIhuGvGc3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhfnbLNWrUqKpLsJJ4z26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJWLQfnZJhwELgUOAT4D5EXG7pOuB7wH92axzI+KxdhVq1Vi0aFFu+8UXX9yhSqyooVxUswO4OiJWShoFPCdpedZ2W0T8Q/vKM7OyDBr2iNgMbM5evyPpJWB8uwszs3Lt1nd2SROA44BfZZOukPSCpLskjW6yzGxJfZL6+vv7G81iZh0w5LBL2g94ELgqIrYDdwBfBSZR2/Pf0mi5iJgfEb0R0dvT01NCyWbWiiGFXdIXqQX9voj4BUBEbImInRHxCXAnMLl9ZZpZUYOGXZKABcBLEXFr3fRxdbN9G1hTfnlmVpahnI0/CZgBrJa0Kps2F5guaRIQwHrg+22p0Co1fnz+udinnnqqM4VYYUM5G/80oAZN7lM3G0Z8BZ1ZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCYTdLhCKicxuT+oHX6iaNAbZ1rIDd0621dWtd4NpaVWZth0dEw99/62jYP7dxqS8ieisrIEe31tatdYFra1WnavNhvFkiHHazRFQd9vkVbz9Pt9bWrXWBa2tVR2qr9Du7mXVO1Xt2M+sQh90sEZWEXdKZkv5X0lpJc6qooRlJ6yWtlrRKUl/FtdwlaaukNXXTDpS0XNIr2XPDMfYqqu16SZuyz26VpLMrqu0wSb+U9JKkFyVdmU2v9LPLqasjn1vHv7NL2ht4GZgCbASeBaZHxP90tJAmJK0HeiOi8gswJJ0MvAssjIivZdNuBt6KiHnZH8rREXFtl9R2PfBu1cN4Z6MVjasfZhyYBnyXCj+7nLouoAOfWxV79snA2ohYFxEfAYuBqRXU0fUiYgXw1oDJU4F7stf3UPvP0nFNausKEbE5IlZmr98Bdg0zXulnl1NXR1QR9vHAr+veb6S7xnsP4AlJz0maXXUxDRwcEZuh9p8HGFtxPQMNOox3Jw0YZrxrPrtWhj8vqoqwNxpKqpv6/06KiOOBs4DLs8NVG5ohDePdKQ2GGe8KrQ5/XlQVYd8IHFb3/lDg9QrqaCgiXs+etwIP0X1DUW/ZNYJu9ry14no+1U3DeDcaZpwu+OyqHP68irA/C0yUdISkfYCLgKUV1PE5kkZmJ06QNBI4ne4binopMDN7PRN4uMJaPqNbhvFuNsw4FX92lQ9/HhEdfwBnUzsj/yrw11XU0KSurwDPZ48Xq64NWETtsO5jakdEs4CDgCeBV7LnA7uotp8Bq4EXqAVrXEW1fYPaV8MXgFXZ4+yqP7ucujryuflyWbNE+Ao6s0Q47GaJcNjNEuGwmyXCYTdLhMNulgiH3SwR/w8jWQ5NNhmmjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 42\n",
    "plt.imshow(test_images[idx].reshape(28, 28), cmap=plt.cm.binary)\n",
    "plt.title(f'True Label: {test_labels[idx]}', fontdict={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1 (Conv2D)               (None, 13, 13, 8)         80        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               346368    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "Softmax (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 380,634\n",
      "Trainable params: 380,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        input_shape=(28,28,1), filters=8, kernel_size=3,\n",
    "        strides=2, activation='relu', name='Conv1'\n",
    "    ),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 146us/sample - loss: 0.1967 - accuracy: 0.9418\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 144us/sample - loss: 0.0976 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 0.0831 - accuracy: 0.9746\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 145us/sample - loss: 0.0719 - accuracy: 0.9765\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.0659 - accuracy: 0.9791\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "epochs = 5\n",
    "history = model.fit(train_images, train_labels, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0919\n",
      "accuracy: 0.972\n"
     ]
    }
   ],
   "source": [
    "results_eval = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "for metric, value in zip(model.metrics_names, results_eval):\n",
    "    print(metric + ': {:.3}'.format(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/shankar/dev/tools/anaconda3/envs/kaggle/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /var/folders/wh/h43cl57j4ljf1x5_4p1bqmx80000gn/T/1/assets\n",
      "\n",
      "export_path = /var/folders/wh/h43cl57j4ljf1x5_4p1bqmx80000gn/T/1\n",
      "total 232\n",
      "drwxr-xr-x  2 shankar  staff      64 May  5 14:55 \u001b[1m\u001b[36massets\u001b[m\u001b[m\n",
      "-rw-r--r--  1 shankar  staff  114998 May  5 14:55 saved_model.pb\n",
      "drwxr-xr-x  4 shankar  staff     128 May  5 14:55 \u001b[1m\u001b[36mvariables\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = tempfile.gettempdir()\n",
    "\n",
    "version = 1\n",
    "\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "\n",
    "if(os.path.isdir(export_path)):\n",
    "    print(\"\\nAlready saved a model, cleaning up\\n\")\n",
    "    !rm -r {export_path}\n",
    "    \n",
    "model.save(export_path, save_format=\"tf\")\n",
    "\n",
    "print(f\"\\nexport_path = {export_path}\")\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['Conv1_input'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 28, 28, 1)\n",
      "        name: serving_default_Conv1_input:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['Softmax'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING:tensorflow:From /Users/shankar/dev/tools/anaconda3/envs/kaggle/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='Conv1_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tee: /etc/apt/sources.list.d/tensorflow-serving.list: No such file or directory\n",
      "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
      "Unable to locate an executable at \"/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/bin/apt\" (-1)\n"
     ]
    }
   ],
   "source": [
    "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
    "!apt update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install tensorflow-model-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "nohup tensorflow_model_server --rest_api_port=8051 --model_name=mym --model_base_path=\"${MODEL_DIR}\" > server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps({\n",
    "    \"signature_name\": \"server_default\",\n",
    "    \"instances\": test_images[0:3].tolist()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/digits_model:predict', data=data, headers=headers)\n",
    "\n",
    "predictions = json.loads(json_response.text)['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 15))\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(test_images[i].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "    color = 'green' if np.argmax(pedictions[i]) == test_labels[i] else 'red'\n",
    "    plt.title(f'Prediction: {np.argmax(predictions[i])}\\nTrue Label: {test_labels[i]}', color=color)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
