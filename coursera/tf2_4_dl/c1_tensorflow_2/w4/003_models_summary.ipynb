{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Saving and loading model weights](#coding_tutorial_1)\n",
    " #### [2. Model saving criteria](#coding_tutorial_2)\n",
    " #### [3. Saving the entire model](#coding_tutorial_3)\n",
    " #### [4. Loading pre-trained Keras models](#coding_tutorial_4)\n",
    " #### [5. Tensorflow Hub modules](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Saving and loading model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and inspect CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of, in total, 60000 color images, each with one of 10 labels: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. For an introduction and a download, see [this link](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CIFAR-10 dataset and rescale the pixel values\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Use smaller subset -- speeds things up\n",
    "x_train = x_train[:10000]\n",
    "y_train = y_train[:10000]\n",
    "x_test = x_test[:1000]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 10 CIFAR-10 images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 10, figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].imshow(x_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduce two useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce function to test model accuracy\n",
    "\n",
    "def get_test_accuracy(model, x_test, y_test):\n",
    "    test_loss, test_acc = model.evaluate(x=x_test, y=y_test, verbose=0)\n",
    "    print('accuracy: {acc:0.3f}'.format(acc=test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce function that creates a new instance of a simple CNN\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "def get_new_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=16, input_shape=(32, 32, 3), kernel_size=(3, 3), \n",
    "               activation='relu', name='conv_1'),\n",
    "        Conv2D(filters=8, kernel_size=(3, 3), activation='relu', name='conv_2'),\n",
    "        MaxPooling2D(pool_size=(4, 4), name='pool_1'),\n",
    "        Flatten(name='flatten'),\n",
    "        Dense(units=32, activation='relu', name='dense_1'),\n",
    "        Dense(units=10, activation='softmax', name='dense_2')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create simple convolutional neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model and show model summary\n",
    "\n",
    "model = get_new_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy of the untrained model, around 10% (random)\n",
    "\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model with checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow checkpoint object\n",
    "\n",
    "checkpoint_path = 'model_checkpoints/checkpoint'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    frequency='epoch',\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model, with simple checkpoint which saves (and overwrites) model weights every epoch\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    callbacks=[checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at what the checkpoint creates\n",
    "!ls -lh model_checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the trained model\n",
    "\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new model, load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the (initialised) model, accuracy around 10% again\n",
    "\n",
    "model = get_new_model()\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights -- accuracy is the same as the trained model\n",
    "model.load_weights(checkpoint_path)\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r model_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Model saving criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create more customised checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow checkpoint object with epoch and batch details\n",
    "\n",
    "checkpoint_500_path = \\\n",
    "    'model_checkpoints_500/checkpoint_{epoch:02d}_{batch:04d}'\n",
    "\n",
    "checkpoint_5000 = ModelCheckpoint(\n",
    "    filepath=checkpoint_500_path,\n",
    "    save_weights_only=True,\n",
    "    save_freq=5000,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model with checkpoint\n",
    "\n",
    "model = get_new_model()\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=3,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=10,\n",
    "    callbacks=[checkpoint_5000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at what the checkpoint creates\n",
    "\n",
    "!ls -lh model_checkpoints_500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work with model saving criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tiny training and test set -- will overfit!\n",
    "\n",
    "x_train = x_train[:100]\n",
    "y_train = y_train[:100]\n",
    "x_test = x_test[:100]\n",
    "y_test = y_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of untrained model\n",
    "\n",
    "model = get_new_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow checkpoint object which monitors the validation accuracy\n",
    "checkpoint_best_path = \\\n",
    "    'model_checkpoints_best/checkpoint' #_{epoch:02d}_{batch:04d}'\n",
    "\n",
    "checkpoint_best = ModelCheckpoint(\n",
    "    filepath=checkpoint_best_path,\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    save_best_only=True,\n",
    "    #save_freq=5000,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and save only the weights with the highest validation accuracy\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=50,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=10,\n",
    "    callbacks=[checkpoint_best],\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and testing curves\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(y=['accuracy', 'val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the checkpoint directory\n",
    "\n",
    "!ls -lh model_checkpoints_best/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model with the saved weights\n",
    "\n",
    "new_model = get_new_model()\n",
    "new_model.load_weights(checkpoint_best_path)\n",
    "get_test_accuracy(new_model, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r model_checkpoints_5000 model_checkpoints_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Saving the entire model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create checkpoint that saves whole model, not just weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow checkpoint object\n",
    "\n",
    "checkpoint_path = 'model_checkpoints'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=False,\n",
    "    save_freq=\"epoch\",\n",
    "#     monitor=\"val_accuracy\",\n",
    "#     save_best_only=True,\n",
    "#     #save_freq=5000,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model with checkpoint\n",
    "model = get_new_model()\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=3,\n",
    "    callbacks=[checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect what the checkpoint has created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at what the checkpoint creates\n",
    "\n",
    "!ls -lh {checkpoint_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter variables directory\n",
    "\n",
    "\n",
    "!ls -lh {checkpoint_path}/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model's test accuracy\n",
    "\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model from scratch\n",
    "\n",
    "model = load_model(checkpoint_path)\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the .h5 format to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in .h5 format\n",
    "\n",
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect .h5 file\n",
    "\n",
    "!ls -lh my_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model from scratch\n",
    "\n",
    "model = load_model(\"my_model.h5\")\n",
    "get_test_accuracy(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r model_checkpoints\n",
    "! rm my_model.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## Loading pre-trained Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and build Keras ResNet50 model\n",
    "\n",
    "Today we'll be using the ResNet50 model designed by a team at Microsoft Research, available through Keras applications. Please see the description on the [Keras applications page](https://keras.io/applications/#resnet) for details. If you continue using it, please cite it properly! The paper it comes from is:\n",
    "\n",
    "Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. \"Deep Residual Learning for Image Recognition\", 2015.\n",
    "\n",
    "This model takes a long time to download on the Coursera platform, so it is pre-downloaded in your workspace and saved in Keras HDF5 format. If you want to import it on your personal machine, use the following code:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "model = ResNet50(weights='imagenet')\n",
    "```\n",
    "\n",
    "In this coding tutorial, you will instead load the model directly from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Keras ResNet50 model\n",
    "\n",
    "model = load_model(\"models/Keras_ResNet50.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and preprocess 3 sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 3 sample ImageNet images\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "lemon_img = load_img('data/lemon.jpg', target_size=(224, 224))\n",
    "viaduct_img = load_img('data/viaduct.jpg', target_size=(224, 224))\n",
    "water_tower_img = load_img('data/water_tower.jpg', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use ResNet50 model to classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful function: presents top 5 predictions and probabilities\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_5_predictions(img):\n",
    "    x = img_to_array(img)[np.newaxis, ...]\n",
    "    x = preprocess_input(x)\n",
    "    preds = decode_predictions(model.predict(x), top=5)\n",
    "    top_preds = pd.DataFrame(columns=['prediction', 'probability'],\n",
    "                             index=np.arange(5)+1)\n",
    "    for i in range(5):\n",
    "        top_preds.loc[i+1, 'prediction'] = preds[0][i][1]\n",
    "        top_preds.loc[i+1, 'probability'] = preds[0][i][2] \n",
    "    return top_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 1: lemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image\n",
    "lemon_img \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 5 predictions\n",
    "\n",
    "get_top_5_predictions(lemon_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 2: viaduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image\n",
    "viaduct_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 5 predictions\n",
    "get_top_5_predictions(viaduct_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 3: water tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image\n",
    "\n",
    "water_tower_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 5 predictions\n",
    "\n",
    "get_top_5_predictions(water_tower_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Tensorflow Hub modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import and build Tensorflow Hub MobileNet v1 model\n",
    "\n",
    "Today we'll be using Google's MobileNet v1 model, available on Tensorflow Hub. Please see the description on the [Tensorflow Hub page](https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4) for details on it's architecture, how it's trained, and the reference. If you continue using it, please cite it properly! The paper it comes from is:\n",
    "\n",
    "Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam: \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\", 2017.\n",
    "\n",
    "This model takes a long time to download on the Coursera platform, so it is pre-downloaded in your workspace and saved in Tensorflow SavedModel format. If you want to import it on your personal machine, use the following code:\n",
    "\n",
    "```python\n",
    "module_url = \"https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4\"\n",
    "model = Sequential([hub.KerasLayer(module_url)])\n",
    "model.build(input_shape=[None, 160, 160, 3])\n",
    "```\n",
    "\n",
    "In this coding tutorial, you will instead load the model directly from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     multiple                  1343049   \n",
      "=================================================================\n",
      "Total params: 1,343,049\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,343,049\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Google's Mobilenet v1 model\n",
    "\n",
    "module = load_model('models/Tensorflow_MobileNet_v1')\n",
    "model = tf.keras.models.Sequential(hub.KerasLayer(module))\n",
    "model.build(input_shape=[None, 160, 160, 3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use MobileNet model to classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and preprocess 3 sample ImageNet images\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "lemon_img = load_img(\"data/lemon.jpg\", target_size=(160, 160))\n",
    "viaduct_img = load_img(\"data/viaduct.jpg\", target_size=(160, 160))\n",
    "water_tower_img = load_img(\"data/water_tower.jpg\", target_size=(160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in categories text file\n",
    "\n",
    "with open('data/imagenet_categories.txt') as txt_file:\n",
    "    categories = txt_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful function: presents top 5 predictions\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_5_predictions(img):\n",
    "    x = img_to_array(img)[np.newaxis, ...] / 255.0\n",
    "    preds = model.predict(x)\n",
    "    top_preds = pd.DataFrame(columns=['prediction'],\n",
    "                             index=np.arange(5)+1)\n",
    "    sorted_index = np.argsort(-preds[0])\n",
    "    for i in range(5):\n",
    "        ith_pred = categories[sorted_index[i]]\n",
    "        top_preds.loc[i+1, 'prediction'] = ith_pred\n",
    "            \n",
    "    return top_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 1: lemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=160x160 at 0x7FAD204654A8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemon_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shower cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>candle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brassiere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>African chameleon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          prediction\n",
       "1         shower cap\n",
       "2               tray\n",
       "3             candle\n",
       "4          brassiere\n",
       "5  African chameleon"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_5_predictions(lemon_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 2: viaduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>viaduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>solar dish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "1     viaduct\n",
       "2        pier\n",
       "3         dam\n",
       "4      prison\n",
       "5  solar dish"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_5_predictions(viaduct_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image 3: water tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>solar dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>water tower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aircraft carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jigsaw puzzle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oxygen mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction\n",
       "1        solar dish\n",
       "2       water tower\n",
       "3  aircraft carrier\n",
       "4     jigsaw puzzle\n",
       "5       oxygen mask"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_5_predictions(water_tower_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
