{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dk88Aw4NJDIy",
    "outputId": "fc9ca97f-7060-450c-9c36-8d1731a8998a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "GPU name: \n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "print('GPU name: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQb8nVqLJDI5"
   },
   "source": [
    "# Sequence modelling \n",
    "\n",
    "## Coding tutorials\n",
    " #### 1.  The IMDb dataset\n",
    " #### 2. Padding and masking sequence data\n",
    " #### 3. The `Embedding` layer\n",
    " #### 4. The Embedding Projector\n",
    " #### 5. Recurrent neural network layers\n",
    " #### 6. Stacked RNNs and the `Bidirectional` wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b3PNw3gJDI7"
   },
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## The IMDb Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwqGZQ8WJDJF"
   },
   "source": [
    "#### Load the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g3_c1LL5JDJG"
   },
   "outputs": [],
   "source": [
    "# Import imdb\n",
    "\n",
    "import tensorflow.keras.datasets.imdb as imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9jYJCwXJDJK",
    "outputId": "f026685a-bef5-49b3-f2fd-fd60925e09f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Download and assign the data set using load_data()\n",
    "\n",
    "(x_train, y_train), (x_test, y_train) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oCnB8UMJDJP"
   },
   "source": [
    "#### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39RwIt-pJDJQ",
    "outputId": "8d324fcf-3e7c-46cc-8148-78a166cfcd60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the type of the data\n",
    "\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Viryy_PDJDJU",
    "outputId": "0fcf032c-3653-4c68-fd97-fa888451b91d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the shape of the data\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5q6E6v-FJDJX",
    "outputId": "be36f8cf-8fc3-476e-ff76-9a1541cc2e86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first dataset element input\n",
    "# Notice encoding\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_lbEqyjxJDJc"
   },
   "outputs": [],
   "source": [
    "# Display the first dataset element output\n",
    "\n",
    "# x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAk-PyOgJDJg"
   },
   "source": [
    "#### Load dataset with different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfzFxDj-JDJh",
    "outputId": "cdb03c75-0b34-444c-e9fd-1d8ec27b6a4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with defaults\n",
    "imdb.load_data(path=\"imdb.npz\", index_from=3)\n",
    "\n",
    "# ~/.keras/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuGfzZg3JDJv",
    "outputId": "1762f551-eb26-4e49-b1de-57476858ed6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 4, 86, 320, 35, 534, 19, 263, 2, 2, 4, 2, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 2, 43, 645, 662, 8, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 8, 106, 14, 2, 2, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2, 51, 9, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 2, 9, 6, 2, 446, 2, 45, 2, 84, 2, 2, 21, 4, 912, 84, 2, 325, 725, 134, 2, 2, 84, 5, 36, 28, 57, 2, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 2, 14, 9, 31, 7, 4, 2, 2, 2, 2, 2, 18, 6, 20, 207, 110, 563, 12, 8, 2, 2, 8, 97, 6, 20, 53, 2, 74, 4, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 6, 2, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 2, 11, 4, 2, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2, 234, 2, 2, 7, 496, 4, 139, 929, 2, 2, 2, 5, 2, 18, 4, 2, 2, 250, 11, 2, 2, 4, 2, 2, 747, 2, 372, 2, 2, 541, 2, 7, 4, 59, 2, 4, 2, 2]),\n",
       "         list([1, 2, 2, 69, 72, 2, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 8, 4, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 2, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 4, 719, 2, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2, 101, 405, 39, 14, 2, 4, 2, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 2, 2, 9, 24, 6, 78, 2, 17, 2, 2, 21, 27, 2, 2, 5, 2, 2, 92, 2, 4, 2, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 2, 4, 631, 2, 5, 2, 272, 191, 2, 6, 2, 8, 2, 2, 2, 544, 5, 383, 2, 848, 2, 2, 497, 2, 8, 2, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 2, 72, 7, 51, 6, 2, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 2, 6, 176, 7, 2, 88, 12, 2, 23, 2, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2, 109, 2, 21, 4, 22, 2, 8, 6, 2, 2, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 2, 5, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 4, 405, 5, 2, 7, 27, 85, 108, 131, 4, 2, 2, 2, 405, 9, 2, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2, 45, 407, 31, 7, 41, 2, 105, 21, 59, 299, 12, 38, 950, 5, 2, 15, 45, 629, 488, 2, 127, 6, 52, 292, 17, 4, 2, 185, 132, 2, 2, 2, 488, 2, 47, 6, 392, 173, 4, 2, 2, 270, 2, 4, 2, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2, 7, 2, 861, 2, 5, 2, 30, 2, 2, 56, 4, 841, 5, 990, 692, 8, 4, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 9, 2, 21, 45, 2, 5, 45, 252, 8, 2, 6, 565, 921, 2, 39, 4, 529, 48, 25, 181, 8, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 2]),\n",
       "         list([1, 111, 748, 2, 2, 2, 2, 4, 87, 2, 2, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 2, 8, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 5, 2, 98, 31, 2, 33, 6, 58, 14, 2, 2, 8, 4, 365, 7, 2, 2, 356, 346, 4, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 2, 431, 748, 7, 32, 2, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 2, 2, 2, 2, 8, 847, 8, 2, 121, 31, 7, 27, 86, 2, 2, 16, 6, 465, 993, 2, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 4, 2, 2, 74, 476, 37, 62, 91, 2, 169, 4, 2, 2, 146, 655, 2, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 2, 18, 631, 2, 797, 7, 4, 2, 71, 348, 425, 2, 2, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2, 2, 7, 4, 2, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 2, 19, 68, 2, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 2, 2, 36, 2, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 9, 2, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2, 247, 30, 656, 6, 2, 54, 2, 2, 98, 6, 2, 40, 558, 37, 2, 98, 4, 2, 2, 15, 14, 9, 57, 2, 5, 2, 6, 275, 711, 2, 2, 2, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2, 90, 19, 6, 2, 7, 2, 2, 2, 4, 2, 2, 930, 8, 508, 90, 4, 2, 8, 4, 2, 17, 2, 2, 2, 4, 2, 8, 2, 189, 4, 2, 2, 2, 4, 2, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 2, 6, 425, 2, 2, 2, 2, 7, 4, 2, 2, 469, 4, 2, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 5, 2, 68, 2, 19, 2, 2, 4, 2, 7, 263, 65, 2, 34, 6, 2, 2, 43, 159, 29, 9, 2, 9, 387, 73, 195, 584, 10, 10, 2, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 2, 4, 192, 15, 12, 16, 93, 34, 6, 2, 2, 33, 4, 2, 7, 15, 2, 2, 2, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 7, 819, 4, 22, 2, 17, 6, 2, 787, 7, 2, 2, 2, 100, 30, 4, 2, 2, 2, 2, 42, 2, 11, 4, 2, 42, 101, 704, 7, 101, 999, 15, 2, 94, 2, 180, 5, 9, 2, 34, 2, 45, 6, 2, 22, 60, 6, 2, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 2, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 2, 910, 769, 2, 2, 395, 2, 5, 2, 11, 119, 2, 89, 2, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2, 284, 2, 2, 37, 315, 4, 226, 20, 272, 2, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2, 7, 743, 46, 2, 9, 2, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 2, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 6, 2, 7, 470]),\n",
       "         list([1, 6, 52, 2, 430, 22, 9, 220, 2, 8, 28, 2, 519, 2, 6, 769, 15, 47, 6, 2, 2, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 5, 6, 364, 350, 4, 184, 2, 9, 133, 2, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2, 2, 9, 6, 2, 17, 6, 2, 2, 21, 17, 6, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 2, 19, 4, 78, 173, 7, 27, 2, 2, 2, 718, 2, 9, 6, 2, 17, 210, 5, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 2, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 2, 2, 2, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the vocabulary to the top 500 words using num_words\n",
    "imdb.load_data(num_words=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMkXgUGaJDJy",
    "outputId": "03db9123-9704-4f30-f765-4e99eb6faaa9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([list([2, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 2, 173, 36, 256, 2, 25, 100, 43, 838, 112, 50, 670, 2, 2, 35, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 39, 2, 172, 2, 2, 17, 546, 38, 13, 447, 2, 192, 50, 16, 2, 147, 2, 19, 14, 22, 2, 2, 2, 469, 2, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 2, 22, 17, 515, 17, 12, 16, 626, 18, 2, 2, 62, 386, 12, 2, 316, 2, 106, 2, 2, 2, 2, 16, 480, 66, 2, 33, 2, 130, 12, 16, 38, 619, 2, 25, 124, 51, 36, 135, 48, 25, 2, 33, 2, 22, 12, 215, 28, 77, 52, 2, 14, 407, 16, 82, 2, 2, 2, 107, 117, 2, 15, 256, 2, 2, 2, 2, 2, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 2, 2, 2, 2, 13, 104, 88, 2, 381, 15, 297, 98, 32, 2, 56, 26, 141, 2, 194, 2, 18, 2, 226, 22, 21, 134, 476, 26, 480, 2, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 2, 226, 65, 16, 38, 2, 88, 12, 16, 283, 2, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
       "         list([2, 194, 2, 194, 2, 78, 228, 2, 2, 2, 2, 2, 134, 26, 2, 715, 2, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 2, 207, 110, 2, 21, 14, 69, 188, 2, 30, 23, 2, 2, 249, 126, 93, 2, 114, 2, 2, 2, 2, 647, 2, 116, 2, 35, 2, 2, 229, 2, 340, 2, 2, 118, 2, 2, 130, 2, 19, 2, 2, 2, 89, 29, 952, 46, 37, 2, 455, 2, 45, 43, 38, 2, 2, 398, 2, 2, 26, 2, 2, 163, 11, 2, 2, 2, 2, 2, 194, 775, 2, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 2, 2, 228, 2, 43, 2, 2, 15, 299, 120, 2, 120, 174, 11, 220, 175, 136, 50, 2, 2, 228, 2, 2, 2, 656, 245, 2, 2, 2, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 2, 2, 371, 78, 22, 625, 64, 2, 2, 2, 168, 145, 23, 2, 2, 15, 16, 2, 2, 2, 28, 2, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([2, 14, 47, 2, 30, 31, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 2, 2, 311, 12, 16, 2, 33, 75, 43, 2, 296, 2, 86, 320, 35, 534, 19, 263, 2, 2, 2, 2, 33, 89, 78, 12, 66, 16, 2, 360, 2, 2, 58, 316, 334, 11, 2, 2, 43, 645, 662, 2, 257, 85, 2, 42, 2, 2, 83, 68, 2, 15, 36, 165, 2, 278, 36, 69, 2, 780, 2, 106, 14, 2, 2, 18, 2, 22, 12, 215, 28, 610, 40, 2, 87, 326, 23, 2, 21, 23, 22, 12, 272, 40, 57, 31, 11, 2, 22, 47, 2, 2, 51, 2, 170, 23, 595, 116, 595, 2, 13, 191, 79, 638, 89, 2, 14, 2, 2, 106, 607, 624, 35, 534, 2, 227, 2, 129, 113]),\n",
       "         ...,\n",
       "         list([2, 11, 2, 230, 245, 2, 2, 2, 2, 446, 2, 45, 2, 84, 2, 2, 21, 2, 912, 84, 2, 325, 725, 134, 2, 2, 84, 2, 36, 28, 57, 2, 21, 2, 140, 2, 703, 2, 2, 84, 56, 18, 2, 14, 2, 31, 2, 2, 2, 2, 2, 2, 2, 18, 2, 20, 207, 110, 563, 12, 2, 2, 2, 2, 97, 2, 20, 53, 2, 74, 2, 460, 364, 2, 29, 270, 11, 960, 108, 45, 40, 29, 2, 395, 11, 2, 2, 500, 2, 2, 89, 364, 70, 29, 140, 2, 64, 2, 11, 2, 2, 26, 178, 2, 529, 443, 2, 2, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 2, 2, 10, 10, 288, 2, 2, 34, 2, 2, 2, 65, 496, 2, 231, 2, 790, 2, 2, 320, 234, 2, 234, 2, 2, 2, 496, 2, 139, 929, 2, 2, 2, 2, 2, 18, 2, 2, 2, 250, 11, 2, 2, 2, 2, 2, 747, 2, 372, 2, 2, 541, 2, 2, 2, 59, 2, 2, 2, 2]),\n",
       "         list([2, 2, 2, 69, 72, 2, 13, 610, 930, 2, 12, 582, 23, 2, 16, 484, 685, 54, 349, 11, 2, 2, 45, 58, 2, 13, 197, 12, 16, 43, 23, 2, 2, 62, 30, 145, 402, 11, 2, 51, 575, 32, 61, 369, 71, 66, 770, 12, 2, 75, 100, 2, 2, 2, 105, 37, 69, 147, 712, 75, 2, 44, 257, 390, 2, 69, 263, 514, 105, 50, 286, 2, 23, 2, 123, 13, 161, 40, 2, 421, 2, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 2, 121, 25, 70, 2, 2, 719, 2, 13, 18, 31, 62, 40, 2, 2, 2, 2, 2, 14, 123, 2, 942, 25, 2, 721, 12, 145, 2, 202, 12, 160, 580, 202, 12, 2, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 2, 15, 251, 2, 2, 12, 38, 84, 80, 124, 12, 2, 23]),\n",
       "         list([2, 17, 2, 194, 337, 2, 2, 204, 22, 45, 254, 2, 106, 14, 123, 2, 2, 270, 2, 2, 2, 2, 732, 2, 101, 405, 39, 14, 2, 2, 2, 2, 115, 50, 305, 12, 47, 2, 168, 2, 235, 2, 38, 111, 699, 102, 2, 2, 2, 2, 2, 24, 2, 78, 2, 17, 2, 2, 21, 27, 2, 2, 2, 2, 2, 92, 2, 2, 2, 2, 2, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 2, 97, 12, 157, 21, 2, 2, 2, 2, 66, 78, 2, 2, 631, 2, 2, 2, 272, 191, 2, 2, 2, 2, 2, 2, 2, 544, 2, 383, 2, 848, 2, 2, 497, 2, 2, 2, 2, 2, 21, 60, 27, 239, 2, 43, 2, 209, 405, 10, 10, 12, 764, 40, 2, 248, 20, 12, 16, 2, 174, 2, 72, 2, 51, 2, 2, 22, 2, 204, 131, 2])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([2, 591, 202, 14, 31, 2, 717, 10, 10, 2, 2, 2, 2, 360, 2, 2, 177, 2, 394, 354, 2, 123, 2, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 2, 124, 14, 286, 170, 2, 157, 46, 2, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 2, 717]),\n",
       "         list([2, 14, 22, 2, 2, 176, 2, 2, 88, 12, 2, 23, 2, 2, 109, 943, 2, 114, 2, 55, 606, 2, 111, 2, 2, 139, 193, 273, 23, 2, 172, 270, 11, 2, 2, 2, 2, 2, 109, 2, 21, 2, 22, 2, 2, 2, 2, 2, 10, 10, 2, 105, 987, 35, 841, 2, 19, 861, 2, 2, 2, 2, 45, 55, 221, 15, 670, 2, 526, 14, 2, 2, 405, 2, 2, 2, 27, 85, 108, 131, 2, 2, 2, 2, 405, 2, 2, 133, 2, 50, 13, 104, 51, 66, 166, 14, 22, 157, 2, 2, 530, 239, 34, 2, 2, 45, 407, 31, 2, 41, 2, 105, 21, 59, 299, 12, 38, 950, 2, 2, 15, 45, 629, 488, 2, 127, 2, 52, 292, 17, 2, 2, 185, 132, 2, 2, 2, 488, 2, 47, 2, 392, 173, 2, 2, 2, 270, 2, 2, 2, 2, 2, 65, 55, 73, 11, 346, 14, 20, 2, 2, 976, 2, 2, 2, 861, 2, 2, 2, 30, 2, 2, 56, 2, 841, 2, 990, 692, 2, 2, 2, 398, 229, 10, 10, 13, 2, 670, 2, 14, 2, 31, 2, 27, 111, 108, 15, 2, 19, 2, 2, 875, 551, 14, 22, 2, 2, 21, 45, 2, 2, 45, 252, 2, 2, 2, 565, 921, 2, 39, 2, 529, 48, 25, 181, 2, 67, 35, 2, 22, 49, 238, 60, 135, 2, 14, 2, 290, 2, 58, 10, 10, 472, 45, 55, 878, 2, 169, 11, 374, 2, 25, 203, 28, 2, 818, 12, 125, 2, 2]),\n",
       "         list([2, 111, 748, 2, 2, 2, 2, 2, 87, 2, 2, 2, 31, 318, 2, 2, 2, 498, 2, 748, 63, 29, 2, 220, 686, 2, 2, 17, 12, 575, 220, 2, 17, 2, 185, 132, 2, 16, 53, 928, 11, 2, 74, 2, 438, 21, 27, 2, 589, 2, 22, 107, 2, 2, 997, 2, 2, 35, 2, 2, 11, 22, 231, 54, 29, 2, 29, 100, 2, 2, 34, 2, 2, 2, 2, 2, 98, 31, 2, 33, 2, 58, 14, 2, 2, 2, 2, 365, 2, 2, 2, 356, 346, 2, 2, 2, 63, 29, 93, 11, 2, 11, 2, 33, 2, 58, 54, 2, 431, 748, 2, 32, 2, 16, 11, 94, 2, 10, 10, 2, 993, 2, 2, 2, 2, 2, 2, 2, 2, 847, 2, 2, 121, 31, 2, 27, 86, 2, 2, 16, 2, 465, 993, 2, 2, 573, 17, 2, 42, 2, 2, 37, 473, 2, 711, 2, 2, 2, 328, 212, 70, 30, 258, 11, 220, 32, 2, 108, 21, 133, 12, 2, 55, 465, 849, 2, 53, 33, 2, 2, 37, 70, 2, 2, 2, 2, 74, 476, 37, 62, 91, 2, 169, 2, 2, 2, 146, 655, 2, 2, 258, 12, 184, 2, 546, 2, 849, 2, 2, 2, 22, 2, 18, 631, 2, 797, 2, 2, 2, 71, 348, 425, 2, 2, 19, 2, 2, 2, 11, 661, 2, 339, 2, 2, 2, 2, 2, 2, 2, 10, 10, 263, 787, 2, 270, 11, 2, 2, 2, 2, 2, 121, 2, 2, 26, 2, 19, 68, 2, 2, 28, 446, 2, 318, 2, 2, 67, 51, 36, 70, 81, 2, 2, 2, 36, 2, 2, 2, 2, 18, 2, 711, 2, 2, 26, 2, 2, 11, 14, 636, 720, 12, 426, 28, 77, 776, 2, 97, 38, 111, 2, 2, 168, 2, 2, 137, 2, 18, 27, 173, 2, 2, 17, 2, 2, 428, 2, 232, 11, 2, 2, 37, 272, 40, 2, 247, 30, 656, 2, 2, 54, 2, 2, 98, 2, 2, 40, 558, 37, 2, 98, 2, 2, 2, 15, 14, 2, 57, 2, 2, 2, 2, 275, 711, 2, 2, 2, 98, 2, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 2, 2, 2, 90, 19, 2, 2, 2, 2, 2, 2, 2, 2, 2, 930, 2, 508, 90, 2, 2, 2, 2, 2, 17, 2, 2, 2, 2, 2, 2, 2, 189, 2, 2, 2, 2, 2, 2, 2, 95, 271, 23, 2, 2, 2, 2, 2, 33, 2, 2, 425, 2, 2, 2, 2, 2, 2, 2, 2, 469, 2, 2, 54, 2, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 2, 27, 2, 2, 2, 68, 2, 19, 2, 2, 2, 2, 2, 263, 65, 2, 34, 2, 2, 2, 43, 159, 29, 2, 2, 2, 387, 73, 195, 584, 10, 10, 2, 2, 58, 810, 54, 14, 2, 117, 22, 16, 93, 2, 2, 2, 192, 15, 12, 16, 93, 34, 2, 2, 2, 33, 2, 2, 2, 15, 2, 2, 2, 325, 12, 62, 30, 776, 2, 67, 14, 17, 2, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 2, 2, 819, 2, 22, 2, 17, 2, 2, 787, 2, 2, 2, 2, 100, 30, 2, 2, 2, 2, 2, 42, 2, 11, 2, 2, 42, 101, 704, 2, 101, 999, 15, 2, 94, 2, 180, 2, 2, 2, 34, 2, 45, 2, 2, 22, 60, 2, 2, 31, 11, 94, 2, 96, 21, 94, 749, 2, 57, 975]),\n",
       "         ...,\n",
       "         list([2, 13, 2, 15, 2, 135, 14, 2, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 2, 2, 910, 769, 2, 2, 395, 2, 2, 2, 11, 119, 2, 89, 2, 2, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 2, 185, 2, 284, 2, 2, 37, 315, 2, 226, 20, 272, 2, 40, 29, 152, 60, 181, 2, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
       "         list([2, 11, 119, 241, 2, 2, 840, 20, 12, 468, 15, 94, 2, 562, 791, 39, 2, 86, 107, 2, 97, 14, 31, 33, 2, 2, 2, 743, 46, 2, 2, 2, 2, 2, 768, 47, 2, 79, 90, 145, 164, 162, 50, 2, 501, 119, 2, 2, 2, 78, 232, 15, 16, 224, 11, 2, 333, 20, 2, 985, 200, 2, 2, 2, 2, 2, 2, 79, 357, 2, 20, 47, 220, 57, 206, 139, 11, 12, 2, 55, 117, 212, 13, 2, 92, 124, 51, 45, 2, 71, 536, 13, 520, 14, 20, 2, 2, 2, 470]),\n",
       "         list([2, 2, 52, 2, 430, 22, 2, 220, 2, 2, 28, 2, 519, 2, 2, 769, 15, 47, 2, 2, 2, 2, 114, 2, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 2, 2, 2, 364, 350, 2, 184, 2, 2, 133, 2, 11, 2, 2, 21, 2, 2, 2, 570, 50, 2, 2, 2, 2, 2, 17, 2, 2, 2, 21, 17, 2, 2, 232, 2, 2, 29, 266, 56, 96, 346, 194, 308, 2, 194, 21, 29, 218, 2, 19, 2, 78, 173, 2, 27, 2, 2, 2, 718, 2, 2, 2, 2, 17, 210, 2, 2, 2, 47, 77, 395, 14, 172, 173, 18, 2, 2, 2, 82, 127, 27, 173, 11, 2, 392, 217, 21, 50, 2, 57, 65, 12, 2, 53, 40, 35, 390, 2, 11, 2, 2, 2, 2, 314, 74, 2, 792, 22, 2, 19, 714, 727, 2, 382, 2, 91, 2, 439, 19, 14, 20, 2, 2, 2, 2, 2, 756, 25, 124, 2, 31, 12, 16, 93, 804, 34, 2, 2])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore the top 10 most frequent words using skip_top\n",
    "\n",
    "imdb.load_data(skip_top=10, num_words=1000, oov_char=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBDAFt0FJDJ3",
    "outputId": "daf96dd1-e131-4522-fd82-e0b1a6d23055"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 13, 1228, 119, 14, 552, 7, 20, 190, 14, 58, 13, 258, 546, 1786, 8, 1968, 4, 268, 237, 13, 191, 81, 15, 13, 80, 43, 3824, 44, 12, 14, 16, 427, 3192, 4, 183, 15, 593, 19, 4, 351, 362, 26, 55, 646, 21, 4, 1239, 84, 26, 1557, 3755, 13, 244, 6, 2071, 132, 184, 194, 5, 13, 70, 4478, 546, 73, 190, 13, 62, 24, 81, 320, 4, 538, 4, 117, 250, 127, 11, 14, 20, 82, 4, 452, 11, 14, 20, 9, 8654, 19, 41, 476, 8, 4, 213, 7, 9185, 13, 657, 13, 286, 38, 1612, 44, 41, 5, 41, 1729, 88, 13, 62, 28, 900, 510, 4, 509, 51, 6, 612, 59, 16, 193, 61, 4666, 5, 702, 930, 143, 285, 25, 67, 41, 81, 366, 4, 130, 82, 9, 259, 334, 397, 1195, 7, 149, 102, 15, 26, 814, 38, 465, 1627, 31, 70, 983, 67, 51, 9, 112, 814, 17, 35, 311, 75, 26, 11649, 574, 19, 4, 1729, 23, 4, 268, 38, 95, 138, 4, 609, 191, 75, 28, 314, 1772]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 0, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit the sequence lengths to 500 using maxlen\n",
    "imdb.load_data(maxlen=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DI-Nr897LorW",
    "outputId": "1ecb6aee-a173-4cd6-c577-b7638afafc46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "         list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "         ...,\n",
       "         list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
       "         list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
       " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 18142, 10698, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 15387, 38, 32, 25, 7944, 451, 202, 14, 6, 717]),\n",
       "         list([1, 14, 22, 3443, 6, 176, 7, 5063, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 7216, 10626, 4, 8463, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 16873, 19, 861, 1074, 5, 1987, 17975, 45, 55, 221, 15, 670, 5304, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 5045, 5304, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 8463, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 6936, 185, 132, 1988, 5304, 1799, 488, 2693, 47, 6, 392, 173, 4, 21686, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 5293, 861, 12746, 5, 4182, 30, 3127, 23651, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 5304, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 7836, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 12508, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 5687, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
       "         list([1, 111, 748, 4368, 1133, 33782, 24563, 4, 87, 1551, 1262, 7, 31, 318, 9459, 7, 4, 498, 5076, 748, 63, 29, 5161, 220, 686, 10941, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 24563, 16, 53, 928, 11, 51278, 74, 4, 438, 21, 27, 10044, 589, 8, 22, 107, 20123, 19550, 997, 1638, 8, 35, 2076, 9019, 11, 22, 231, 54, 29, 1706, 29, 100, 18995, 2425, 34, 12998, 8738, 48078, 5, 19353, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 27608, 1060, 63, 29, 93, 11, 5421, 11, 15236, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 19469, 10, 10, 4, 993, 45222, 7, 4, 1766, 2634, 2164, 24563, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 10760, 16, 6, 465, 993, 2006, 30995, 573, 17, 61862, 42, 4, 17345, 37, 473, 6, 711, 6, 8869, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 5940, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 10104, 146, 655, 2212, 5, 258, 12, 184, 10104, 546, 5, 849, 10333, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 8712, 71, 348, 425, 4320, 1061, 19, 10288, 5, 12141, 11, 661, 8, 339, 17863, 4, 2455, 11434, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 9466, 4, 61862, 48414, 121, 4, 5437, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 7149, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 68411, 25399, 18, 6, 711, 4, 9909, 26, 10296, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 7489, 6175, 168, 1239, 5189, 137, 25399, 18, 27, 173, 9, 2399, 17, 6, 12397, 428, 14657, 232, 11, 4, 8014, 37, 272, 40, 2708, 247, 30, 656, 6, 13182, 54, 25399, 3292, 98, 6, 2840, 40, 558, 37, 6093, 98, 4, 17345, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 7937, 25399, 3292, 98, 6, 31036, 10, 10, 6639, 19, 14, 10241, 267, 162, 711, 37, 5900, 752, 98, 4, 17345, 2378, 90, 19, 6, 73284, 7, 36744, 1810, 77553, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 48414, 17, 15454, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 31036, 6287, 5774, 4, 4770, 5, 95, 271, 23, 6, 7742, 6063, 21627, 5437, 33, 1526, 6, 425, 3155, 33697, 4535, 1636, 7, 4, 4669, 11966, 469, 4, 4552, 54, 4, 150, 5664, 17345, 280, 53, 68411, 25399, 18, 339, 29, 1978, 27, 7885, 5, 17303, 68, 1830, 19, 6571, 14605, 4, 1515, 7, 263, 65, 2132, 34, 6, 5680, 7489, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 6078, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 28228, 33, 4, 5673, 7, 15, 18760, 9252, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 12214, 44, 148, 687, 24563, 203, 42, 203, 24, 28, 69, 32157, 6676, 11, 330, 54, 29, 93, 61862, 21, 845, 14148, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 14967, 787, 7, 2460, 19569, 61862, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 9101, 34, 15205, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 6408, 96, 21, 94, 749, 9, 57, 975]),\n",
       "         ...,\n",
       "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 5093, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 16946, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 60664, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 5518]),\n",
       "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 28739, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
       "         list([1, 6, 52, 7465, 430, 22, 9, 220, 2594, 8, 28, 24357, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 5586, 18020, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 5586, 9, 133, 1810, 11, 5417, 13226, 21, 4, 7298, 42657, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 25194, 27803, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 20067, 5698, 3406, 718, 21264, 9, 6, 6907, 17, 210, 5, 3281, 5677, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 14274, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 16261, 19, 714, 727, 5205, 382, 4, 91, 6533, 439, 19, 14, 20, 9, 1441, 5805, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
       "        dtype=object),\n",
       "  array([0, 1, 1, ..., 0, 0, 0])))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Use '1' as the character that indicates the start of a sequence\n",
    "\n",
    " imdb.load_data(start_char=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuBCKKGyJDJ7"
   },
   "source": [
    "#### Explore the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_gkaFf6MJDJ9"
   },
   "outputs": [],
   "source": [
    "# Load the imdb word index using get_word_index()\n",
    "\n",
    "imdb_word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EUzgAIoKJDKB"
   },
   "outputs": [],
   "source": [
    "# View the word index as a dictionary,\n",
    "# accounting for index_from.\n",
    "index_from = 3\n",
    "imdb_word_index = {\n",
    "    key: value + index_from for key, value in imdb_word_index.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "huCi_QIzJDKL",
    "outputId": "97b6b894-9335-48aa-98c5-ca784bfc5a72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52256"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a specific word's index\n",
    "\n",
    "imdb_word_index[\"simpsonian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7UkZwHiJDKU",
    "outputId": "689ae18e-21a7-41a7-b7c0-22c99096fb10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View an input sentence\n",
    "\n",
    "imdb_word_index[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qq2ID8wRJDKX",
    "outputId": "7486119a-ad67-4ab1-f8b2-a9a07d2e5bae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'film',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'casting',\n",
       " 'location',\n",
       " 'scenery',\n",
       " 'story',\n",
       " 'direction',\n",
       " \"everyone's\",\n",
       " 'really',\n",
       " 'suited',\n",
       " 'the',\n",
       " 'part',\n",
       " 'they',\n",
       " 'played',\n",
       " 'and',\n",
       " 'you',\n",
       " 'could',\n",
       " 'just',\n",
       " 'imagine',\n",
       " 'being',\n",
       " 'there',\n",
       " 'robert',\n",
       " \"redford's\",\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'same',\n",
       " 'being',\n",
       " 'director',\n",
       " \"norman's\",\n",
       " 'father',\n",
       " 'came',\n",
       " 'from',\n",
       " 'the',\n",
       " 'same',\n",
       " 'scottish',\n",
       " 'island',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'so',\n",
       " 'i',\n",
       " 'loved',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'real',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " 'the',\n",
       " 'witty',\n",
       " 'remarks',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'film',\n",
       " 'were',\n",
       " 'great',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'film',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'it',\n",
       " 'was',\n",
       " 'released',\n",
       " 'for',\n",
       " 'retail',\n",
       " 'and',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'it',\n",
       " 'to',\n",
       " 'everyone',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fly',\n",
       " 'fishing',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'really',\n",
       " 'cried',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'if',\n",
       " 'you',\n",
       " 'cry',\n",
       " 'at',\n",
       " 'a',\n",
       " 'film',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'good',\n",
       " 'and',\n",
       " 'this',\n",
       " 'definitely',\n",
       " 'was',\n",
       " 'also',\n",
       " 'congratulations',\n",
       " 'to',\n",
       " 'the',\n",
       " 'two',\n",
       " 'little',\n",
       " \"boy's\",\n",
       " 'that',\n",
       " 'played',\n",
       " 'the',\n",
       " \"part's\",\n",
       " 'of',\n",
       " 'norman',\n",
       " 'and',\n",
       " 'paul',\n",
       " 'they',\n",
       " 'were',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'children',\n",
       " 'are',\n",
       " 'often',\n",
       " 'left',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'praising',\n",
       " 'list',\n",
       " 'i',\n",
       " 'think',\n",
       " 'because',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'play',\n",
       " 'them',\n",
       " 'all',\n",
       " 'grown',\n",
       " 'up',\n",
       " 'are',\n",
       " 'such',\n",
       " 'a',\n",
       " 'big',\n",
       " 'profile',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'but',\n",
       " 'these',\n",
       " 'children',\n",
       " 'are',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'praised',\n",
       " 'for',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'think',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'story',\n",
       " 'was',\n",
       " 'so',\n",
       " 'lovely',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'true',\n",
       " 'and',\n",
       " 'was',\n",
       " \"someone's\",\n",
       " 'life',\n",
       " 'after',\n",
       " 'all',\n",
       " 'that',\n",
       " 'was',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sentiment value\n",
    "\n",
    "inv_imdb_word_index = {\n",
    "    value: key for key, value in imdb_word_index.items()\n",
    "}\n",
    "\n",
    "[inv_imdb_word_index[index] for index in x_train[0] if index > index_from]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcPUtmz-JDKZ"
   },
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Padding and Masking Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UggNd-8VLgV",
    "outputId": "1459fa9d-b344-4a0b-c683-5ff171e03e45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Load the imdb data set\n",
    "\n",
    "(x_train, y_train), (x_test, y_train) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuqWhXi-JDKa"
   },
   "source": [
    "#### Preprocess the data with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWULtJ7CJDKe",
    "outputId": "9c33a9d8-014c-44b9-e024-38f6ac10e014"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the input data shape\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OOts_k01JDKh"
   },
   "outputs": [],
   "source": [
    "# Pad the inputs to the maximum length using maxlen\n",
    "\n",
    "padded_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=300, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNPiMGwDJDKk",
    "outputId": "1b07dc29-c1c2-461f-e0ca-fd054adb0371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the output data shape\n",
    "\n",
    "padded_x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJt56letJDKn"
   },
   "source": [
    "#### Create a Masking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZdoMdifYJDKo"
   },
   "outputs": [],
   "source": [
    "# Import numpy \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "v8LjX9QaJDKr"
   },
   "outputs": [],
   "source": [
    "# Masking expects to see (batch, sequence, features)\n",
    "# Create a dummy feature dimension using expand_dims\n",
    "\n",
    "padded_x_train = np.expand_dims(padded_x_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "uFrgXbDrJDKt"
   },
   "outputs": [],
   "source": [
    "# Create a Masking layer \n",
    "tf_x_train = tf.convert_to_tensor(padded_x_train, dtype=\"float32\")\n",
    "masking_layer = tf.keras.layers.Masking(mask_value=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9kkSzdHwJDKw"
   },
   "outputs": [],
   "source": [
    "# Pass tf_x_train to it\n",
    "masked_x_train = masking_layer(tf_x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MuStn9s0JDK0",
    "outputId": "c343051a-fafc-4c8d-961f-8f007dc48824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25000, 300, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the dataset\n",
    "masked_x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O54DVLx4JDK7",
    "outputId": "f3664b0b-f95c-4626-d061-7afb72d020da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25000, 300), dtype=bool, numpy=\n",
       "array([[False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True]])>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the ._keras_mask for the dataset\n",
    "\n",
    "masked_x_train._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo5rD5ZcJDK_"
   },
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## The Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCkBOM8mJDLA"
   },
   "source": [
    "#### Create and apply an `Embedding` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "D-esPcdDJDLJ"
   },
   "outputs": [],
   "source": [
    "# Create an embedding layer using layers.Embedding\n",
    "# Specify input_dim, output_dim, input_length\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=501,  output_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sf3B6HamJDLN",
    "outputId": "6fa3d6bd-3c8c-45d9-f1d2-dbac4646af6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 1, 16), dtype=float32, numpy=\n",
       "array([[[[ 0.02094739,  0.00103117, -0.01703463,  0.01034521,\n",
       "          -0.04114103,  0.04232563, -0.02008139,  0.01831988,\n",
       "           0.00337379,  0.02405358, -0.04276301,  0.02080414,\n",
       "           0.01928044, -0.02518438, -0.02070094, -0.03913722]],\n",
       "\n",
       "        [[ 0.00651466, -0.00593676, -0.0313101 , -0.01466116,\n",
       "          -0.04423263, -0.03219112, -0.04983497,  0.04698278,\n",
       "          -0.04969071, -0.022656  , -0.02338659, -0.04076099,\n",
       "           0.00961256,  0.02958396,  0.0299066 , -0.01210193]],\n",
       "\n",
       "        [[-0.01098968,  0.02155801,  0.03721699, -0.0318867 ,\n",
       "           0.02241817, -0.00224588, -0.01508214,  0.03250315,\n",
       "           0.03087569,  0.04693658, -0.02676847,  0.00187502,\n",
       "          -0.0261374 ,  0.01477842, -0.03070632,  0.03437871]],\n",
       "\n",
       "        [[-0.03601196,  0.01025336, -0.01942555,  0.0177735 ,\n",
       "          -0.01744779,  0.04866245, -0.03369596,  0.03402552,\n",
       "           0.04336366,  0.02307408, -0.00262952,  0.02538956,\n",
       "           0.02268143, -0.04732613, -0.02471091,  0.02023405]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an Embedding layer output for a fixed input\n",
    "# Expects an input of shape (batch, sequence, feature)\n",
    "\n",
    "sequence_of_indices = tf.constant([[[0], [1], [5], [500]]])\n",
    "# (batch, sequence, features)\n",
    "sequence_of_embeddings = embedding_layer(sequence_of_indices)\n",
    "sequence_of_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ualmsaPpJDLV",
    "outputId": "f44f6595-edec-4936-e3cc-f66defe96bca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02094739,  0.00103117, -0.01703463, ..., -0.02518438,\n",
       "        -0.02070094, -0.03913722],\n",
       "       [ 0.00651466, -0.00593676, -0.0313101 , ...,  0.02958396,\n",
       "         0.0299066 , -0.01210193],\n",
       "       [-0.01800198,  0.03329739,  0.01884109, ...,  0.03933907,\n",
       "        -0.00898697,  0.02709362],\n",
       "       ...,\n",
       "       [ 0.0225425 ,  0.01220075, -0.0168062 , ..., -0.01129008,\n",
       "        -0.03539677,  0.01475897],\n",
       "       [-0.00762861,  0.01559135, -0.02340034, ..., -0.02590054,\n",
       "         0.04010576, -0.04713123],\n",
       "       [-0.03601196,  0.01025336, -0.01942555, ..., -0.04732613,\n",
       "        -0.02471091,  0.02023405]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the Embedding layer weights using get_weights()\n",
    "\n",
    "embedding_layer.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Wadlt3AJDLX",
    "outputId": "9dc246ed-4502-4374-97ae-156acf94a24c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9873107e-02,  4.3293666e-02,  1.4100123e-02, -4.7230769e-02,\n",
       "       -1.7029215e-02, -2.4494423e-02, -7.6318607e-03, -1.3154935e-02,\n",
       "        4.2943705e-02, -9.8787248e-05,  4.3804076e-02,  3.9738204e-02,\n",
       "       -3.4901928e-02,  1.0875821e-02, -3.3654571e-03,  4.9857806e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embedding for the 14th index\n",
    "\n",
    "embedding_layer.get_weights()[0][14, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFuhReOm9xF7"
   },
   "source": [
    "#### Create and apply an `Embedding` layer that uses `mask_zero=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "nKYwKT_I-H2O"
   },
   "outputs": [],
   "source": [
    "# Create a layer that uses the mask_zero kwarg\n",
    "masking_embedding_layer = tf.keras.layers.Embedding(input_dim=501,  output_dim=16, mask_zero=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hc1zx6A-H6R",
    "outputId": "d12c2fcb-2059-4967-e615-88383e09d32b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05305466237942122"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply this layer to the sequence and see the _keras_mask property\n",
    "\n",
    "masked_sequence_of_embeddings = masking_embedding_layer(sequence_of_indices)\n",
    "masked_sequence_of_embeddings._keras_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUG6LF1MJDL0"
   },
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## The Embedding Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zna3TCoTAu00"
   },
   "source": [
    "#### Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPKYrlepAxPV",
    "outputId": "7d37e787-36bf-4781-ef55-884d10fcf235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBAX9ENDBFFE"
   },
   "source": [
    "#### Load and preprocess the IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "yo5qBbDDBIdn"
   },
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGpymnb2BIiR",
    "outputId": "3f4571fd-c325-4167-fbe8-bba874a41094"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "5EtU2vK0BLts"
   },
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "vtkIEIdRBSxv"
   },
   "outputs": [],
   "source": [
    "# Get the word index\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Ur2fp10YBS6T"
   },
   "outputs": [],
   "source": [
    "# Swap the keys and values of the word index\n",
    "\n",
    "inv_imdb_word_index = {\n",
    "    value: key for key, value in imdb_word_index.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cquirCA8BS99",
    "outputId": "226525ff-bceb-4072-d6ae-fe8fa44bc72a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'and',\n",
       " 'have',\n",
       " 'everything',\n",
       " 'that',\n",
       " \"he's\",\n",
       " 'made',\n",
       " 'on',\n",
       " 'dvd',\n",
       " 'except',\n",
       " 'for',\n",
       " 'hotel',\n",
       " 'room',\n",
       " 'the',\n",
       " '2',\n",
       " 'hour',\n",
       " 'twin',\n",
       " 'peaks',\n",
       " 'movie',\n",
       " 'so',\n",
       " 'when',\n",
       " 'i',\n",
       " 'found',\n",
       " 'out',\n",
       " 'about',\n",
       " 'this',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'grabbed',\n",
       " 'it',\n",
       " 'and',\n",
       " 'and',\n",
       " 'what',\n",
       " 'is',\n",
       " 'this',\n",
       " \"it's\",\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'drawn',\n",
       " 'black',\n",
       " 'and',\n",
       " 'white',\n",
       " 'cartoons',\n",
       " 'that',\n",
       " 'are',\n",
       " 'loud',\n",
       " 'and',\n",
       " 'foul',\n",
       " 'mouthed',\n",
       " 'and',\n",
       " 'unfunny',\n",
       " 'maybe',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " \"what's\",\n",
       " 'good',\n",
       " 'but',\n",
       " 'maybe',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'crap',\n",
       " 'that',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'public',\n",
       " 'under',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'david',\n",
       " 'lynch',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'few',\n",
       " 'bucks',\n",
       " 'too',\n",
       " 'let',\n",
       " 'me',\n",
       " 'make',\n",
       " 'it',\n",
       " 'clear',\n",
       " 'that',\n",
       " 'i',\n",
       " \"didn't\",\n",
       " 'care',\n",
       " 'about',\n",
       " 'the',\n",
       " 'foul',\n",
       " 'language',\n",
       " 'part',\n",
       " 'but',\n",
       " 'had',\n",
       " 'to',\n",
       " 'keep',\n",
       " 'the',\n",
       " 'sound',\n",
       " 'because',\n",
       " 'my',\n",
       " 'neighbors',\n",
       " 'might',\n",
       " 'have',\n",
       " 'all',\n",
       " 'in',\n",
       " 'all',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'highly',\n",
       " 'disappointing',\n",
       " 'release',\n",
       " 'and',\n",
       " 'may',\n",
       " 'well',\n",
       " 'have',\n",
       " 'just',\n",
       " 'been',\n",
       " 'left',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " 'set',\n",
       " 'as',\n",
       " 'a',\n",
       " 'curiosity',\n",
       " 'i',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'you',\n",
       " \"don't\",\n",
       " 'spend',\n",
       " 'your',\n",
       " 'money',\n",
       " 'on',\n",
       " 'this',\n",
       " '2',\n",
       " 'out',\n",
       " 'of',\n",
       " '10']"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first dataset example sentence\n",
    "\n",
    "[inv_imdb_word_index[index] for index in x_train[100] if index > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrE0rpCVJDL1"
   },
   "source": [
    "#### Build an Embedding layer into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "UPUfv9kjJDL1"
   },
   "outputs": [],
   "source": [
    "# Get the maximum token value\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "lO0CkecjJDL5"
   },
   "outputs": [],
   "source": [
    "# Specify an embedding dimension\n",
    "\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "oFBZOlp3JDL7"
   },
   "outputs": [],
   "source": [
    "# Build a model using Sequential:\n",
    "#     1. Embedding layer\n",
    "#     2. GlobalAveragePooling1D\n",
    "#     3. Dense\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value + 1, output_dim=embedding_dim, mask_zero=False),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Kw9qhtlPJDL9"
   },
   "outputs": [],
   "source": [
    "# Functional API refresher: use the Model to build the same model\n",
    "\n",
    "review_sequence = tf.keras.Input((None, ))\n",
    "embedding_sequence = tf.keras.layers.Embedding(\n",
    "    input_dim=max_index_value+1, output_dim=embedding_dim\n",
    ")(review_sequence)\n",
    "average_embedding = tf.keras.layers.GlobalAveragePooling1D()(embedding_sequence)\n",
    "positive_probability = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(average_embedding)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=review_sequence, outputs=positive_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rf6oaEvTCKxV",
    "outputId": "678cab36-b37e-4886-9235-5402b878d64b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrX43gwPJDL-"
   },
   "source": [
    "#### Compile, train, and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "mVfI_1EoJDL_"
   },
   "outputs": [],
   "source": [
    "# Compile the model with a binary cross-entropy loss\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvR-O7wGJDMC",
    "outputId": "57806d74-18a1-4ba6-ee44-2a43b8398c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 8s 9ms/step - loss: 0.6920 - accuracy: 0.5273 - val_loss: 0.6841 - val_accuracy: 0.6422\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.6779 - accuracy: 0.6778 - val_loss: 0.6512 - val_accuracy: 0.7281\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.6387 - accuracy: 0.7243 - val_loss: 0.6001 - val_accuracy: 0.7609\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5861 - accuracy: 0.7846 - val_loss: 0.5496 - val_accuracy: 0.7875\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5331 - accuracy: 0.8153 - val_loss: 0.5053 - val_accuracy: 0.8031\n"
     ]
    }
   ],
   "source": [
    "# Train the model using .fit(), savng its history\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=5, batch_size=32,\n",
    "    validation_data=(x_test, y_test),\n",
    "    validation_steps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "Ind0d_gvJDMG",
    "outputId": "453a2011-f34a-4381-af5d-800bda0c3ee8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHcNqGnWJDMH"
   },
   "source": [
    "#### The TensorFlow embedding projector\n",
    "\n",
    "The Tensorflow embedding projector can be found [here](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVP4G9X0JDMH",
    "outputId": "2a9143c8-920f-45f7-f769-92afc8c51ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.04380768, -0.00910871,  0.02553733, ..., -0.00192716,\n",
       "        -0.03160537,  0.00782399],\n",
       "       [ 0.01486811,  0.03561668,  0.00256975, ...,  0.03882383,\n",
       "        -0.00169328, -0.06155381],\n",
       "       [ 0.03650168, -0.01487766, -0.03603707, ..., -0.02597174,\n",
       "        -0.00514681,  0.05686932],\n",
       "       ...,\n",
       "       [ 0.2474533 , -0.3336656 ,  0.32198718, ..., -0.29823   ,\n",
       "        -0.34687227,  0.3662498 ],\n",
       "       [ 0.15369202, -0.09670065,  0.0763182 , ..., -0.18659571,\n",
       "        -0.13934287,  0.09386985],\n",
       "       [ 0.01914991,  0.02971189, -0.02525959, ...,  0.0484804 ,\n",
       "        -0.0392632 , -0.00433008]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the embedding layer's weights from the trained model\n",
    "print(len(model.layers))\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "yHd29nfZJDMJ"
   },
   "outputs": [],
   "source": [
    "# Save the word Embeddings to tsv files\n",
    "# Two files: \n",
    "#     one contains the embedding labels (meta.tsv),\n",
    "#     one contains the embeddings (vecs.tsv)\n",
    "\n",
    "import io\n",
    "from os import path\n",
    "\n",
    "out_v = io.open(path.join('data', 'vecs.tsv'), 'w', encoding='utf-8')\n",
    "out_m = io.open(path.join('data', 'meta.tsv'), 'w', encoding='utf-8')\n",
    "\n",
    "k = 0\n",
    "\n",
    "for word, token in imdb_word_index.items():\n",
    "    if k != 0:\n",
    "        out_m.write('\\n')\n",
    "        out_v.write('\\n')\n",
    "    \n",
    "    out_v.write('\\t'.join([str(x) for x in weights[token]]))\n",
    "    out_m.write(word)\n",
    "    k += 1\n",
    "    \n",
    "out_v.close()\n",
    "out_m.close()\n",
    "# beware large collections of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ti4kMquJDML"
   },
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## Recurrent neural network layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hrm6Q2jJDMM"
   },
   "source": [
    "#### Initialize and pass an input to a SimpleRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "tM7uSwkQJDMR"
   },
   "outputs": [],
   "source": [
    "# Create a SimpleRNN layer and test it\n",
    "# Shape of input is (batch, sequence, features)\n",
    "\n",
    "simplernn_layer = tf.keras.layers.SimpleRNN(units=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_YJUyrEJDMT",
    "outputId": "4dfde9b7-14b9-4e39-abb8-ae9678ff6cf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[-1.       ,  1.       , -1.       ,  0.9999988,  1.       ,\n",
       "         1.       ,  1.       , -1.       , -1.       , -1.       ,\n",
       "        -1.       , -1.       ,  1.       , -0.9992302,  1.       ,\n",
       "         1.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that only the final cell output is returned\n",
    "\n",
    "sequence = tf.constant([[[1., 1.], [2., 2.], [56., -100.]]])\n",
    "layer_output = simplernn_layer(sequence)\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_rwdZtmJDMV"
   },
   "source": [
    "#### Load and transform the IMDB review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "qvAtycIpH1aA"
   },
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49rJuSFmJDMV",
    "outputId": "7a2538cc-0fe2-469d-a520-11d7d6c109b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "XwUHcFKwH4wh"
   },
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "KfyqmfOXJDMX"
   },
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR7y1e-xJDMd"
   },
   "source": [
    "#### Create a recurrent neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "Tym76m2dIVOZ"
   },
   "outputs": [],
   "source": [
    "# Get the maximum index value\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "2tO953-oJDMd"
   },
   "outputs": [],
   "source": [
    "# Using Sequential, build the model:\n",
    "# 1. Embedding.\n",
    "# 2. LSTM.\n",
    "# 3. Dense.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value + 1, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(units=16),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")                            \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v076l5CUJDMf"
   },
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "iRRXW5mPJDMg"
   },
   "outputs": [],
   "source": [
    "# Compile the model with binary cross-entropy loss\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    optimizer=\"adam\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "216PeHZFJDMi",
    "outputId": "383f6771-02da-4a4d-c5da-189cca1bd433"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "536/536 [==============================] - 72s 125ms/step - loss: 0.5631 - accuracy: 0.6892\n",
      "Epoch 2/3\n",
      "536/536 [==============================] - 66s 123ms/step - loss: 0.2300 - accuracy: 0.9157\n",
      "Epoch 3/3\n",
      "536/536 [==============================] - 65s 121ms/step - loss: 0.1502 - accuracy: 0.9520\n"
     ]
    }
   ],
   "source": [
    "# Fit the model and save its training history\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DITL7BKauHS3",
    "outputId": "f985455e-d5da-47d4-8ef4-00f749ae22c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NVXF1TSJDMj"
   },
   "source": [
    "#### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "ms9VW07lJDMk",
    "outputId": "34e6a113-e304-48dd-f15a-c21e0fd68d1a"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-14f5d334cc79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0macc\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mval_acc\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mloss\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    }
   ],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AAyEd6wJDMm"
   },
   "source": [
    "#### Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sk9CHYLiJDMo",
    "outputId": "72a62d01-ca8c-46fc-aa05-50da4fac27b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['please',\n",
       " 'give',\n",
       " 'this',\n",
       " 'one',\n",
       " 'a',\n",
       " 'miss',\n",
       " 'br',\n",
       " 'br',\n",
       " 'and',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cast',\n",
       " 'rendered',\n",
       " 'terrible',\n",
       " 'performances',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'flat',\n",
       " 'flat',\n",
       " 'flat',\n",
       " 'br',\n",
       " 'br',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'how',\n",
       " 'michael',\n",
       " 'madison',\n",
       " 'could',\n",
       " 'have',\n",
       " 'allowed',\n",
       " 'this',\n",
       " 'one',\n",
       " 'on',\n",
       " 'his',\n",
       " 'plate',\n",
       " 'he',\n",
       " 'almost',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'know',\n",
       " 'this',\n",
       " \"wasn't\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'work',\n",
       " 'out',\n",
       " 'and',\n",
       " 'his',\n",
       " 'performance',\n",
       " 'was',\n",
       " 'quite',\n",
       " 'so',\n",
       " 'all',\n",
       " 'you',\n",
       " 'madison',\n",
       " 'fans',\n",
       " 'give',\n",
       " 'this',\n",
       " 'a',\n",
       " 'miss']"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first test data example sentence\n",
    "# (invert the word index)\n",
    "\n",
    "inv_imdb_word_index = {\n",
    "    value: key for key, value in imdb_word_index.items()\n",
    "}\n",
    "[inv_imdb_word_index[index] for index in x_test[0] if index > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Blf6in2dJDMs",
    "outputId": "67a37327-d7cf-41bd-cb23-4dc65b176d54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03277346]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model prediction using model.predict()\n",
    "\n",
    "model.predict(x_test[None, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCyKBsZHJDMt",
    "outputId": "27fe90eb-7454-4735-94fa-7bb132519be5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the corresponding label\n",
    "y_test[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpaI83PlJDMv"
   },
   "source": [
    "---\n",
    "<a id=\"coding_tutorial_6\"></a>\n",
    "## Stacked RNNs and the Bidirectional wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Qr4kOevKRt8"
   },
   "source": [
    "#### Load and transform the IMDb review sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "i06LdJiXKRt9"
   },
   "outputs": [],
   "source": [
    "# A function to load and preprocess the IMDB dataset\n",
    "\n",
    "def get_and_pad_imdb_dataset(num_words=10000, maxlen=None, index_from=2):\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Load the reviews\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(path='imdb.npz',\n",
    "                                                          num_words=num_words,\n",
    "                                                          skip_top=0,\n",
    "                                                          maxlen=maxlen,\n",
    "                                                          start_char=1,\n",
    "                                                          oov_char=2,\n",
    "                                                          index_from=index_from)\n",
    "\n",
    "    x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        maxlen=None,\n",
    "                                                        padding='pre',\n",
    "                                                        truncating='pre',\n",
    "                                                        value=0)\n",
    "    \n",
    "    x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                           maxlen=None,\n",
    "                                                           padding='pre',\n",
    "                                                           truncating='pre',\n",
    "                                                           value=0)\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjA8JlQVKRuB",
    "outputId": "77bd97d8-033f-4c5f-c3ef-67701ef23179"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_and_pad_imdb_dataset(maxlen=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "7iBFGx9_KRuD"
   },
   "outputs": [],
   "source": [
    "# A function to get the dataset word index\n",
    "\n",
    "def get_imdb_word_index(num_words=10000, index_from=2):\n",
    "    imdb_word_index = tf.keras.datasets.imdb.get_word_index(\n",
    "                                        path='imdb_word_index.json')\n",
    "    imdb_word_index = {key: value + index_from for\n",
    "                       key, value in imdb_word_index.items() if value <= num_words-index_from}\n",
    "    return imdb_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "29lcV0UGKRuF"
   },
   "outputs": [],
   "source": [
    "# Get the word index using get_imdb_word_index()\n",
    "\n",
    "imdb_word_index = get_imdb_word_index(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lh_Vv9-5JDM1"
   },
   "source": [
    "#### Build stacked and bidirectional recurrent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6Sy-gMyLLEI"
   },
   "outputs": [],
   "source": [
    "# Get the maximum index value and specify an embedding dimension\n",
    "\n",
    "max_index_value = max(imdb_word_index.values())\n",
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89yWIAFdJDM1"
   },
   "outputs": [],
   "source": [
    "# Using Sequential, build a stacked LSTM model via return_sequences=True\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-34ZWvRJDM3"
   },
   "outputs": [],
   "source": [
    "# Using Sequential, build a bidirectional RNN with merge_mode='sum'\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        layer=tf.keras.layers.LSTM(8, return_sequences=False), \n",
    "        backward_layer=tf.keras.layers.GRU(8, go_backwards=True)\n",
    "        merge_mode=\"sum\"\n",
    "    ),\n",
    "    # tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "mSpOIOCmJDM4"
   },
   "outputs": [],
   "source": [
    "# Create a model featuring both stacked recurrent layers and a bidirectional layer\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_index_value, output_dim=embedding_dim, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(8, return_sequences=True), \n",
    "        merge_mode=\"concat\"\n",
    "    ),\n",
    "    tf.keras.layers.GRU(8, return_sequences=False),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3srEhqCJDM7"
   },
   "source": [
    "#### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "k5Dy_C6-JDM7"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    optimizer=\"adam\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Er8atiBoJDM9",
    "outputId": "06443e30-c259-40ed-f8a4-c5bec38212ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "536/536 [==============================] - 174s 303ms/step - loss: 0.5521 - accuracy: 0.6703\n",
      "Epoch 2/3\n",
      "536/536 [==============================] - 164s 306ms/step - loss: 0.2168 - accuracy: 0.9199\n",
      "Epoch 3/3\n",
      "536/536 [==============================] - 163s 304ms/step - loss: 0.1371 - accuracy: 0.9550\n"
     ]
    }
   ],
   "source": [
    "# Train the model, saving its history\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLOLtBKwJDNA"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc      = history_dict['accuracy']\n",
    "val_acc  = history_dict['val_accuracy']\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(epochs, acc, marker='.', label='Training acc')\n",
    "plt.plot(epochs, val_acc, marker='.', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim(0, 1);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9b3PNw3gJDI7",
    "hcPUtmz-JDKZ",
    "Zo5rD5ZcJDK_",
    "NrE0rpCVJDL1",
    "yrX43gwPJDL-",
    "MHcNqGnWJDMH",
    "9Ti4kMquJDML",
    "jR7y1e-xJDMd",
    "H3srEhqCJDM7"
   ],
   "name": "icl_c2_w3_tutorials.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
