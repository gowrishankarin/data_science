{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "import transformers\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 10\n",
    "ACCUMULATION = 2\n",
    "BERT_PATH = \"../input/bert_base_uncased\"\n",
    "MODEL_PATH = \"model.bin\"\n",
    "TRAINING_FILE = \"../input/imdb.csv\"\n",
    "TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
    "    BERT_PATH,\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTBaseUncased(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTBaseUncased, self).__init__()\n",
    "        self.bert = transformers.BertModel.from_pretrained(\n",
    "            config.BERT_PATH\n",
    "        )\n",
    "        self.bert_drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(768, 1) # Binary classification problem with 768 classes\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids): # Attention mask\n",
    "        _, o2 = self.bert( # Sequence of hidden state for every token, cls token of BERT of last hidden state\n",
    "            ids, \n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        bo = self.bert_drop(o2)\n",
    "        output = self.out(bo)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine.py\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
    "\n",
    "\n",
    "def train_fn(data_loader, model, optimizer, device, scheduler, accumulation_steps):\n",
    "    model.train()\n",
    "    \n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"targets\"]\n",
    "        \n",
    "        ids  = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids  = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask  = mask.to(device, dtype=torch.long)\n",
    "        targets  = targets.to(device, dtype=torch.float)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            ids = ids,\n",
    "            mask = mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        # if(bi + 1) % accumulation_steps == 0:\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "            \n",
    "            \n",
    "    \n",
    "def evan_fun(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids  = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids  = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask  = mask.to(device, dtype=torch.long)\n",
    "            targets  = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(\n",
    "                ids = ids,\n",
    "                mask = mask,\n",
    "                token_type_ids = token_type_ids\n",
    "            )\n",
    "            fin_targest.extend(\n",
    "                targets.cpu().detach().numpy().tolist()\n",
    "            )\n",
    "            fin_outputs.extend(\n",
    "                torch.sigmoid(outputs).cpu().detach().numpy().tolist()\n",
    "            )\n",
    "            \n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.py\n",
    "import config\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BERTDataset:\n",
    "    def __init__(self, review, target):\n",
    "        self.review = review\n",
    "        self.target = target\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.max_len = config.MAX_LEN\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.review)\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.review)\n",
    "        review = \" \".join(review.split())\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        padding_length = self.max_len - len(ids)\n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long), \n",
    "            'mask': torch.tensor(mask, dtype=torch.long), \n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.target[item], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import config\n",
    "import pandas as pd\n",
    "#import dataset\n",
    "# import engine\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from transformers import AdamW\n",
    "# from model import BERTBaseUncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.__version__\n",
    "from transformers import get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'sentiment'], dtype='object')\n",
      "Index(['review', 'sentiment'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/5625 [03:35<68:26:40, 43.85s/it]"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    dfx = pd.read_csv(config.TRAINING_FILE).fillna(\"none\")\n",
    "    print(dfx.columns)\n",
    "    dfx.sentiment = dfx.sentiment.apply(\n",
    "        lambda x: 1 if x == \"positive\" else 0\n",
    "    )\n",
    "    \n",
    "    df_train, df_valid = model_selection.train_test_split(\n",
    "        dfx,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "        stratify=dfx.sentiment.values\n",
    "    )\n",
    "    print(df_valid.columns)\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_valid = df_valid.reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = BERTDataset(\n",
    "        review=df_train.review.values,\n",
    "        target=df_train.sentiment.values\n",
    "    )\n",
    "    \n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.TRAIN_BATCH_SIZE,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    valid_dataset = BERTDataset(\n",
    "        review=df_valid.review.values,\n",
    "        target=df_valid.sentiment.values\n",
    "    )\n",
    "    \n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.VALID_BATCH_SIZE,\n",
    "        num_workers=1\n",
    "    )\n",
    "    \n",
    "    device = torch.device(\"cpu\")\n",
    "    model = BERTBaseUncased()\n",
    "    model.to(device)\n",
    "    \n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    #print(param_optimizer)\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001\n",
    "        }, {\n",
    "            'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    #print(optimizer_parameters)\n",
    "    \n",
    "    num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "    \n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    \n",
    "    #print()\n",
    "    #print(tqdm(enumerate(train_data_loader), len(train_data_loader)))\n",
    "    \n",
    "    for epoch in range(config.EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler, accumulation_steps=ACCUMULATION)\n",
    "        outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "        outputs = np.array(outputs) >= 0.5\n",
    "        accuracy = metrics.accuracy_score(targets, outputs)\n",
    "        print(f\"Accuracy Score = {accuracy}\")\n",
    "        \n",
    "        if(accuracy > best_accuracy):\n",
    "            torch.save(model.state_dict(), config.MODEL_PATH)\n",
    "            best_accuracy = accuracy\n",
    "            \n",
    "            \n",
    "#if __name__ == \"__main__\":\n",
    "#    run()\n",
    "run()   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6106.404545454545"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67170.45/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App.py\n",
    "\n",
    "from flask import Flask\n",
    "from flask import Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_prediction(sentence, model=MODEL):\n",
    "    tokenizer = TOKENIZER\n",
    "    max_length = MAX_LEN\n",
    "    review = str(sentence)\n",
    "    \n",
    "    review = \" \".join(review.split())\n",
    "        \n",
    "    inputs = self.tokenizer.encode_plus(\n",
    "        review,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        pad_to_max_length=True\n",
    "    )\n",
    "    ids = inputs[\"input_ids\"]\n",
    "    mask = inputs[\"attention_mask\"]\n",
    "    token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "    padding_length = self.max_len - len(ids)\n",
    "    ids = ids + ([0] * padding_length)\n",
    "    mask = mask + ([0] * padding_length)\n",
    "    token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "\n",
    "    ids: torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n",
    "    mask: torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n",
    "    token_type_ids: torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0)\n",
    "        \n",
    "    ids  = ids.to(device, dtype=torch.long)\n",
    "    token_type_ids  = token_type_ids.to(device, dtype=torch.long)\n",
    "    mask  = mask.to(device, dtype=torch.long)\n",
    "\n",
    "    outputs = model(\n",
    "        ids = ids,\n",
    "        mask = mask,\n",
    "        token_type_ids = token_type_ids\n",
    "    )\n",
    "    outputs = torch.sigmoid(outputs).cpu().detach().numpy()\n",
    "    return outputs[0][0]\n",
    "\n",
    "@app.route(\"predict\")\n",
    "def predict():\n",
    "    sentence = request.args.get(\"sentence\")\n",
    "    positive_prediction = sentence_prediction(sentence)\n",
    "    negative_prediction = 1 - positive_prediction\n",
    "    response = {}\n",
    "    response[\"response\"] = {\n",
    "        'positiive': str(positive_prediction),\n",
    "        'negative': str(negative_prediction),\n",
    "        'sentence': str(sentence)\n",
    "        \n",
    "    }\n",
    "    return flask.jsonify(response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MODEL = BERTBaseUncased()\n",
    "    MODEL = nn.DataParallel(MODEL)\n",
    "    MODEL.load_state_dict(torch.load(config.MODEL_PATH))\n",
    "    MODEL.to(DEVICE)\n",
    "    MODEL.eval()\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
