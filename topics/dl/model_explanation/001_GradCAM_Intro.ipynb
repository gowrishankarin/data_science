{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "!wget https://raw.githubusercontent.com/jacobgil/keras-grad-cam/master/examples/cat_dog.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = keras.preprocessing.image.load_img(path, target_size=(224, 224))\n",
    "    x = keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = keras.applications.vgg16.preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242\n"
     ]
    }
   ],
   "source": [
    "preprocessed_input = load_image(\"cat_dog.png\")\n",
    "model = keras.applications.vgg16.VGG16(weights='imagenet')\n",
    "predictions = model.predict(preprocessed_input)    \n",
    "indexx = np.argmax(predictions[0])\n",
    "print(indexx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class:\n",
      "boxer (n02108089) with probability 0.42\n"
     ]
    }
   ],
   "source": [
    "top_1 = keras.applications.vgg16.decode_predictions(predictions)[0][0]\n",
    "print('Predicted class:')\n",
    "print('%s (%s) with probability %.2f' % (top_1[1], top_1[0], top_1[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, keras.backend.one_hot([category_index], nb_classes))\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def normalize(x):\n",
    "    return x / (keras.backend.sqrt(keras.backend.mean(keras.backend.square(x))) + 1e-5)\n",
    "\n",
    "def compute_heatmap(input_model, image, layer_name, eps=1e-8):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(input_model)\n",
    "    conv_output = [l for l in model.layers[0].layers if l.name is layer_name][0].output\n",
    "    grad_model = keras.models.Model(\n",
    "        inputs=[input_model.inputs],\n",
    "        outputs=[conv_output, input_model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        inputs = tf.cast(image, tf.float32)\n",
    "        (conv_outputs, predictions) = grad_model(inputs)\n",
    "        loss = predictions[:, 242]\n",
    "    \n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    \n",
    "    \n",
    "    cast_conv_outputs = tf.cast(conv_outputs > 0, tf.float32)\n",
    "    cast_grads = tf.cast(grads > 0, tf.float32)\n",
    "    \n",
    "    guided_grads = cast_conv_outputs * cast_grads * grads\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    guided_grads = guided_grads[0]\n",
    "    \n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs), axis=-1)\n",
    "    \n",
    "    heatmap = cv2.resize(cam.numpy(), (224, 224))\n",
    "    \n",
    "    numer = heatmap - np.min(heatmap)\n",
    "    denom = (heatmap.max() - heatmap.min()) + 1e-5\n",
    "    heatmap = numer / denom\n",
    "    heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "    return cam, heatmap\n",
    "\n",
    "def overlay_heatmap(heatmap, image, alpha=0.5, color_map=cv2.COLORMAP_VIRIDIS):\n",
    "    heatmap = cv2.applyColorMap(heatmap, color_map)\n",
    "    output = cv2.addWeighted(image, alpha, heatmap, 1-alpha, 0)\n",
    "\n",
    "    \n",
    "    return output, heatmap\n",
    "\n",
    "def grad_cam(input_model, image, category_index, layer_name, tape):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(input_model)\n",
    "\n",
    "    nb_classes = 1000\n",
    "    target_layer = lambda x: target_category_loss(\n",
    "        x, category_index, nb_classes\n",
    "    )\n",
    "    model.add(keras.layers.Lambda(target_layer, output_shape=target_category_loss_output_shape))\n",
    "\n",
    "\n",
    "\n",
    "    loss = keras.backend.sum(model.layers[-1].output)\n",
    "    conv_output = [l for l in model.layers[0].layers if l.name is layer_name][0].output\n",
    "    grads = tape.gradient(loss, conv_output)\n",
    "    # print(grads)\n",
    "    grads = normalize(grads[0])\n",
    "    \n",
    "    gradient_function = keras.backend.function([model.layers[0].input], [conv_output, grads])\n",
    "    \n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "    \n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.ones(output.shape[0:2], dtype=np.float32)\n",
    "    \n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i]\n",
    "        \n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "    \n",
    "    # Return to BGR from the preprocessed image\n",
    "    image = image[0, :]\n",
    "    image -= np.min(image)\n",
    "    image = np.minimum(image, 255)\n",
    "    \n",
    "    cam = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(cam) + np.float32(image)\n",
    "    cam = 255 * cam / np.max(cam)\n",
    "    \n",
    "    return np.uint8(cam), heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(predictions)\n",
    "#cam, heatmap = grad_cam(model, preprocessed_input, predicted_class, \"block5_conv3\", tape)\n",
    "cam, heatmap = compute_heatmap(model, preprocessed_input, \"block5_conv3\")\n",
    "\n",
    "heatmap = cv2.resize(heatmap, (224, 224))\n",
    "(heatmap, output) = overlay_heatmap(heatmap, preprocessed_input, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = cv2.COLORMAP_VIRIDIS\n",
    "heatmap = cv2.applyColorMap(heatmap, color_map)\n",
    "output = cv2.addWeighted(load_image(\"boat.jpg\"), 0.5, heatmap, 1 - 0.5, 0)\n",
    "cv2.imwrite(\"gradcam.jpg\", ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(preprocessed_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/vision/grad_cam/\n",
    "# https://github.com/samson6460/tf-keras-gradcamplusplus/blob/master/gradcam.py\n",
    "# https://github.com/eclique/keras-gradcam/blob/master/gradcam_vgg.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-30 19:13:14--  https://upload.wikimedia.org/wikipedia/commons/e/ef/Brosen_motor_boat.jpg\n",
      "Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240\n",
      "Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 733416 (716K) [image/jpeg]\n",
      "Saving to: ‘Brosen_motor_boat.jpg’\n",
      "\n",
      "Brosen_motor_boat.j 100%[===================>] 716.23K  3.03MB/s    in 0.2s    \n",
      "\n",
      "2020-06-30 19:13:15 (3.03 MB/s) - ‘Brosen_motor_boat.jpg’ saved [733416/733416]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://upload.wikimedia.org/wikipedia/commons/e/ef/Brosen_motor_boat.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
